{"pageProps":{"note":{"id":"axbhdgw3famw4py1hy1fywg","title":"LMQL","desc":"","updated":1689691102039,"created":1689680593676,"custom":{},"fname":"science.stats.Machine Learning.Industry Applications.ChatBots.Large Language Models.LMQL","type":"note","vault":{"fsPath":"vault"},"contentHash":"9a2ee6db36337709cdf406dba83bd2cf","links":[],"anchors":{"lmql":{"type":"header","text":"LMQL","value":"lmql","line":7,"column":0,"depth":1},"clauses":{"type":"header","text":"Clauses","value":"clauses","line":13,"column":0,"depth":1},"where-clause":{"type":"header","text":"where clause","value":"where-clause","line":15,"column":0,"depth":2},"the-main-program-caluse":{"type":"header","text":"the main program caluse","value":"the-main-program-caluse","line":18,"column":0,"depth":2},"its-also-included-in-langchain":{"type":"header","text":"It's also included in LangChain","value":"its-also-included-in-langchain","line":60,"column":0,"depth":3},"decoder-clause":{"type":"header","text":"decoder clause","value":"decoder-clause","line":66,"column":0,"depth":2},"from-clause":{"type":"header","text":"from clause","value":"from-clause","line":76,"column":0,"depth":2},"related-work":{"type":"header","text":"Related work","value":"related-work","line":80,"column":0,"depth":1},"language-model-programming":{"type":"header","text":"Language Model Programming","value":"language-model-programming","line":82,"column":0,"depth":3}},"children":[],"parent":"ux4bci7nifh9ctpofbl7txi","data":{}},"body":"<h1 id=\"lmql\">LMQL<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lmql\"></a></h1>\n<h1 id=\"lmql-1\">LMQL<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lmql-1\"></a></h1>\n<p>syntaxt</p>\n<p>'' where ...</p>\n<h1 id=\"clauses\">Clauses<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#clauses\"></a></h1>\n<h2 id=\"where-clause\">where clause<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#where-clause\"></a></h2>\n<p>specify some constraints on the output</p>\n<h2 id=\"the-main-program-caluse\">the main program caluse<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#the-main-program-caluse\"></a></h2>\n<p>Basically we can have some holes inn a text and some python expressions inside, where we're predicting the masked words.</p>\n<p>Then as the model is generating stuff according to the strategy, there is a mechanism to enforce the constraints.</p>\n<p>How does this work? with partial evaluation.\nFirst note how LLM's generate their output.\nBefore I thought they generate it trough only a deterministic greedy procedure, but actually they can use\nother graph search algorithms, where the log-probablity of the output is the weight function in the inference graph. So they can do beam search, greedy search, etc.</p>\n<p>As they go they know what variable is being 'generated' at the moment. This variable has some current value and on the basis of this one can say if the variable is violating some constraints. If yes, the search procedure can backtrack. If not, it can continue, while also knowing if the variable can have something added to it, or not.\nI think these are generated as 'follow' and 'fin' nodes in the graph for a particular variable.</p>\n<p>Examples:\nIf a var is constrained to be in a list (e.g. 'positive' or 'negtive') that can work in an obvious way..</p>\n<p>other things...</p>\n<p>It saves 26-60% ofthe cost, but sort of a 'normal amound', as it can cut off unsatisfiable branches.</p>\n<p>quite flexeble with the constraints, have to learn more about the syntax...\nThere was this syntax </p>\n<pre><code>sample(temperature=1.2)\n\"A few things not to forget when going to the sea (not travelling):\\n \"\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n</code></pre>\n<p>where 'thing' is not the same everywhere.</p>\n<p>Quite good at enforxing consistency, eg.g by a clause like:</p>\n<pre><code>\"A few things not to forget when going to the sea (not travelling):\\n \"\n</code></pre>\n<h3 id=\"its-also-included-in-langchain\">It's also included in LangChain<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#its-also-included-in-langchain\"></a></h3>\n<p>As we've geneRated the partial outpud</p>\n<h2 id=\"decoder-clause\">decoder clause<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#decoder-clause\"></a></h2>\n<p>Specity the decoding algorithm to use,\ncan be sample, argmax/or other stuff, like beam or best_k</p>\n<p>Beam, argmax.\n,\nsample, beam_sample, beam_var,...</p>\n<h2 id=\"from-clause\">from clause<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#from-clause\"></a></h2>\n<p>specify the model to use</p>\n<h1 id=\"related-work\">Related work<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#related-work\"></a></h1>\n<h3 id=\"language-model-programming\">Language Model Programming<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#language-model-programming\"></a></h3>\n<p>All sorts of chain-of-thought and similar things can be considered as part of language model programming...</p>\n<p>Chain of thought prompting, tree of thought, and others are all part of this and instantiations of it.</p>","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1647507231129,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"db285659ccac8b133c384de1ef51de66","links":[],"anchors":{"welcome-to-stefans-notes":{"type":"header","text":"Welcome to Stefan's Notes!","value":"welcome-to-stefans-notes","line":7,"column":0,"depth":1}},"children":["mxzxxu8z4e6krz99ht96y9d","W1EOZ27Tqx6RbiA2aW3DI","DyoLE2kwm9rRfRZhBGxPW","idhfogizmtcmvaamtalp3o3","4w8wBCSRvYUnGIZeozW03","vB321AipYCs6ldVC0APs9","h6WVdl1UTWVXeWuMJSZ1f","bth6m0exy9q9loxib1mc4al","4abAmH56ausbldEJbZokx","JyOFJ5NTPSVWMfiDy951X","0OO7fjCpcaGZg5qDRZr8z","138666663","pohXgII67dAxnoufG7yAP","6hs48bnjnaoxahk07exj74u","42r6290iqzLPmg9BY7fIp","3hoLerNJHjNkDziIKlFF2","T6meT3UNw0nRorEbzoPSl","hIOTXIIBj3vmhG1xc91lA","tnFlQuOAGPkbU2fZI7Cb1","Jb3w3f4x8kixLhrjUW6S1","LV6q5jlD2xtCF6yYFEqFC","ENDcCZFjAW9h66eDoFg7I","b5IeREnsTbeggC7rmWV0p","2hmbhdzcdljtdwln762gcrv","z9la6u9t3xueldj2omf2gc6","9akeo93l6b026jmu4t6e7pw","sc24o4jglr9jg29qr5v0e44","0mt5ao8tbbz3z5mdwe0aer8","r7rvb6nal69nfb6ogqdadnm","xujx5iuxskj10o0ajpi109n","lyl1rzqz6zwcswpwh0kafrm","skpw697vlqdq3t3uqxpq5e3","a4tts3oc3oms7wuralrbzdc","13a1ufqh6o8yi9evw1u5kv5"],"parent":null,"data":{},"body":"# Welcome to Stefan's Notes!\n\n        \n\nLast updated: 2021.12.30\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/PublicPersonalKnowledgeBase","siteUrl":"https://petrovs12.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}