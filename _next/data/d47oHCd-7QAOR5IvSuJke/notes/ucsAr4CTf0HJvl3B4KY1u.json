{"pageProps":{"note":{"id":"ucsAr4CTf0HJvl3B4KY1u","title":"Vision Models","desc":"","updated":1644708282688,"created":1644706160543,"custom":{},"fname":"science.stats.Deep Neural Networks.Vision Models","type":"note","vault":{"fsPath":"vault"},"contentHash":"3f09c90b05ff927085aa4f0a4f4697f5","links":[{"type":"wiki","from":{"fname":"science.stats.Deep Neural Networks.Vision Models","id":"ucsAr4CTf0HJvl3B4KY1u","vaultName":"vault"},"value":"science.stats.Deep Neural Networks","position":{"start":{"line":3,"column":1,"offset":2},"end":{"line":3,"column":44,"offset":45},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"science.stats.Deep Neural Networks","anchorHeader":"^cnn"}},{"type":"wiki","from":{"fname":"science.stats.Deep Neural Networks.Vision Models","id":"ucsAr4CTf0HJvl3B4KY1u","vaultName":"vault"},"value":"science.engineering.technologies.MLOps.ONNX","position":{"start":{"line":10,"column":67,"offset":232},"end":{"line":10,"column":114,"offset":279},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"science.engineering.technologies.MLOps.ONNX"}},{"from":{"fname":"science.stats.Deep Neural Networks.Transfer Learning","id":"V4exKlI4VAWINpSZOytYw","vaultName":"vault"},"type":"backlink","position":{"start":{"line":8,"column":1,"offset":140},"end":{"line":8,"column":53,"offset":192},"indent":[]},"value":"science.stats.Deep Neural Networks.Vision Models"},{"from":{"fname":"science.stats.Machine Learning.Industry Applications","id":"hiuvax4qcz63e0zseg5c8ai","vaultName":"vault"},"type":"backlink","position":{"start":{"line":18,"column":1,"offset":816},"end":{"line":18,"column":53,"offset":868},"indent":[]},"value":"science.stats.Deep Neural Networks.Vision Models"}],"anchors":{"image-classification":{"type":"header","text":"Image Classification","value":"image-classification","line":12,"column":0,"depth":1},"vgg-16":{"type":"header","text":"VGG-16","value":"vgg-16","line":18,"column":0,"depth":2},"resnet":{"type":"header","text":"ResNet","value":"resnet","line":23,"column":0,"depth":2},"efficientnet-lite4":{"type":"header","text":"EfficientNet-Lite4","value":"efficientnet-lite4","line":27,"column":0,"depth":2},"object-detection-and-image-segmentation":{"type":"header","text":"Object detection and Image Segmentation","value":"object-detection-and-image-segmentation","line":33,"column":0,"depth":1},"evaluation-metrics":{"type":"header","text":"Evaluation metrics","value":"evaluation-metrics","line":38,"column":0,"depth":2},"intersection-over-union-iou":{"type":"header","text":"Intersection over Union (IoU):","value":"intersection-over-union-iou","line":41,"column":0,"depth":3},"coco-map":{"type":"header","text":"COCO mAP","value":"coco-map","line":47,"column":0,"depth":3},"modelsalgorithms":{"type":"header","text":"Models/Algorithms","value":"modelsalgorithms","line":51,"column":0,"depth":2},"yolo3":{"type":"header","text":"Yolo3","value":"yolo3","line":53,"column":0,"depth":3},"body-face-and-gesture-analysis":{"type":"header","text":"Body, Face, And Gesture Analysis","value":"body-face-and-gesture-analysis","line":57,"column":0,"depth":1},"image-mnanipulation":{"type":"header","text":"Image MNanipulation","value":"image-mnanipulation","line":60,"column":0,"depth":1}},"children":[],"parent":"1oUqI7ql4EuPu9Ml94Xe1","data":{}},"body":"<h1 id=\"vision-models\">Vision Models<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vision-models\"></a></h1>\n<p><a href=\"/PublicPersonalKnowledgeBase/notes/1oUqI7ql4EuPu9Ml94Xe1#^cnn\">Deep Neural Networks</a></p>\n<h1 id=\"image-classification\">Image Classification<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#image-classification\"></a></h1>\n<p>Normally these models are trained on ImageNet and top-5 classification accuracy is reported.</p>\n<p>Here are some of the current champions that are also available as <a href=\"/PublicPersonalKnowledgeBase/notes/fwJbQKdytxvuwjuehkoXf\">ONNX</a> models.</p>\n<h2 id=\"vgg-16\">VGG-16<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#vgg-16\"></a></h2>\n<p><img src=\"/PublicPersonalKnowledgeBase/assets/images/2022-02-12-23-49-48.png\">\n<a href=\"https://keras.io/api/applications/vgg/\">Keras Link</a></p>\n<h2 id=\"resnet\">ResNet<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#resnet\"></a></h2>\n<p>Uses Shortcut connections</p>\n<h2 id=\"efficientnet-lite4\">EfficientNet-Lite4<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#efficientnet-lite4\"></a></h2>\n<p><a href=\"https://arxiv.org/abs/1905.11946\">Paper Link</a>\n<a href=\"https://github.com/onnx/models/tree/main/vision/classification/efficientnet-lite4\">ONXX</a></p>\n<h1 id=\"object-detection-and-image-segmentation\">Object detection and Image Segmentation<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#object-detection-and-image-segmentation\"></a></h1>\n<p>Object detection and image segmentation algorithms draw rectangles on a picture and put labels on them.</p>\n<h2 id=\"evaluation-metrics\">Evaluation metrics<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#evaluation-metrics\"></a></h2>\n<p>A common evaluation metric are (from <a href=\"https://medium.com/@vijayshankerdubey550/evaluation-metrics-for-object-detection-algorithms-b0d6489879f3\">here</a>):</p>\n<h3 id=\"intersection-over-union-iou\">Intersection over Union (IoU):<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#intersection-over-union-iou\"></a></h3>\n<p> Evaluate the overlap of the two bounding boxes. Requires a true and predicted bounding box. So then we have something like:</p>\n<p> Intersection Over Union on top 5 Labels.</p>\n<h3 id=\"coco-map\">COCO mAP<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#coco-map\"></a></h3>\n<p>For the COCO 2017 challenge, the mAP was calculated by averaging the AP over all 80 object categories AND all 10 IoU thresholds from 0.5 to 0.95 with a step size of 0.05. The authors hypothesize that averaging over IoUs rewards detectors with better localization.</p>\n<h2 id=\"modelsalgorithms\">Models/Algorithms<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#modelsalgorithms\"></a></h2>\n<h3 id=\"yolo3\">Yolo3<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#yolo3\"></a></h3>\n<p><a href=\"https://github.com/onnx/models/tree/main/vision/object_detection_segmentation/yolov3\">YoloV4</a></p>\n<h1 id=\"body-face-and-gesture-analysis\">Body, Face, And Gesture Analysis<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#body-face-and-gesture-analysis\"></a></h1>\n<h1 id=\"image-mnanipulation\">Image MNanipulation<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#image-mnanipulation\"></a></h1>\n<ul>\n<li>Unpaired Image To Image Translation</li>\n<li>Super REsolution </li>\n<li>Fast Neural Style Transfer</li>\n</ul>\n<hr>\n<strong>Backlinks</strong>\n<ul>\n<li><a href=\"/PublicPersonalKnowledgeBase/notes/V4exKlI4VAWINpSZOytYw\">Transfer Learning</a></li>\n<li><a href=\"/PublicPersonalKnowledgeBase/notes/hiuvax4qcz63e0zseg5c8ai\">Industry Applications</a></li>\n</ul>","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1647507231129,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"db285659ccac8b133c384de1ef51de66","links":[],"anchors":{"welcome-to-stefans-notes":{"type":"header","text":"Welcome to Stefan's Notes!","value":"welcome-to-stefans-notes","line":7,"column":0,"depth":1}},"children":["mxzxxu8z4e6krz99ht96y9d","W1EOZ27Tqx6RbiA2aW3DI","DyoLE2kwm9rRfRZhBGxPW","idhfogizmtcmvaamtalp3o3","4w8wBCSRvYUnGIZeozW03","vB321AipYCs6ldVC0APs9","h6WVdl1UTWVXeWuMJSZ1f","bth6m0exy9q9loxib1mc4al","4abAmH56ausbldEJbZokx","JyOFJ5NTPSVWMfiDy951X","0OO7fjCpcaGZg5qDRZr8z","138666663","pohXgII67dAxnoufG7yAP","6hs48bnjnaoxahk07exj74u","42r6290iqzLPmg9BY7fIp","3hoLerNJHjNkDziIKlFF2","T6meT3UNw0nRorEbzoPSl","hIOTXIIBj3vmhG1xc91lA","tnFlQuOAGPkbU2fZI7Cb1","Jb3w3f4x8kixLhrjUW6S1","LV6q5jlD2xtCF6yYFEqFC","ENDcCZFjAW9h66eDoFg7I","b5IeREnsTbeggC7rmWV0p","2hmbhdzcdljtdwln762gcrv","z9la6u9t3xueldj2omf2gc6","9akeo93l6b026jmu4t6e7pw","sc24o4jglr9jg29qr5v0e44","0mt5ao8tbbz3z5mdwe0aer8","r7rvb6nal69nfb6ogqdadnm","xujx5iuxskj10o0ajpi109n","lyl1rzqz6zwcswpwh0kafrm","skpw697vlqdq3t3uqxpq5e3","a4tts3oc3oms7wuralrbzdc","13a1ufqh6o8yi9evw1u5kv5"],"parent":null,"data":{},"body":"# Welcome to Stefan's Notes!\n\n        \n\nLast updated: 2021.12.30\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/PublicPersonalKnowledgeBase","siteUrl":"https://petrovs12.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}