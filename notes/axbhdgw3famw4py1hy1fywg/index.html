<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/PublicPersonalKnowledgeBase/favicon.ico"/><title>LMQL</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="LMQL"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://petrovs12.github.io/PublicPersonalKnowledgeBase/notes/axbhdgw3famw4py1hy1fywg/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/18/2023"/><meta property="article:modified_time" content="7/18/2023"/><link rel="canonical" href="https://petrovs12.github.io/PublicPersonalKnowledgeBase/notes/axbhdgw3famw4py1hy1fywg/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/PublicPersonalKnowledgeBase/_next/static/css/7719b08cc3352912.css" as="style"/><link rel="stylesheet" href="/PublicPersonalKnowledgeBase/_next/static/css/7719b08cc3352912.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/PublicPersonalKnowledgeBase/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/webpack-b320c149a25b986a.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/main-8915ee191b7710e8.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/pages/_app-bf98b80149ea852b.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/d47oHCd-7QAOR5IvSuJke/_buildManifest.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/d47oHCd-7QAOR5IvSuJke/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="lmql">LMQL<a aria-hidden="true" class="anchor-heading icon-link" href="#lmql"></a></h1>
<h1 id="lmql-1">LMQL<a aria-hidden="true" class="anchor-heading icon-link" href="#lmql-1"></a></h1>
<p>syntaxt</p>
<p>'' where ...</p>
<h1 id="clauses">Clauses<a aria-hidden="true" class="anchor-heading icon-link" href="#clauses"></a></h1>
<h2 id="where-clause">where clause<a aria-hidden="true" class="anchor-heading icon-link" href="#where-clause"></a></h2>
<p>specify some constraints on the output</p>
<h2 id="the-main-program-caluse">the main program caluse<a aria-hidden="true" class="anchor-heading icon-link" href="#the-main-program-caluse"></a></h2>
<p>Basically we can have some holes inn a text and some python expressions inside, where we're predicting the masked words.</p>
<p>Then as the model is generating stuff according to the strategy, there is a mechanism to enforce the constraints.</p>
<p>How does this work? with partial evaluation.
First note how LLM's generate their output.
Before I thought they generate it trough only a deterministic greedy procedure, but actually they can use
other graph search algorithms, where the log-probablity of the output is the weight function in the inference graph. So they can do beam search, greedy search, etc.</p>
<p>As they go they know what variable is being 'generated' at the moment. This variable has some current value and on the basis of this one can say if the variable is violating some constraints. If yes, the search procedure can backtrack. If not, it can continue, while also knowing if the variable can have something added to it, or not.
I think these are generated as 'follow' and 'fin' nodes in the graph for a particular variable.</p>
<p>Examples:
If a var is constrained to be in a list (e.g. 'positive' or 'negtive') that can work in an obvious way..</p>
<p>other things...</p>
<p>It saves 26-60% ofthe cost, but sort of a 'normal amound', as it can cut off unsatisfiable branches.</p>
<p>quite flexeble with the constraints, have to learn more about the syntax...
There was this syntax </p>
<pre><code>sample(temperature=1.2)
"A few things not to forget when going to the sea (not travelling):\n "
"-[THING]" where stops_at(thing,"\n")
"-[THING]" where stops_at(thing,"\n")
"-[THING]" where stops_at(thing,"\n")
"-[THING]" where stops_at(thing,"\n")
</code></pre>
<p>where 'thing' is not the same everywhere.</p>
<p>Quite good at enforxing consistency, eg.g by a clause like:</p>
<pre><code>"A few things not to forget when going to the sea (not travelling):\n "
</code></pre>
<h3 id="its-also-included-in-langchain">It's also included in LangChain<a aria-hidden="true" class="anchor-heading icon-link" href="#its-also-included-in-langchain"></a></h3>
<p>As we've geneRated the partial outpud</p>
<h2 id="decoder-clause">decoder clause<a aria-hidden="true" class="anchor-heading icon-link" href="#decoder-clause"></a></h2>
<p>Specity the decoding algorithm to use,
can be sample, argmax/or other stuff, like beam or best_k</p>
<p>Beam, argmax.
,
sample, beam_sample, beam_var,...</p>
<h2 id="from-clause">from clause<a aria-hidden="true" class="anchor-heading icon-link" href="#from-clause"></a></h2>
<p>specify the model to use</p>
<h1 id="related-work">Related work<a aria-hidden="true" class="anchor-heading icon-link" href="#related-work"></a></h1>
<h3 id="language-model-programming">Language Model Programming<a aria-hidden="true" class="anchor-heading icon-link" href="#language-model-programming"></a></h3>
<p>All sorts of chain-of-thought and similar things can be considered as part of language model programming...</p>
<p>Chain of thought prompting, tree of thought, and others are all part of this and instantiations of it.</p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#lmql" title="LMQL">LMQL</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#clauses" title="Clauses">Clauses</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#where-clause" title="where clause">where clause</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#the-main-program-caluse" title="the main program caluse">the main program caluse</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#its-also-included-in-langchain" title="It&#x27;s also included in LangChain">It&#x27;s also included in LangChain</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#decoder-clause" title="decoder clause">decoder clause</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#from-clause" title="from clause">from clause</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#related-work" title="Related work">Related work</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#language-model-programming" title="Language Model Programming">Language Model Programming</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"axbhdgw3famw4py1hy1fywg","title":"LMQL","desc":"","updated":1689691102039,"created":1689680593676,"custom":{},"fname":"science.stats.Machine Learning.Industry Applications.ChatBots.Large Language Models.LMQL","type":"note","vault":{"fsPath":"vault"},"contentHash":"9a2ee6db36337709cdf406dba83bd2cf","links":[],"anchors":{"lmql":{"type":"header","text":"LMQL","value":"lmql","line":7,"column":0,"depth":1},"clauses":{"type":"header","text":"Clauses","value":"clauses","line":13,"column":0,"depth":1},"where-clause":{"type":"header","text":"where clause","value":"where-clause","line":15,"column":0,"depth":2},"the-main-program-caluse":{"type":"header","text":"the main program caluse","value":"the-main-program-caluse","line":18,"column":0,"depth":2},"its-also-included-in-langchain":{"type":"header","text":"It's also included in LangChain","value":"its-also-included-in-langchain","line":60,"column":0,"depth":3},"decoder-clause":{"type":"header","text":"decoder clause","value":"decoder-clause","line":66,"column":0,"depth":2},"from-clause":{"type":"header","text":"from clause","value":"from-clause","line":76,"column":0,"depth":2},"related-work":{"type":"header","text":"Related work","value":"related-work","line":80,"column":0,"depth":1},"language-model-programming":{"type":"header","text":"Language Model Programming","value":"language-model-programming","line":82,"column":0,"depth":3}},"children":[],"parent":"ux4bci7nifh9ctpofbl7txi","data":{}},"body":"\u003ch1 id=\"lmql\"\u003eLMQL\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lmql\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch1 id=\"lmql-1\"\u003eLMQL\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lmql-1\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003esyntaxt\u003c/p\u003e\n\u003cp\u003e'' where ...\u003c/p\u003e\n\u003ch1 id=\"clauses\"\u003eClauses\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#clauses\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch2 id=\"where-clause\"\u003ewhere clause\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#where-clause\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003especify some constraints on the output\u003c/p\u003e\n\u003ch2 id=\"the-main-program-caluse\"\u003ethe main program caluse\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#the-main-program-caluse\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eBasically we can have some holes inn a text and some python expressions inside, where we're predicting the masked words.\u003c/p\u003e\n\u003cp\u003eThen as the model is generating stuff according to the strategy, there is a mechanism to enforce the constraints.\u003c/p\u003e\n\u003cp\u003eHow does this work? with partial evaluation.\nFirst note how LLM's generate their output.\nBefore I thought they generate it trough only a deterministic greedy procedure, but actually they can use\nother graph search algorithms, where the log-probablity of the output is the weight function in the inference graph. So they can do beam search, greedy search, etc.\u003c/p\u003e\n\u003cp\u003eAs they go they know what variable is being 'generated' at the moment. This variable has some current value and on the basis of this one can say if the variable is violating some constraints. If yes, the search procedure can backtrack. If not, it can continue, while also knowing if the variable can have something added to it, or not.\nI think these are generated as 'follow' and 'fin' nodes in the graph for a particular variable.\u003c/p\u003e\n\u003cp\u003eExamples:\nIf a var is constrained to be in a list (e.g. 'positive' or 'negtive') that can work in an obvious way..\u003c/p\u003e\n\u003cp\u003eother things...\u003c/p\u003e\n\u003cp\u003eIt saves 26-60% ofthe cost, but sort of a 'normal amound', as it can cut off unsatisfiable branches.\u003c/p\u003e\n\u003cp\u003equite flexeble with the constraints, have to learn more about the syntax...\nThere was this syntax \u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esample(temperature=1.2)\n\"A few things not to forget when going to the sea (not travelling):\\n \"\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ewhere 'thing' is not the same everywhere.\u003c/p\u003e\n\u003cp\u003eQuite good at enforxing consistency, eg.g by a clause like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e\"A few things not to forget when going to the sea (not travelling):\\n \"\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"its-also-included-in-langchain\"\u003eIt's also included in LangChain\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#its-also-included-in-langchain\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAs we've geneRated the partial outpud\u003c/p\u003e\n\u003ch2 id=\"decoder-clause\"\u003edecoder clause\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#decoder-clause\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eSpecity the decoding algorithm to use,\ncan be sample, argmax/or other stuff, like beam or best_k\u003c/p\u003e\n\u003cp\u003eBeam, argmax.\n,\nsample, beam_sample, beam_var,...\u003c/p\u003e\n\u003ch2 id=\"from-clause\"\u003efrom clause\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#from-clause\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003especify the model to use\u003c/p\u003e\n\u003ch1 id=\"related-work\"\u003eRelated work\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#related-work\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch3 id=\"language-model-programming\"\u003eLanguage Model Programming\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#language-model-programming\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eAll sorts of chain-of-thought and similar things can be considered as part of language model programming...\u003c/p\u003e\n\u003cp\u003eChain of thought prompting, tree of thought, and others are all part of this and instantiations of it.\u003c/p\u003e","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1647507231129,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"db285659ccac8b133c384de1ef51de66","links":[],"anchors":{"welcome-to-stefans-notes":{"type":"header","text":"Welcome to Stefan's Notes!","value":"welcome-to-stefans-notes","line":7,"column":0,"depth":1}},"children":["mxzxxu8z4e6krz99ht96y9d","W1EOZ27Tqx6RbiA2aW3DI","DyoLE2kwm9rRfRZhBGxPW","idhfogizmtcmvaamtalp3o3","4w8wBCSRvYUnGIZeozW03","vB321AipYCs6ldVC0APs9","h6WVdl1UTWVXeWuMJSZ1f","bth6m0exy9q9loxib1mc4al","4abAmH56ausbldEJbZokx","JyOFJ5NTPSVWMfiDy951X","0OO7fjCpcaGZg5qDRZr8z","138666663","pohXgII67dAxnoufG7yAP","6hs48bnjnaoxahk07exj74u","42r6290iqzLPmg9BY7fIp","3hoLerNJHjNkDziIKlFF2","T6meT3UNw0nRorEbzoPSl","hIOTXIIBj3vmhG1xc91lA","tnFlQuOAGPkbU2fZI7Cb1","Jb3w3f4x8kixLhrjUW6S1","LV6q5jlD2xtCF6yYFEqFC","ENDcCZFjAW9h66eDoFg7I","b5IeREnsTbeggC7rmWV0p","2hmbhdzcdljtdwln762gcrv","z9la6u9t3xueldj2omf2gc6","9akeo93l6b026jmu4t6e7pw","sc24o4jglr9jg29qr5v0e44","0mt5ao8tbbz3z5mdwe0aer8","r7rvb6nal69nfb6ogqdadnm","xujx5iuxskj10o0ajpi109n","lyl1rzqz6zwcswpwh0kafrm","skpw697vlqdq3t3uqxpq5e3","a4tts3oc3oms7wuralrbzdc","13a1ufqh6o8yi9evw1u5kv5"],"parent":null,"data":{},"body":"# Welcome to Stefan's Notes!\n\n        \n\nLast updated: 2021.12.30\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/PublicPersonalKnowledgeBase","siteUrl":"https://petrovs12.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"axbhdgw3famw4py1hy1fywg"},"buildId":"d47oHCd-7QAOR5IvSuJke","assetPrefix":"/PublicPersonalKnowledgeBase","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>