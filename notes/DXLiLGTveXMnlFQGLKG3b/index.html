<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/PublicPersonalKnowledgeBase/favicon.ico"/><title>Regularizations</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Regularizations"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://petrovs12.github.io/PublicPersonalKnowledgeBase/notes/DXLiLGTveXMnlFQGLKG3b/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="1/11/2022"/><meta property="article:modified_time" content="3/3/2022"/><link rel="canonical" href="https://petrovs12.github.io/PublicPersonalKnowledgeBase/notes/DXLiLGTveXMnlFQGLKG3b/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/PublicPersonalKnowledgeBase/_next/static/css/7719b08cc3352912.css" as="style"/><link rel="stylesheet" href="/PublicPersonalKnowledgeBase/_next/static/css/7719b08cc3352912.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/PublicPersonalKnowledgeBase/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/webpack-b320c149a25b986a.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/main-8915ee191b7710e8.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/pages/_app-bf98b80149ea852b.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/d47oHCd-7QAOR5IvSuJke/_buildManifest.js" defer=""></script><script src="/PublicPersonalKnowledgeBase/_next/static/d47oHCd-7QAOR5IvSuJke/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="regularizations">Regularizations<a aria-hidden="true" class="anchor-heading icon-link" href="#regularizations"></a></h1>
<h1 id="l_1or-l_2-regularizations-in-regression"><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span>or <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> regularizations in regression<a aria-hidden="true" class="anchor-heading icon-link" href="#l_1or-l_2-regularizations-in-regression"></a></h1>
<p><a href="/PublicPersonalKnowledgeBase/notes/YSgeu1I7ZeKOAKUbvuL8M">Linear Regression</a></p>
<h1 id="map-vs-mle">MAP vs MLE<a aria-hidden="true" class="anchor-heading icon-link" href="#map-vs-mle"></a></h1>
<p><a href="/PublicPersonalKnowledgeBase/notes/YSgeu1I7ZeKOAKUbvuL8M">Linear Regression</a></p>
<p>Given a dataset X, a common task is to try to estimate the most likely values for the model parameters. To do this, you must find the values that maximize the likelihood function, given X. In this example, if you have observed a single instance x=2.5, the maximum likelihood estimate (MLE) of θ is <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover><mo>=</mo><mn>1.5</mn></mrow><annotation encoding="application/x-tex">\hat{\theta}=1.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1.5</span></span></span></span></span>. If a prior probability distribution g over θ exists, it is possible to take it into account by maximizing <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mi>g</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(θ|x)g(θ)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span></span> rather than just maximizing <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L(θ|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>. This is called <strong>maximum a-posteriori (MAP) estimation</strong>. Since MAP constrains the parameter values, you can think of it as a regularized version of MLE.</p>
<p>For example <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> regularization is equivalent to putting a Laplace prior on the parameters, whereas
<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span> regularization is equivalent to putting a Gaussian prior on them.</p>
<h1 id="l1-l2-ridge-tikhonov-lasso">L1, L2, Ridge, Tikhonov, LASSO<a aria-hidden="true" class="anchor-heading icon-link" href="#l1-l2-ridge-tikhonov-lasso"></a></h1>
<p>Ridge regression has a closed form solution.</p>
<p><a href="/PublicPersonalKnowledgeBase/notes/1JYjLMyPvKFb3dG4hc3oM">Norms and Metrics</a></p>
<h1 id="dropout">Dropout<a aria-hidden="true" class="anchor-heading icon-link" href="#dropout"></a></h1>
<p></p><p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">Dropout</span></div>
<a href="/PublicPersonalKnowledgeBase/notes/ytp3nmwv2nmc0tum4472bba" class="portal-arrow">Go to text <span class="right-arrow">→</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><p>Dropout:</p>
<ol>
<li>At training time, in each training epoch, drop out nodes/connections randomly by setting their weights to zero.
Each node weight is set by 0 with probability <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span>.</li>
<li>At testing/inference time, multiply each learned weight by <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span>.</li>
</ol>
<p>Justification:
We 'stochastically train' simultaneously <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mi mathvariant="normal">∣</mi><mi>N</mi><mi>N</mi><mi mathvariant="normal">∣</mi></mrow></msup></mrow><annotation encoding="application/x-tex">2^{|NN|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">NN</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span></span></span></span></span> models,where <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi>N</mi><mi>N</mi><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">|NN|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.10903em;">NN</span><span class="mord">∣</span></span></span></span></span> is the network size.
Thus at the end of training we may pretend we have <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mi mathvariant="normal">∣</mi><mi>N</mi><mi>N</mi><mi mathvariant="normal">∣</mi></mrow></msup></mrow><annotation encoding="application/x-tex">2^{|NN|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">NN</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span></span></span></span></span> candidate models. That is, we can drop any number of nodes and still have a model.
Now, ideally, on inference time, we may :
For each subset of nodes, disable them, and predict on the basis of the rest, and then take the average.
But this is obviously infeasible.  So we approximate their 'model average' by <strong>multiplying the weights by <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span></strong>.</p>
</div></div><p></p><p></p>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/PublicPersonalKnowledgeBase/notes/ytp3nmwv2nmc0tum4472bba">Dropout</a></li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#l_1or-l_2-regularizations-in-regression" title="$L_1$or $L_2$ regularizations in regression">$L_1$or $L_2$ regularizations in regression</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#map-vs-mle" title="MAP vs MLE">MAP vs MLE</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#l1-l2-ridge-tikhonov-lasso" title="L1, L2, Ridge, Tikhonov, LASSO">L1, L2, Ridge, Tikhonov, LASSO</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#dropout" title="Dropout">Dropout</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"DXLiLGTveXMnlFQGLKG3b","title":"Regularizations","desc":"","updated":1646298983624,"created":1641864475560,"custom":{},"fname":"science.math.Optimization.Regularizations","type":"note","vault":{"fsPath":"vault"},"contentHash":"bb5ce3098dabd8e5d5977361840f664e","links":[{"type":"wiki","from":{"fname":"science.math.Optimization.Regularizations","id":"DXLiLGTveXMnlFQGLKG3b","vaultName":"vault"},"value":"science.stats.Regression.Linear Regression","position":{"start":{"line":2,"column":1,"offset":46},"end":{"line":2,"column":47,"offset":92},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"science.stats.Regression.Linear Regression"}},{"type":"wiki","from":{"fname":"science.math.Optimization.Regularizations","id":"DXLiLGTveXMnlFQGLKG3b","vaultName":"vault"},"value":"science.stats.Regression.Linear Regression","position":{"start":{"line":5,"column":1,"offset":107},"end":{"line":5,"column":47,"offset":153},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"science.stats.Regression.Linear Regression"}},{"type":"wiki","from":{"fname":"science.math.Optimization.Regularizations","id":"DXLiLGTveXMnlFQGLKG3b","vaultName":"vault"},"value":"science.math.Norms and Metrics","position":{"start":{"line":17,"column":1,"offset":1040},"end":{"line":17,"column":35,"offset":1074},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"science.math.Norms and Metrics"}},{"type":"ref","from":{"fname":"science.math.Optimization.Regularizations","id":"DXLiLGTveXMnlFQGLKG3b","vaultName":"vault"},"value":"science.math.Optimization.Regularizations.Dropout","position":{"start":{"line":20,"column":1,"offset":1086},"end":{"line":20,"column":55,"offset":1140},"indent":[]},"xvault":false,"to":{"fname":"science.math.Optimization.Regularizations.Dropout"}}],"anchors":{"l_1or-l_2-regularizations-in-regression":{"type":"header","text":"$L_1$or $L_2$ regularizations in regression","value":"l_1or-l_2-regularizations-in-regression","line":7,"column":0,"depth":1},"map-vs-mle":{"type":"header","text":"MAP vs MLE","value":"map-vs-mle","line":10,"column":0,"depth":1},"l1-l2-ridge-tikhonov-lasso":{"type":"header","text":"L1, L2, Ridge, Tikhonov, LASSO","value":"l1-l2-ridge-tikhonov-lasso","line":19,"column":0,"depth":1},"dropout":{"type":"header","text":"Dropout","value":"dropout","line":25,"column":0,"depth":1}},"children":["ytp3nmwv2nmc0tum4472bba"],"parent":"4FIxH4rGwMUvVyCogNmHe","data":{}},"body":"\u003ch1 id=\"regularizations\"\u003eRegularizations\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#regularizations\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch1 id=\"l_1or-l_2-regularizations-in-regression\"\u003e\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL_1\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003eor \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL_2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e regularizations in regression\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#l_1or-l_2-regularizations-in-regression\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"/PublicPersonalKnowledgeBase/notes/YSgeu1I7ZeKOAKUbvuL8M\"\u003eLinear Regression\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"map-vs-mle\"\u003eMAP vs MLE\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#map-vs-mle\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"/PublicPersonalKnowledgeBase/notes/YSgeu1I7ZeKOAKUbvuL8M\"\u003eLinear Regression\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eGiven a dataset X, a common task is to try to estimate the most likely values for the model parameters. To do this, you must find the values that maximize the likelihood function, given X. In this example, if you have observed a single instance x=2.5, the maximum likelihood estimate (MLE) of θ is \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmover accent=\"true\"\u003e\u003cmi\u003eθ\u003c/mi\u003e\u003cmo\u003e^\u003c/mo\u003e\u003c/mover\u003e\u003cmo\u003e=\u003c/mo\u003e\u003cmn\u003e1.5\u003c/mn\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e\\hat{\\theta}=1.5\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.9579em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord accent\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.9579em;\"\u003e\u003cspan style=\"top:-3em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eθ\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"top:-3.2634em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:3em;\"\u003e\u003c/span\u003e\u003cspan class=\"accent-body\" style=\"left:-0.1667em;\"\u003e\u003cspan class=\"mord\"\u003e^\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003cspan class=\"mrel\"\u003e=\u003c/span\u003e\u003cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.6444em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e1.5\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e. If a prior probability distribution g over θ exists, it is possible to take it into account by maximizing \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eθ\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003cmi\u003eg\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eθ\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL(θ|x)g(θ)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eθ\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.03588em;\"\u003eg\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eθ\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e rather than just maximizing \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e(\u003c/mo\u003e\u003cmi\u003eθ\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003ex\u003c/mi\u003e\u003cmo stretchy=\"false\"\u003e)\u003c/mo\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL(θ|x)\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"mopen\"\u003e(\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.02778em;\"\u003eθ\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ex\u003c/span\u003e\u003cspan class=\"mclose\"\u003e)\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e. This is called \u003cstrong\u003emaximum a-posteriori (MAP) estimation\u003c/strong\u003e. Since MAP constrains the parameter values, you can think of it as a regularized version of MLE.\u003c/p\u003e\n\u003cp\u003eFor example \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmn\u003e1\u003c/mn\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL_1\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e1\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e regularization is equivalent to putting a Laplace prior on the parameters, whereas\n\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsub\u003e\u003cmi\u003eL\u003c/mi\u003e\u003cmn\u003e2\u003c/mn\u003e\u003c/msub\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003eL_2\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord mathnormal\"\u003eL\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t vlist-t2\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.3011em;\"\u003e\u003cspan style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e2\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-s\"\u003e​\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.15em;\"\u003e\u003cspan\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e regularization is equivalent to putting a Gaussian prior on them.\u003c/p\u003e\n\u003ch1 id=\"l1-l2-ridge-tikhonov-lasso\"\u003eL1, L2, Ridge, Tikhonov, LASSO\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#l1-l2-ridge-tikhonov-lasso\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eRidge regression has a closed form solution.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"/PublicPersonalKnowledgeBase/notes/1JYjLMyPvKFb3dG4hc3oM\"\u003eNorms and Metrics\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"dropout\"\u003eDropout\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#dropout\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cdiv class=\"portal-container\"\u003e\n\u003cdiv class=\"portal-head\"\u003e\n\u003cdiv class=\"portal-backlink\"\u003e\n\u003cdiv class=\"portal-title\"\u003eFrom \u003cspan class=\"portal-text-title\"\u003eDropout\u003c/span\u003e\u003c/div\u003e\n\u003ca href=\"/PublicPersonalKnowledgeBase/notes/ytp3nmwv2nmc0tum4472bba\" class=\"portal-arrow\"\u003eGo to text \u003cspan class=\"right-arrow\"\u003e→\u003c/span\u003e\u003c/a\u003e\n\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"portal-parent-anchor\" class=\"portal-parent\" markdown=\"1\"\u003e\n\u003cdiv class=\"portal-parent-fader-top\"\u003e\u003c/div\u003e\n\u003cdiv class=\"portal-parent-fader-bottom\"\u003e\u003c/div\u003e\u003cp\u003eDropout:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAt training time, in each training epoch, drop out nodes/connections randomly by setting their weights to zero.\nEach node weight is set by 0 with probability \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ep\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e.\u003c/li\u003e\n\u003cli\u003eAt testing/inference time, multiply each learned weight by \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ep\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eJustification:\nWe 'stochastically train' simultaneously \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsup\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2^{|NN|}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.888em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.888em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e∣\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eNN\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e models,where \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e|NN|\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10903em;\"\u003eNN\u003c/span\u003e\u003cspan class=\"mord\"\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e is the network size.\nThus at the end of training we may pretend we have \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmsup\u003e\u003cmn\u003e2\u003c/mn\u003e\u003cmrow\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi\u003eN\u003c/mi\u003e\u003cmi mathvariant=\"normal\"\u003e∣\u003c/mi\u003e\u003c/mrow\u003e\u003c/msup\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003e2^{|NN|}\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.888em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord\"\u003e\u003cspan class=\"mord\"\u003e2\u003c/span\u003e\u003cspan class=\"msupsub\"\u003e\u003cspan class=\"vlist-t\"\u003e\u003cspan class=\"vlist-r\"\u003e\u003cspan class=\"vlist\" style=\"height:0.888em;\"\u003e\u003cspan style=\"top:-3.063em;margin-right:0.05em;\"\u003e\u003cspan class=\"pstrut\" style=\"height:2.7em;\"\u003e\u003c/span\u003e\u003cspan class=\"sizing reset-size6 size3 mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e\u003cspan class=\"mord mtight\"\u003e∣\u003c/span\u003e\u003cspan class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\"\u003eNN\u003c/span\u003e\u003cspan class=\"mord mtight\"\u003e∣\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e candidate models. That is, we can drop any number of nodes and still have a model.\nNow, ideally, on inference time, we may :\nFor each subset of nodes, disable them, and predict on the basis of the rest, and then take the average.\nBut this is obviously infeasible.  So we approximate their 'model average' by \u003cstrong\u003emultiplying the weights by \u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ep\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ep\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\"\u003ep\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/strong\u003e.\u003c/p\u003e\n\u003c/div\u003e\u003c/div\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eChildren\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/PublicPersonalKnowledgeBase/notes/ytp3nmwv2nmc0tum4472bba\"\u003eDropout\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e","noteIndex":{"id":"wn8PE1RhG0znK1alrGFYv","title":"Root","desc":"","updated":1647507231129,"created":1631901573363,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"db285659ccac8b133c384de1ef51de66","links":[],"anchors":{"welcome-to-stefans-notes":{"type":"header","text":"Welcome to Stefan's Notes!","value":"welcome-to-stefans-notes","line":7,"column":0,"depth":1}},"children":["mxzxxu8z4e6krz99ht96y9d","W1EOZ27Tqx6RbiA2aW3DI","DyoLE2kwm9rRfRZhBGxPW","idhfogizmtcmvaamtalp3o3","4w8wBCSRvYUnGIZeozW03","vB321AipYCs6ldVC0APs9","h6WVdl1UTWVXeWuMJSZ1f","bth6m0exy9q9loxib1mc4al","4abAmH56ausbldEJbZokx","JyOFJ5NTPSVWMfiDy951X","0OO7fjCpcaGZg5qDRZr8z","138666663","pohXgII67dAxnoufG7yAP","6hs48bnjnaoxahk07exj74u","42r6290iqzLPmg9BY7fIp","3hoLerNJHjNkDziIKlFF2","T6meT3UNw0nRorEbzoPSl","hIOTXIIBj3vmhG1xc91lA","tnFlQuOAGPkbU2fZI7Cb1","Jb3w3f4x8kixLhrjUW6S1","LV6q5jlD2xtCF6yYFEqFC","ENDcCZFjAW9h66eDoFg7I","b5IeREnsTbeggC7rmWV0p","2hmbhdzcdljtdwln762gcrv","z9la6u9t3xueldj2omf2gc6","9akeo93l6b026jmu4t6e7pw","sc24o4jglr9jg29qr5v0e44","0mt5ao8tbbz3z5mdwe0aer8","r7rvb6nal69nfb6ogqdadnm","xujx5iuxskj10o0ajpi109n","lyl1rzqz6zwcswpwh0kafrm","skpw697vlqdq3t3uqxpq5e3","a4tts3oc3oms7wuralrbzdc","13a1ufqh6o8yi9evw1u5kv5"],"parent":null,"data":{},"body":"# Welcome to Stefan's Notes!\n\n        \n\nLast updated: 2021.12.30\n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableUserTags":true,"enableHashTags":true,"dendronVersion":"0.95.0","enableEditorDecorations":true,"enableFullHierarchyNoteTitle":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","assetsPrefix":"/PublicPersonalKnowledgeBase","siteUrl":"https://petrovs12.github.io","duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"theme":"light","templateVersion":"0.97.0","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"DXLiLGTveXMnlFQGLKG3b"},"buildId":"d47oHCd-7QAOR5IvSuJke","assetPrefix":"/PublicPersonalKnowledgeBase","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>