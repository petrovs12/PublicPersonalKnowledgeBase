{"id":"0eavyyB1FV31znYjoX6hE","title":"Attention Mechanisms","desc":"","updated":1646244441357,"created":1644708670411,"custom":{},"fname":"science.stats.Deep Neural Networks.Attention Mechanisms","type":"note","vault":{"fsPath":"vault"},"contentHash":"7edb9f997307a9d9b4ad16703462d84a","links":[{"from":{"fname":"science.stats.Deep Neural Networks.Transformers","id":"wBdAtrMgIGaoliZx7AL58","vaultName":"vault"},"type":"backlink","position":{"start":{"line":2,"column":18,"offset":18},"end":{"line":2,"column":77,"offset":77},"indent":[]},"value":"science.stats.Deep Neural Networks.Attention Mechanisms"},{"from":{"fname":"science.CS.theory.NLP.Sequence To Sequence Modelling","id":"e19xez30674v61vgdmj2wyp","vaultName":"vault"},"type":"backlink","position":{"start":{"line":17,"column":1,"offset":391},"end":{"line":17,"column":60,"offset":450},"indent":[]},"value":"science.stats.Deep Neural Networks.Attention Mechanisms"}],"anchors":{"bahnadau-attention-mechanism":{"type":"header","text":"Bahnadau Attention mechanism","value":"bahnadau-attention-mechanism","line":9,"column":0,"depth":1},"transformer-tutorial-from":{"type":"header","text":"Transformer Tutorial from","value":"transformer-tutorial-from","line":40,"column":0,"depth":1},"rnn-recap":{"type":"header","text":"RNN Recap","value":"rnn-recap","line":43,"column":0,"depth":3},"attention-networks":{"type":"header","text":"Attention Networks","value":"attention-networks","line":53,"column":0,"depth":2},"attention-variants":{"type":"header","text":"Attention Variants","value":"attention-variants","line":81,"column":0,"depth":3}},"children":[],"parent":"1oUqI7ql4EuPu9Ml94Xe1","data":{}}
