{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Business","n":1},"1":{"v":"\n Some stuff from the [Organic Growth Playbook](https://www.amazon.com/Organic-Growth-Playbook-Extraordinary-Results-Every/dp/0877573689).\n","n":0.354}}},{"i":2,"$":{"0":{"v":"Root","n":1},"1":{"v":"# Welcome to Stefan's Notes!\n\n        \n\nLast updated: 2021.12.30\n","n":0.354}}},{"i":3,"$":{"0":{"v":"Meet","n":1}}},{"i":4,"$":{"0":{"v":"2022","n":1}}},{"i":5,"$":{"0":{"v":"05","n":1}}},{"i":6,"$":{"0":{"v":"19","n":1},"1":{"v":"_Edit the [[dendron.templates.meet]] to change this template generated for Dendron Meeting Notes._\n\n## Attendees\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- @JohnDoe\n- @StefanPetrov\n\n\n## Goals\n<!-- Main objectives of the meeting -->\n\n## Agenda\n<!-- Agenda to be covered in the meeting -->\n\n## Minutes\n<!-- Notes of discussion occurring during the meeting -->\n\n## Action Items\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- Follow Up Task 1\n- Follow Up Task 2\n","n":0.099}}},{"i":7,"$":{"0":{"v":"Evening","n":1},"1":{"v":"_Edit the [[dendron.templates.meet]] to change this template generated for Dendron Meeting Notes._\n\n## Attendees\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- @JohnDoe\n\n## Goals\n<!-- Main objectives of the meeting -->\n\n## Agenda\n<!-- Agenda to be covered in the meeting -->\n\n## Minutes\n<!-- Notes of discussion occurring during the meeting -->\n\n## Action Items\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- Follow Up Task 1\n- Follow Up Task 2\n","n":0.099}}},{"i":8,"$":{"0":{"v":"Dendron","n":1}}},{"i":9,"$":{"0":{"v":"Templates","n":1}}},{"i":10,"$":{"0":{"v":"Meeting Notes Template","n":0.577},"1":{"v":"_Edit the [[dendron.templates.meet]] to change this template generated for Dendron Meeting Notes._\n\n## Attendees\n<!-- Meeting attendees. If you prefix users with an '@', you can then optionally click Ctrl+Enter to create a note for that user. -->\n\n- @JohnDoe\n\n## Goals\n<!-- Main objectives of the meeting -->\n\n## Agenda\n<!-- Agenda to be covered in the meeting -->\n\n## Minutes\n<!-- Notes of discussion occurring during the meeting -->\n\n## Action Items\n<!-- You can add any follow up items here. If they require more detail, you can use `Create Task Note` to create each follow up item as a separate note. -->\n\n- Follow Up Task 1\n- Follow Up Task 2\n","n":0.099}}},{"i":11,"$":{"0":{"v":"User","n":1}}},{"i":12,"$":{"0":{"v":"StefanPetrov","n":1}}},{"i":13,"$":{"0":{"v":"JohnDoe","n":1}}},{"i":14,"$":{"0":{"v":"Test","n":1}}},{"i":15,"$":{"0":{"v":"Mics","n":1},"1":{"v":"\n\n\n![](/assets/images/2022-04-10-10-30-31.png)\n![](/assets/images/moo.exalidraw.svg)\n\n![](/assets/images/test_excalidraw.svg)\n\n\n","n":1}}},{"i":16,"$":{"0":{"v":"Stats","n":1}}},{"i":17,"$":{"0":{"v":"Sampling","n":1},"1":{"v":"\n# Univariate Sampling\n[Inverse CDF sampling Method](https://blogs.sas.com/content/iml/2013/07/22/the-inverse-cdf-method.html)\n\n# Mutlivariate Gaussian Sampling\n\n[Faster Gaussian Sampling](https://www-users.cse.umn.edu/~saad/PDF/ys-2013-3.pdf)\n","n":0.302}}},{"i":18,"$":{"0":{"v":"Bootstrapping","n":1}}},{"i":19,"$":{"0":{"v":"Data Science and ML Process","n":0.447},"1":{"v":"\n```mermaid\ngraph LR;\n\na[Data Collection] -->b[Data Preparation] --> c[Model Training] --> d[Model Evaluation/Selection] --> e[Model Persistence]\nreq[Requests]-->ms[Model Serving]\nms-->ml[Model Logging]\nms<-.->g\nms<-.->f\n\n\n\n\n\nb-->f[Feature Store]\nc-->g[Model Store]\n```\n\n\n\n# Data Science Process Diagram\n","n":0.213}}},{"i":20,"$":{"0":{"v":"Statistics","n":1}}},{"i":21,"$":{"0":{"v":"Mixture Models","n":0.707},"1":{"v":"\n# Mean and Variance of a Limear Combination of Random Variables\n\nUnder independence assumptions, if we have $N$ random variables $X_i$ with means $\\mu_i$ and variances $\\sigma_i^2$, and non-negative weights $w_i$, then the mean and variance of a linear combination of these random variables is given by:\n\n$Y = \\sum_{i=1}^N w_i X_i$\n\n$\\mu_Y = \\sum_{i=1}^N w_i \\mu_i$\n\n$\\sigma_Y^2 = \\sum_{i=1}^N w_i \\sigma_i^2$\n\nLet's call the function that takes a list of $mu$ and $sigma$ values and a list of $w$ values and returns the mean and variance of the linear combination `linear_combination_mean_variance`.\n\n# Mean and Variance of a Mixture of Random Variables\n\nUnder the assumptions above,\nthe mean and variance of a mixture of random variables, where the weights sum to 1, is given by:\n\n$\\mu_Z = \\sum_{i=1}^N w_i \\mu_i$\n\n$\\sigma_Z^2 = \\sum_{i=1}^N w_i \\sigma_i^2 + \\sum_{i=1}^N w_i(\\mu_i)^2- (\\sum_{i=1}^N(w_i\\mu_i)^2)$ \n\nNote that the last 2 terms can be interpreted as the variance of the means of the mixture.\n\nLet's call the function that takes a list of $mu$ and $sigma$ values and a list of $w$ values and returns the mean and variance of the mixture `mixture_mean_variance`. We Assume default $w$ parameter be list of $1/len([\\mu])$ of length $len([\\mu])$.\n\n# Splitting a distribution into a mixture with the same mean and variance\n\nLet the distribution have mean $\\mu$ and variance $\\sigma^2$.\nThis can be done by using the equation for the mixture in the following way:\n1. Take as parameters the number of mixtures to split into $L$\n2. As another parameter the target variance of each component in the mixtures $\\sigma_{comp}^2$.\n2. Set the target mean of the means of the mixture be the original distribution mean $\\mu$. That would make the mean of the mixture equal to the mean of the original distribution.\n3. Then we need same for the variance. We will achieve it by taking the variance of the means in the mixture to be:\n$\\sigma^2 = \\sigma_{comp}^2 + Var(means)$. This directly gives us the variance of the means, and we can just sample from them and sort.\nLet the function, implementing this, be called **splitDistribution**($\\mu,\\sigma,\\sigma_{component},L=100$), returning list of means and list of variances, size $L$. \n\n# Modeling 'Mixture of Controls'\n\nLet's have a CS-BQRT batch with relative experiment sizes (as measured by the total SAV in their control segments) \n$s_1, s_2, ..., s_N$., normalized: $\\sum_{i=1}^N s_i = 1$.\n\nThen, imagine somehow we have a proper control on the full CS-BQRT Traffic, and the distribution over it's segments \nhas mean $\\mu_t$ and variance $\\sigma_t^2$.\n\nThen let's imagine we did a split of that distribution like in the previous section, and we got $N=100$ distributions,\nso $[\\mu_{ci}|{i=1..100}],[\\sigma_{ci}^2|{i=1..100}]=splitDistribution(\\mu_c,\\sigma_c,\\sigma_c/2,100)$.\nwhere the 'target variance' is arbitrarly chosen here.\n\n## Proposition 1:\nThe mean and variance of the SAV, obtained by an experiment $i$, would be given by **mixture_mean_variance**(unzip([**linear_combination_mean_variance**[$\\mu_{c_i}$],[$\\sigma_{ci}^2$],[$s_i$])|i = 1..100]).\n\nIn words, to get the SAV distribution for a given experiment, we first down-scale w/ experiment size each individual 'user bundle' we found when we split the original distribution into a mixture, and then we mix together the down-scaled segments.\n\n\n## Proposition 2:\nAs we do this process for each experiment, then we use their linear combination to get the distribution of the SAV for the whole CS-BQRT batch.\n\nWe get the same expected mean as the original distribution, and variance, depending on the level of mixing. \nThe variance would grow for more uniform experiment sizes, and would shrink for more skewed sizes. In the limit of one\nhuge experiment it would grow to the variance of the original distribution (maybe + whatever variance we added when we sampled segments (???)). \n\nThe variance would shrink as we have more and more experiments of the same size, up to a limit.\n\n\n\n\n ","n":0.041}}},{"i":22,"$":{"0":{"v":"Algos","n":1}}},{"i":23,"$":{"0":{"v":"Discrete Fourier Transform","n":0.577},"1":{"v":"[Link from Cp algorithms](https://cp-algorithms.com/algebra/fft.html)\n\n[[science.math.Functional Analysis.Functional Spaces.Bases]]\n\n\ninput:\nPeriodic function $f(x) \\in R$, output: \nan infinite vector with the coefficients of $e^{i\\pi(x/n)}f(x),\\forall n\\in N$ \n\nDiscrete Fourier Transform:\n\n```\nInput:\nset of values\n\nthen pretend there is a function:\nA(i)=A[i]\nand then we get the DFT of that function.\n```\n\nSo effectively we get a representation of the array, pretending it's a function, by figuring out the set of coefficients in some functional space it belongs to.\n\nWhy would we do that?\n:\nWell, the fourier transform is an integral transform, and integral transforms often turn composition operations into pointwise multiplication operations.\n\n\nThat's kind of the point of the fourier transform, as if it's applied to the coefficients of 2 polynomicals, then it allows us to findthe DFT of their product as well as just a pointwise multiplication of the transforms of the 2 polynomials, and then invert...\n\nThen the complexity of this obviously fundamental operation goes from $O(N^2$ to $O(nlog(n)))$.\n\n\n# DFT\n\nA DFT of an array is the evaluation of the polynomial w/ coefs the elements of the array:\n$P(x)=a[0]+a[1]x+a[2]+a[3]x^2+...+a[n-1]x^{n-1}$\n\non the set of the n-th roots of unity:\n$\\{e^{2i\\pi(x/n)}\\}, x=0,1,2,...,n-1$\n\nObviously we can find this by solving a linear equation.\n\n\nHowever, why DFT is quick?\nLet $A$ be a polynomial, and we split it into $A_0,A_1$, such that $A_0$ is the polynomial w/ the evenly-numbered coefficients of A, and $A_!$ is the one with the oddly numbered coefficients of A.\n\n\nThen:\n$A(x)=x^2A_0(x)+xA_1(x)$\nwhere $len(A_0)=len(A)/2$\n\nthen by the [[science.CS.algos.Master Theorem of Algorithmic Complexity]] the complexity of computing A would be $O(nlog(n))$\n\n# [Inverse FFT](https://cp-algorithms.com/algebra/fft.html)\nit's the same, also the Vandermonde matrix pops up here...s\n\n\n\n\n","n":0.064}}},{"i":24,"$":{"0":{"v":"Urban Development And Transportation","n":0.5}}},{"i":25,"$":{"0":{"v":"Youtube Notes","n":0.707},"1":{"v":"\n\n# City Nerd Notes\n\nLargest intersection by numbeqr ofa pproach lanes notes.\nvery long cycles.\nwasted time in a cycle is: yellow light+ 'all reds'. All red is when all lights are red, so starting movements can be completed (synchronization all red).\n\nWhen designign and intersection, you look at about 400 meters radios of where traffic might be coming from and consider this, Including\nshops, drive troughs, residential or commercial properties:).\n\n### equation for waiting time on interesection\n\nDepends on how lond fhte waiting lanes are.\n\n# Satire about the loop\n\n\ns\n\n\n","n":0.11}}},{"i":26,"$":{"0":{"v":"Adam Something","n":0.707},"1":{"v":"\n# Anarcho capitalism \n## First variation- Feudalism and krepostnichestvo\n\n## Theocracy\n\n## Communism\n\n","n":0.302}}},{"i":27,"$":{"0":{"v":"Psychology","n":1}}},{"i":28,"$":{"0":{"v":"Noise (Daniel Kahneman, Oliver Sibony, Cass","n":0.408}}},{"i":29,"$":{"0":{"v":" R Sunstein)","n":0.707},"1":{"v":"\n# What's up with noisy Judgements\n\n# Noise and Bias\n\n# Psychological reasons for noise\n\n## Groups amplifying noise\n\nThings not being i.i.d, but error being autocorrlated (or correlated across the social graph via first-move advantage).\n\nImagine a [[science.engineering.technologies.graphs.Random Graphs#^baGraphs]] graph, and some features related to it.\nE.g. how much a song is liked. Then as new members join, they form a judgement, and the current distribution of the\nmemmbers they attach to, affects this (maybe proportionally to the influence).\nThen the noise is obviously not i.i.d.\n\nChapter 8 of Kahneman's book.\n\n\nIf a song benefited from **early success, it could do very well**. \n\n\nLevel of success in the social influence condition was **more unpredictable than in the independent condition**.\n\n**Popularity is self-reinforcing**, so it's **manipulatable**.\n\n**Vote manupulation** by telling people what's already **popular**.\n\n### Illusion of Agreement\n\nIf no noise audit, people in a company get checked while they are apprentices, but\nwhen they get more experience, they start believing their own hype and 'expertise'.\n\nAt the same time there might not be agreement at all.\n\n# Noise in various decisions \n\n* Judges give different verdicts for the same case.\n* Medical professionals too.\n* Also, on different days\n\n\n# Causes of Noise\n\n\n# Singular decisions\n\nIn non-repeated experiments, people assume full determinism and then look for causality retrospectively.\nThat makes it so ppl don't think like they would if they did a repeated experiment.\n\nOne-of-a-kind decisions should be treated the same way as 'repeated' ones.\n\n\n# Occasion noise\n\nE.g. mood affects things a lot.\n\nE.g. Software developers give 70% different time estimates for the same task on 2 consequent days.\n\nVariability in performance things (for the same person) can be caused by variability in their current physical state.\n\n## One is a Crowd\n\nCan sample 'from within'.\nI.e. as people 'tell a story' to interpret something and justify decision, make them think about different features of the same thing, and give a second opinion.\n\n* Guesses from 2nd opinion add more value than asking yourself the same question 'naively'\n* But if you ask yourself 'correctly' you can get about half the 'new information'.\n\n__Dialectical Bootstrapping__\n[[stats.Sampling.Bootstrapping]]\n\n\nEspecially for complex ( ~ high-dimensional) problems.\n\nVul/Pashler:\n__Responses made by a subject are smapled from an internal probability distribution, rather than being generated \nby a deterministic process, taking into account all the knowledge a subject has.__\n\n\nAll of the bellow causes have evidence for affecing judgements.\n* Mood\n* Fatigue\n* Weather \n* Sequencing\n\n**We are not the same person at all times and we're less consistent than we think**.\n\n\n##\n\n\n## Sources of OCcasion Noise\n\n* Mood\n  [[Psychology.First Impression Bias]] Good Mood amplifies this\n\n\n\n# Your mind as a measurement instrument\n\n\n\n# Predictive vs Analytical Judegements\n\n## Judgements and models\n## Noiseless rules\n\n\n# Decomposing Noise\n\n## Bias-variance, and others\n\n\n\n# Why not reduce Noise to 0\n\n* People feeling like cogs\n* Some non-determinism makes people feel like they're not failures (e.g. like luck in games)\n## Rules vs standards\n\n\nKeep values and facts separate...\n\n\n# Legal System Noise\n\n## Level Error\nMixed effect models- each judge has a different \"constant\" to draw from...\n\n## Pattern Noise\n\nEach type of case has a different 'constant' to draw from.\nI.e. variance comes from both the item, and the user:\nMaybe smiliar to\n\n[Item Response theory models...](https://mc-stan.org/docs/stan-users-guide/item-response-models.html)\n\nThe noise here is in the coefficients\n\n[[science.stats.Mixed Effect Models]]\n[[science.stats.Bayesian Framework]]\n\n$\\text{System Noise}^2=\\text{Pattern Noise}^2+\\text{Level Noise}^2$\n\nTo summarize:\n\n* __Level Noise__ is variability in average judgement of judges.\n* __Pattern Noise__ is variability for a particular case across Judges.\n\n\n\n# KNN and Noise\n\nImagine you are a judge and have to judge a case.\nThen you might use a KNN type approach, drawing on your experience + knowledge.\n\nBut now, it's a high dimensional thing.\nIn KNN sparse regions are noisy.\n\nBut if you:\n1. Sample experience across judges (cases/rows)\n2. Sample values across judges (case features/columns)\n\nand then use KNN, you can get a lot of 'pattern' noise (as per the classification above).\n\n\n\n\n# How noise happens\n\n## Matching 'Story' to Number s( Part IV)\n\nLots of noise there.\n\n## Heuristics, Bias, Noise\n\nAnother type of 'group' contagion.\nHistorical reasons, different [[science.math.Optimization.Objective Functions]] maybe?\n\n\n\n##\n\n","n":0.04}}},{"i":30,"$":{"0":{"v":"Social Loafing","n":0.707},"1":{"v":"Reduce Motivation when working in groups. The **more anonymous** one gets, the **stronger the effect**.\n","n":0.258}}},{"i":31,"$":{"0":{"v":"Moral Judgements","n":0.707},"1":{"v":"\n\n# Hijacking Disguist Circuitry for Moral Judgements\n\nE.g. ppl, who are somewhat disgusted by observing gay PDA conflate this with it being morally wrong/needs to be forbidden.\n\n","n":0.196}}},{"i":32,"$":{"0":{"v":"Mood","n":1},"1":{"v":"\n\n[[Psychology.Moral Judgements]]\n\n[[Psychology.First Impression Bias]]\n\n\n[[Psychology.Bullshit]]\n\n\n\n\nWeather can affect moral judgements trough mood (Noise book page 89).\n\n\n","n":0.267}}},{"i":33,"$":{"0":{"v":"First Impression Bias","n":0.577},"1":{"v":"\n\nIt takes much more time to disagree with a statement (neurologically), than to agree.\nThe circuit for agreeing is faster.\n\nAplified by good mood.\n\nGullability.\n\nSome evidence about \n\n\n[[Psychology.Bullshit]] Reciptivity increases with good mood...\n\n","n":0.183}}},{"i":34,"$":{"0":{"v":"Bullshit","n":1},"1":{"v":"\n[Book](https://www.amazon.de/-/en/Harry-G-Frankfurt/dp/0691122946/ref=sr_1_1?crid=1W2GS4ORSTLVA&keywords=auf+bullshit&qid=1658053117&sprefix=statistical+%2Caps%2C292&sr=8-1)\n\n\n[Trump and Bullshit](https://www.youtube.com/watch?v=WlkIpfc75s0)","n":0.577}}},{"i":35,"$":{"0":{"v":"Philosophy","n":1}}},{"i":36,"$":{"0":{"v":"Cognitive Biases","n":0.707}}},{"i":37,"$":{"0":{"v":"Neural Networks","n":0.707}}},{"i":38,"$":{"0":{"v":"Activation Functions","n":0.707},"1":{"v":"\nFollowing [Statistical View Of Deep Learning](http://www.cs.columbia.edu/~blei/seminar/2020-representation/readings/Mohamed2015a.pdf)\n\nWe have the activation functions in another section\n\n![[science.stats.Regression.Loss Functions.Activation Functions]]","n":0.258}}},{"i":39,"$":{"0":{"v":"Tags","n":1}}},{"i":40,"$":{"0":{"v":"Queuing_theory","n":1}}},{"i":41,"$":{"0":{"v":"Evernote_link","n":1}}},{"i":42,"$":{"0":{"v":"Archive","n":1}}},{"i":43,"$":{"0":{"v":"TODO","n":1}}},{"i":44,"$":{"0":{"v":"DifferentialEquations","n":1}}},{"i":45,"$":{"0":{"v":"Seed","n":1},"1":{"v":"\n\nThis is a page. Plant it and watch it grow.\n\n[[seed.child]## Index\n- [[Child|seed.child]]]","n":0.289}}},{"i":46,"$":{"0":{"v":"Child","n":1},"1":{"v":"\nThis is a child of the seed page\n","n":0.354}}},{"i":47,"$":{"0":{"v":"Product Management","n":0.707}}},{"i":48,"$":{"0":{"v":"UX Research and KPI's","n":0.5},"1":{"v":"\nSee also [[seed.Product Management.Product School Book#^companygoals]]\n\n[HEART framework by Google](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36299.pdf). ^heart\n\n HEART framework:\n\n\nH(appiness) --- how happy customers are\nE(engagement) - how long do they stay on the site\nA(doption)\nR(etention)\nT (task success)  - how they succeed in certain tasks\n\n\n---\nPULSE metrics:\nP(age views)\nU(ptime)\nL(atency)\n","n":0.164}}},{"i":49,"$":{"0":{"v":"Target Customers","n":0.707},"1":{"v":"\n\n# ![[seed.Product Management.Personas]]","n":0.577}}},{"i":50,"$":{"0":{"v":"Strategic Understanding of The Company","n":0.447},"1":{"v":"Notes from 2nd chapter of __The Product Book__.\n\n# What product are we building?\n\n\n# Why does the company exist?\n\n[Start with Why](https://www.youtube.com/watch?v=qp0HIF3SfI4&ab_channel=TED)\nThere's a book as well.\n\n##  _Why_  is guiding light\n\nIf the product is told as a story, __why__ is the theme.  \n\nWhat is the story about?\n\n__Mission Statement__\n\n__why->how->what__\n\nStart with raison d'etre, then figure out how it would be achieved, and finally __what__ to build.\n\n#NB The order of __how__ and __what__ in this context is different than when thinking aobut requirements and implementation details.\n\n### Apple examples:\n* If starting with 'what :“We make great computers. They’re user-friendly, beautifully designed, and\neasy to use. Want to buy one?” That’s fine, but it sounds pretty generic.\nMany other PC manufacturers even make the same claim!\n\n* if starting with 'why': “With\neverything we do, we aim to challenge the status quo. We aim to think\ndifferently. Our products are user-friendly, beautifully designed, and easy\nto use. We just happen to make great computers. Want to buy one?\n\nThe 2nd one is supposedly more useful to guide product decisions.\n\n# Bad Missions\n## Revenue goal\n\nCompany would fail, cause it's backwards. You bring value and then get the revenue. Goal is to make customer awesome.\n\n\n### Revenue is a Validation/Metric\n\nNot a goal by itself.\n\n\n## Solution looking for a problem\n \n Companies that start not with a mission, but some invention they're trying to sell, would have a harder time.\n By itself an invention is not a product- products are solutions to problems people encounter.\n\n 'Pivoting' often happens in such cases, as a company tries to repurpose whatever it has built in order to find customers who will buy it.\n\n## No mission statement\n\nSuch company could be moderately successful, but may be hard to grow, as it's not clear what the product line is about. \n\nThus subsequent products may feel disjointed, may start to solve too many different problems, etc.\n\nFor many of the in the [[#^5C]] analysis you wouldn't be able to produce specific enough answers.\n\n\n### __Figure out at least a common implicit/latent value proposition.__\n\nIf we have some products that are hitting, we can cobble together a mission statement ad-hoc by looking at a common value proposition/theme/etc.\n\nMisfit example w/ wearables.\n\n# [[seed.Product Management.Target Customers]] and  [[seed.Product Management.Personas]]\n\n# Personas\n\n![[seed.Product Management.Personas]]\n\n\n# Adopter Curve\n\n```mermaid\ngraph LR;\na[Investors]-->b[Early Adopters]--Adoption gap-->d[Early Majority]-->e[Late Majority]-->f[Laggards]\n```\n\nMust jump over adoption gap before being able to get mass market adoption\n\n# Make Realistic Personas, get under their skin\n\nCommon mistake is to define personas 90% by demography, 10% by wants/needs/emotions.\n\nImagine a persona, say Jill, who's thinkuing about buying her first car.\n\nWhat does she care about? Fuel efficiency? Up-front cost? New/used? Making a statement? Does Jill enjoy the research process or just wants to be pointed at the right direction?\n\nHow deep does she go while comparing things?  \n\n\n## Anti-Pattern: 3d glasses for home cinema\n\n3D movies performed well, but at-home watching experience is more of a social activity than crowded and darkened theater.\n\nThus, the 3D glasses are goofy and party-pooper.\n\nPut yourself in the place of the **persona**, empathising deeply.\n\n\n\n\n\n#  Use Cases\n\nDefinition:\nHow would the **persona** use the product to achieve a goal?\n\nA sufficiently detailed answer of that question is a **use case**.\n\n\n\n\n\n\n# Enterprise vs Consumers\n\nKey difference between an enterprise-centric and consumer-centric product is that in enterprise, the buyer and user are different personas. \n\nHistorically, B2C was more focused on UI, as this is not people's job and they should be onboarded as painlessly as possible.\n\nFor B2B, functionality has been more important. However, now B2B products also pay a lot of attention to the user experience.\n\nB2B has more complex needs: additional legal requirements, multiuser environments and so on.\nE.g. on-premise solutions vs cloud, different security things, licensing, etc.\n\n\n\n\n# How to measure if product is good\n\nTask success, [[seed.Product Management.Product Metrics]]\n\n# Vanity Metrics vs Actionable\n\n Some metrics can be Investor BS. For example, monthly active users (who in reality just log in and out).\n\n\n## Measuring Metrics\n\n[[engineering.Google Analytics]]\n\n## Net Promoter score,e tc\nSurvey and ask 'how likely are you to recommend this product to a friend?'\n\nRemove 'typical scores'. Call people of high scores 'promoters' and people of low scores 'detractors'.\n\n$NPC = \\frac{numPromoters-numDetractors}{TotalVoters}$\n\n## What's the rest of product portfolio\n\n## Roadmap\n\n## Competition and Climate\n\n\n\n\n# Company Context ^5C\n5C:\n* Company\n* Customers\n* Collaborators\n* Competitors\n* Culture/Climate - macroeconomics or cultural things that are current\n","n":0.038}}},{"i":51,"$":{"0":{"v":"Software Development Methodologies","n":0.577}}},{"i":52,"$":{"0":{"v":"Selecting Projects","n":0.707}}},{"i":53,"$":{"0":{"v":"Product School Book","n":0.577},"1":{"v":"\n\nSummary of [Product Book](https://www.amazon.de/-/en/Product-School/dp/0998973815/ref=sr_1_1?crid=24YZRAKE14LBZ&keywords=das+produkt+buch&qid=1647470234&sprefix=sennheiser+450bt+battery%2Caps%2C92&sr=8-1)\n\n# Product Manager Role\n\n**Understand what game the company is playing and how to keep score**\n\n\n\n\nNobody Asked you to show up!\n\nEngineers build, designers design, marketers make sure people know about it, sales sales, product managers do what?\n\n\n## Justify your existence.\n\n\n\n\nPM Parts:\n1. Idenitfy opportunities- hypothesise\n2.  Design Iteration\n\n\n1. Identity right opportunity.\n2. Build it\n3. Be a **Mini CEO**\n4. Feature subsetting: Once the goal is clear, everybody has many ideas. Your part is to decide which one to keep.\n5. Trade-off technical debt for pushing things forward. \n6. Pay the technical debt so project doesn't become stuck in inability to execute further.\n\n\n## Key skills\n\nTechnical, communication, industry expertise.\n\nTriangle of\n\nEngineering, Product Management, Design, Marketing.\n\n### How technical? \nSomewhat - know how not to be lied to and how to not lie to themselves vis-a-vis technical topics.\n\n### How business-oriented? \n\nKnow industry; how businesses make money? What are key players, competitors? What differentiates our company to theirs.\n\n## Types\n\nProduction Product Manager- internal, focusing on having things build\n\nMarketing PM- more external, focused on making sure ppl know about product.\n\n\n\n\n\n\n\n\n\n### Customer Representative\n\nCustomers dont' want to give you money. Customers want to be awesome. You help them be awesome.\n\n#### Company can operate and scale to a point without PM's\n\n\n\n# How do PM's get products built?\n\n## Planning Cadence\n\n### Waterfall\nLots of planning, long execution time.\n\n### Agile\nfast iteration, MVP's ([[seed.Product Management.Minimum Viable Product]])\n\n### Hybrid (recommended)\n\nMedium planning beforehand to identify opportunity, then fast iteration w/ MVP's\n\n## Product Development Lifecycle\n\n1. Finding and Planning the Right Opportunity\n2. Designing the Solution\n3. Building the Solution\n4. Sharing the Solution\n5. Assessing the Solution [[seed.Product Management.Product Metrics]]\n\n\n### Planning and Opportunity hypothesis\n\n#### **What is the right thing to work on next?**\n\nThe core part of the job.\nBroken down to:\n\n* [[seed.Product Management.Strategic Understanding of The Company]]\n 1. Team Capabilities\n 2. User Needs - be focused\n \n* Create [[seed.Product Management.Opportunity#^create]]\n* Validate [[seed.Product Management.Opportunity#^validate]]\n\n\n### [[seed.Product Management.Product Metrics]]\n\n\nSelect proper metrics.\n\nConsider Company goals, culture, capabilities to filter opportunities.\nAsk yourself 'Why does the company exist??'\n\n\nAfter identifying the right opportunity, you need to [[seed.Product Management.Opportunity#^validate]] validate it.\n\nAfter validating, need to turn it into something build-able.\n\n\n\n## Product Goals ^companygoals\n\nSee Also [[seed.Product Management.UX Research and KPI's#^heart]]\n\nBroadly, product goals could be in 3 main categories:\n1. Revenue: \nHow does the company currently monetize it's products? How do you make them more valuable to customers to make them more willing to pay for the product.\n \n2. User Satisfaction : do you want users to be happier\n What can you deliver that they would love, but couldn't expect?\n\n3. Growth : Do you want more customers\n What's stopping the customers from using the product? What is lacking in the product to reduce friction?\n\nIn addition, a company should consider it's context, i.e. what it excels at, what it can't do as well, what it's competitors are doing and what is the market share.\n\nThis is covered in: \n[[seed.Product Management.Strategic Understanding of The Company]]\n* What is the company building now?\n\n* Who are the key customers you want to solve a problem for?\n\n* What do you excel at, compared to it's competitors?\n\n* What's the company vision, and more importantly, why does the company exist?\n\n## Creating Oportunity Hypothesis \n\nHow to get good ideas?\n\n[[seed.Product Management.Opportunity#^hypothesis]]\n\nCurrent [[seed.Product Management.Product Metrics]] could help you identify the right opportunity.\n\n\n\nLook at the metrics to on how users are using the product. What are they engaging with?\nDoes this contradict with data from surveys?\n\nFor example, it might be that in a CNN app users engage more with videos that text articles. Maybe they watch the whole video,\nbut dont' scroll down as much. This is an __opportunity__ to make them engage more with the content (and show more ads).\n\n### Scoping and [[seed.Product Management.Minimum Viable Product]] ^scoping\n\nDefine goals and non-goals.\nClearly define the opportunity, customers you want to target (and don't want to target), and product requirements .\n\n\nExample:\n\nOpportunity:\n\nBuild a Pen\n\nCustomers:\nStudents\n\nNon-goals\nI don't need it to work in space or underwater? But it's good if it works upside-down?\n\n\nCreate [[seed.Product Management.Minimum Viable Product]].\n\ncontrast MVP-driven vs waterfall development.\nComment on hardware vs software projects.\n\n[[seed.Product Management.Design Document]]\n\n\n\n\n#### Designing\n\nWireframes, user research [[seed.Product Management.Personas]].\nSurvery, user testing. \nWireframes are clickable, w/ fake data.\nInvestigate layout and information ordering.\n\n### Building\n\nTaking on technical debt- must manage that, considering current needs (i.e. build this now) vs future development\ncadence and flexibility.\n\n\nRelated to\n\n\n* Prioritizing buglss\n* Testing Software\n* Do whatever's needed to help product ship\n\n* **NOT** writing code or telling people what to write.\n* Design might figure out most common use cases, but many edge cases will appear.\n* Find ways to share prototypes/MVP's to get feedback.\n* Negotiate taking on tehcnical debt.\n* New information about technologies/competitor features.\n\n\nBuilding is done when a working product has been tested and is ready to release.\n\n### Sharing the Solution \n\n[[seed.Product Management.Product Marketing]]\n\nLet customers know how the product would help them.\nMore PMM(Product Marketing Management)- externally focused.\n\nEven before [[#scoping-and-seedproduct-managementminimum-viable-product]] you should kno wthe 'why ' of the product. \n\nWhat problem does it solve?\nSuccinctly and effectively communicate what problem is being solved and how it \nhelps the customer **be awesome**.\nStorytelling/[[seed.Product Management.Messaging]]\n\nCNN Example:\n360 VR view- ???\nRather, say 'be on the ground/scene with our reporters!'\n\nAlso, here we plan the release.\n* Plan Beta Test\n*Create marketing assets for web/ads\n* briefing press, launch events, etc\n\nMany things to let people know about the product.\n\n\n### Assessing Solution Impact\n\nAt least 2 Parts\nMost importantly, Product impact:\n* Would you success in hitting [[seed.Product Management.Product Metrics]] targets?\n* assess how the product is being used/recieved by customers, etc.\n\n\n\n'Process' metrics\nAssess how the process went internally and how people feel about it.\n* Postmortem about dev process- how does team feel, are they quitting, tec\n* What are the updates about our (Bayesian) belief in team strength how do we use that to re-assess for the future?\n* Deadlines, budget, etc\n\n\n\n\n# Chapter 2- Strategic Understanding of The Company\n\n![[seed.Product Management.Strategic Understanding of The Company]]\n\n\n# Chapter 3: Creating Opportunity Hypothesis\n\n![[seed.Product Management.Opportunity]]\n\n\n\n\n\n\n\n\n\n* \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Other Resources\n\n[How to develop product sense - blog post](https://www.lennysnewsletter.com/p/product-sense?s=r)","n":0.033}}},{"i":54,"$":{"0":{"v":"Product Requirement Document","n":0.577},"1":{"v":"Same/similar to [[seed.Product Management.Design Document]]\n\nGained bad reputation as long to read and dicataing.\nIn a Lean or Hybrid model of development it's not dictating and set in stone.\n\nIt evolves as \ndata about user testing and how design, development, and marketing are going, arrives.\n\n\n\n\n\nContains:\n\n# Why are we pursuing this opportunity? ^why\n\n# Scoped problem definition ^problem definition\n\n\n# Success Metrics ^ metrics\n[[seed.Product Management.Product Metrics]]\n\n\n\n","n":0.129}}},{"i":55,"$":{"0":{"v":"Product Metrics","n":0.707},"1":{"v":"\n# KPI's, OPS\n\n\n","n":0.577}}},{"i":56,"$":{"0":{"v":"User Based Metrics (Digital Products)","n":0.447},"1":{"v":"\n\nsee also [[seed.Product Management.Product School Book#^companygoals]]\n\n# Impressions\n\n\n# CTR ^ctr\n\n\n# Task Success  ^task_success\nDwell time, not \n\n\n# Active Users ^active-users\n## Daily\n## Monthly\n\n# Depth Of scroll \n\n# User Stickiness\n\n# User Engagement ^engagement\n\n\n# User Feedback\n\n\n# Metrics for non-continuous use\n\n# Jobs/ Partner finding/Search\n\n* Users will use linkedin less/none if they find a job\n* Users will use facebook dating less/nont if they find a partner\n* If search is **not** successful, users will come back to search page and try another link/query.\n\n# User Engagement, task completion etc\n![[seed.Product Management.UX Research and KPI's#^heart]]\n\n# Explicit User feedback on Recommendations ^user-feedback-recommendations\n* clicks ([[^engagement]]\n* likes/hearths/etc \n* report\n* Time spend\n* impression time\n\n","n":0.101}}},{"i":57,"$":{"0":{"v":"Product Marketing","n":0.707}}},{"i":58,"$":{"0":{"v":"Personas","n":1},"1":{"v":"\n\n\nCustomers are actual people who (could) use your product. \n\nPersonas are customer types. Must represent real target market!! \n\n**Don't make personas for non-target markets! **\n\n\nKeep details sparse and focused on what is relevant to the product/use cases.\n\nAlso, 'jobs to be done' based customer segmentation (Clayton Christensen). Great way to build good personas.\n\n# Roman Pichler Persona Template\n\n![From romanpichler.com](/assets/images/2022-03-17-16-58-07.png)\n\nWhen writing, write only stuff that's relevant to your product! Delete rest\n\n* Priorities, related to your product/area of expertise\n* Pain points\n* Imagine customer journey, how do you beat the status quo? I.e., how do you do better than the curren tprocess\n\n## Profiles\n* Name \n* Picture \n* Details\n* Goals \n\nformat. Can do it in google docs/word, or use some specialized persona management tool\n\n\n# Demographics\n\nOverused, use demographic information only if relevant, else use goals/targets/objectives/constraints/feelings/etc.\n\nFocusing on common pain points/objectives/desires segment better than demographics!\n\nTry to make it a real persona.\n\n\n# More Goals, Needs and Constraints than Demographics\n\nOne way to look at it is 'what is this person trying to optimize for? What are their constraints '\n\n\n# Example Personas\n\n## __'EVERYONE' is not a persona__\n\nWay too broad, too vague, not actionable.\n\n\n\n## The 'mom' persona. \n## 2/3-sided marketplaces (AirBnb).  \n### AirBnB example\n\n* Renter \n 'Feel like a local' culture. \n 'Cost'.\n 'Doesn't care about service.'\n\n\n* Host \n\n Figure out motivation for renting the place. \n 1. Sharing couch/room.\n\n  Maximize revenue.\n\n2. Retired couple, renting out vacation home.\n\nPrefer longer stays and people who would treat place as their own.\n\n* Persona Business Traveller (__non-target__)\n\n  1. There to work, not 'feel like a local'.\n  2. Favor service and convenience over saving costs, connecting with host, etc.\n  3. Costs are discounted by various discounts, aimed at corporate customers.\n\n  So the business travelers will not be the best customers for AirBnb.\n\n### DoorDash - 3 sided marketplace\n\nSee [[engineering.system_design,,Ml System Design.Doordash Talk#^usergoals]]\n\n## B2B\n\nThe buyer and customer are different personas. E.g.\n * CEO vs HR/Ops persona.\n * Parent vs Child Persona\n\n\n##  Mom\n\nCan my mom use it? Middle aged person, who's not a technology early adopter.\n\n\n## Accounting/Business \n###  Multinational Tom\n Simple accounting/office/shift management software might not have all features \n Tom needs, e.g. management of different offices, tax systems, etc.\n\n Can tolerate bad UI, as staff's job is more specialized and they can learn it.\n\n###  Gill Small Business Owner\n\nDoesnt' need all features Tom might need __AND__ doesn't want to be especially trained to use a software that supports them all.\n\nCan't tolerate bad UI as she needs to run the whole business..\n\n## Very Busy Persona\n\nIf the persona you're targeting is very busy, beside solving the pain point, usage  should require __no training__.\n\n\n\n# Use Cases\n\nHow would a a given persona use the product to solve a specific problem?    \n\n\n\n## Multiple Personas\n\n","n":0.048}}},{"i":59,"$":{"0":{"v":"Opportunity","n":1},"1":{"v":"\n\n\n# What is Opportunity Hypothesis ^hypothesis\n\n## You have opinions, not facts\n\n## 'Average' fallacy.\n* People think they are 'average' in the sense they are the 'mode' of the distribution on a given topic. Therefore if they want something, many other people would want it too.\n\n\n## Testing ideas\n Amazon tests all ideas, <50% of even very good 'first principle' ideas fail\n\nWhat does it mean to __fail__? To not move the metrics you set out in the beginning in the desired direction.\n\n* Have to figure out we're wrong __quickly__.\n* An idea could be **good**, but not helpful for you or your customers.\n* Businesses that start with the business plan and product development, rather than __validate__ their fundamental idea, tend to fail.\n*\n\n\n\n\n\n# Creating an Opportunity Hypothesis ^create\n# Validating and Prioritizing an Opportunity Hypothesis ^validate \n## Internal Discussions\n\n## Guided Interviews\n\n\n## Surveys\n\n## Bug Reports and Data Analysis\n\n\n\n\n\n\n\n\n","n":0.084}}},{"i":60,"$":{"0":{"v":"Minimum Viable Product","n":0.577},"1":{"v":"\n\nDefinition: A Minimum Viable Product (MVP)  is the most minimally featured thing you can build that will address the [[seed.Product Management.Opportunity]] for most of the [[seed.Product Management.Target Customers]] .\n\n\nMVP should be focused, very good at what it does, and not doing too  much!!!\n\nSometimes, First MVP should be very hacky, human powered and not\nautomated (e.g. solved-by-hand instances.)\n\n\n\n# CNN example\n\nCore functionality.\n\nHybrid mode- add a few key features to current product, and show that as a MVP( to the product).\n\nCan work only on some limited isntances.\n","n":0.11}}},{"i":61,"$":{"0":{"v":"Messaging","n":1}}},{"i":62,"$":{"0":{"v":"Lean Startup","n":0.707}}},{"i":63,"$":{"0":{"v":"Funnels","n":1},"1":{"v":"\nSequential grouping of activities.\nExample:\n\n```mermaid\ngraph LR;\n\nA[Click at Product Page]-->B[Add to Cart]-->C[Purchase]-->D[Don't return]\n\n```\n","n":0.302}}},{"i":64,"$":{"0":{"v":"Fairness","n":1},"1":{"v":"\n[One definition towards the bottom here](https://docs.google.com/document/d/12n_lUxZEiv_ve0VIkkqwmYLpRZttPSzeE1nzOWqFj-Q/edit?usp=sharing)\n\n[It seems it's already a developed field...](https://en.wikipedia.org/wiki/Fairness_(machine_learning)#Fairness_criteria_in_classification_problems)\n","n":0.289}}},{"i":65,"$":{"0":{"v":"Design Document","n":0.707},"1":{"v":"\nSame as [[seed.Product Management.Product Requirement Document]].\n\n","n":0.408}}},{"i":66,"$":{"0":{"v":"Case Studies","n":0.707}}},{"i":67,"$":{"0":{"v":"Facebook Marketplace","n":0.707},"1":{"v":"\n\n# Facebook Marketplace\n\nIt's a 2-sided market. Anyone can buy(find items) and sell items(+ attract buyers).\n\n# Metrics, Story ^\n\n[[seed.Product Management.Product School Book#^companygoals]]\n\nFacebook Mission- create community and bring people closer together.\n\nTechnology- discover items, buy items; accessible to everyone.\n\nMain goal- allow ppl to buy and sell products...\n\nFirst goal-engagement\n## Engagement ^engagement\nHow are people using it and getting value.\n\n## Secondary goals\n revenue?\n\n# What does success look like?\n\nThink about cannibalization of products, i.e. how does this product play w/ other commerce initiatives in Facebook.\n\nActive users- e.g. weekly active users.\n\nDefinition of 'active'.\n\n\n\n\n## Buyer-oriented metrics \n\nDefinition on Active: Clicking, gase, messaging to seller\n\ne.g. active user clicks on a post at least one\n\n\n## Seller-oriented metrics\n\nPost an item for sale...\n\nDo we know if transaction happens?\nMessage history, in-person interaction, de-listed.\n\nTotal number of sales.\nProxy metric for transaction- listings w/ a bunch of back and forth messages.\n\nDe-listed item/mark as sold, ask them.\n\nEven distribution of demography using it (i.e. not so many professional shops use it).\n\nTime spent per user (but conflict with task success). \n\n\n\n\n\n","n":0.079}}},{"i":68,"$":{"0":{"v":"Doordash On-Demand Logistics","n":0.577},"1":{"v":"\n3- sided marketplace\n\nMerchants, eaters, drivers.\n\nEaters-drivers:\nBalance supply-demand, use levers, such as dynamic pricing (duh).\n\n# Dispatch type problems\n\nCore engine that powers fulfillment. Core assignment (match drivers to deliveries).\n\nHigh-level goal- fast and efficient deliveries. \n\n\n# Steps\n## Balance Supply and Demand\n\n## Route Planning\n\n\n\n## Matching\n\n\nSo they first balance the marketplace in general, then decide on fulfillment routes, order batching, etc.\nThen assign route sets to drivers, basically...\n\nIs it real time. First, the supply-demand balance has a planning horizon of a week.\n\nContinue to update predictions as we go.\n\n# Actions\nPricing, messaging to drivers, incentives (pricing).\n\n# Core Matching happens on the fly.\n\n\n\n\n\n\n\n\n","n":0.104}}},{"i":69,"$":{"0":{"v":"Deliveroo Notes","n":0.707},"1":{"v":"\n\n\n\n[Notes about how delivery companies make money](https://docs.google.com/document/d/1cy6XRKE8PTg5cuaIiMDJClLe5JKJ6_5T425qMnfJMnk/edit)\n\n\n\n\n\n## Deliveroo Business Sense Questions\n\n*Which markets/cities should we enter next? \n\n• How should we improve our consumer, rider, and restaurant apps? \n\n• How can we incentivise good rider behaviour? \n\n• What is the business impact of exclusive deals we have with restaurants? \n\n• How do we best optimise our compensation policy to keep our customers happy and ordering with Deliveroo? \n\n• How does a new competitor’s entry into one of our markets affect our growth ambitions? \n\n• Can the food delivery market sustain multiple players? \n\n• What are the trade-offs we face when choosing between growth and profitability? How should we decide between them? \n\n• How should we make investment decisions company-wide? \n\n• How should we decide which rider to assign to a given order? \n\n• Which restaurants should we show a given customer? \n\n• What is the optimum selection and variety of restaurants in a particular area? \n\n• What impact do online reviews have? \n• How will a change in the user interface affect customer choice behaviour?\n\n![](/assets/images/2022-03-17-10-32-45.png)\n","n":0.076}}},{"i":70,"$":{"0":{"v":"Augmented Reality","n":0.707},"1":{"v":"\n# Curated List\n[Awesome-AR on Github](https://github.com/dharmeshkakadia/awesome-AR)\n\n__Click on the Videos There___\n# Use And Business Cases\n\n\n[Mckinsey Report-2017](https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/augmented-and-virtual-reality-the-promise-and-peril-of-immersive-technologies)\n\n\n[Baye Report on Customer Experience Based Tools](https://www.bain.com/insights/customer-experience-tools-augmented-or-virtual-reality/)\n\n\n\n[The economist has a bunch of articles on VR](https://www.economist.com/search?q=%22virtual+reality%22&sort=date)\n\nHere are some that might seem interesting.\n\n\n[Promise of AR](https://www.economist.com/science-and-technology/2017/02/04/the-promise-of-augmented-reality)\n\n\n[Why AR will be big in business first](https://www.economist.com/leaders/2017/02/04/why-augmented-reality-will-be-big-in-business-first)\n\n[Usage in Foot Solider technology](https://www.economist.com/science-and-technology/tomorrows-soldiers-will-have-their-reality-augmented/21804963)\n\n[Surgeries/Other Medical Use Cases](https://www.economist.com/technology-quarterly/2001/03/24/the-cutting-edge-of-virtual-reality)\n\n[Which Game Company is Best Positioned](https://www.economist.com/graphic-detail/2016/10/14/which-gaming-company-will-dominate-the-virtual-reality-market)\n\n[Game Over For VR](https://www.economist.com/science-and-technology/2017/12/01/game-over-for-virtual-reality).\n\n\n[How VR works](https://www.economist.com/the-economist-explains/2015/09/01/how-virtual-reality-works)\n\n[Building a Chinese Metaverse](https://www.economist.com/china/2022/02/04/building-a-metaverse-with-chinese-characteristics)\n\n[Virtual Property Prices Boom](https://www.economist.com/business/2022/01/01/virtual-property-prices-are-going-through-the-roof)\n\n[VR in Edtech](https://www.economist.com/united-states/2021/09/18/edtech-that-helps-teachers-beats-edtech-that-replaces-them).\n\n\n[More Healthcare](https://www.economist.com/technology-quarterly/2020/10/01/health-care-is-already-benefiting-from-vr)\n\n\n\n# Curated Lists\n\n\n\n\n# System Design\n[](https://www.youtube.com/watch?v=-7CcuHASEgw&ab_channel=StrangeLoopConference)\n\n[](https://www.youtube.com/watch?v=XJZpf0gk1ZM&ab_channel=Ekeeda)\n\n\n\n## Courses\n\n[Link To Brochure for MIT Course in XR Application Development](https://drive.google.com/file/d/1p7HUxKxOeJwtB1p_xuaiQ1H-qmguc85g/view?usp=sharing)\n\n# Videos\n\n* Redefining what is humanly possible with augmented reality\n* Augmented Reality | John Werner | TEDxAsburyPark\n* Augmented Reality, science fiction is now science fact | Ryan Groom | TEDxMoncton\n* Augmented reality storytelling how it will change the way we play forever | Devon Lyon | TEDxSalem\n* How Augmented Reality Will Change Education Completely | Florian Radke | TEDxGateway\n* Will virtual and augmented reality move us into the knowledge age? | Zenka | TEDxJacksonHole","n":0.08}}},{"i":71,"$":{"0":{"v":"Build to Last Book Summary (Durmonski)","n":0.408},"1":{"v":"\n\n* Figure out what things should change and what shouldn't\n* Exist beyond making money (as in [[seed.Product Management.Product School Book]])\n* Core Values and Mission Statement should be Constant\n* Practices can change \n\n# Clock Building, Not Time Telling\n\n 'Engineering' mindset - build up something that doesn't need you .\n [[Philosophy and Rationality.Knowledge Should be Public]]\n\n Chasing a single project is a 'time-telling' action; creating a system - building a clock- can tell time forever.\n\n Visionary company - needs to stand for something AND this needs to kind of be baked into the culture (i.e. how the organization itself runs), products, and services.\n\n Spend more time thinking about organization design.\n Thinking about 'identity' of the organization.\n\n\n# Everything can change, except the core ideology\n\n# Be like a cult (but hopefully good one)\n\n If people believe they're just working for another company, we'll be just another company.\n\n\n# Continous improvement\n\nIf you are a perfectionist, you'll never publish anything. If you don't publish anything,you'll never be in business. \n\nIf you're in business, users will drive you towards perfection.\n\n# ","n":0.076}}},{"i":72,"$":{"0":{"v":"AdTech","n":1}}},{"i":73,"$":{"0":{"v":"Science","n":1}}},{"i":74,"$":{"0":{"v":"Stats","n":1}}},{"i":75,"$":{"0":{"v":"Tests","n":1},"1":{"v":"\n\n# Tests for Difference in means \n## t-test ^ttest\n\n## ANOVA ^anova\n\n Can test if subgroups of data (split by __category/factor__) have different means. In many situation equivalent w/\n running [[science.stats.Regression.Linear Regression]] w/ predictor the factor.\n\n [Technical Description](https://stats.stackexchange.com/questions/175246/why-is-anova-equivalent-to-linear-regression).\n \n\"\"Somewhat aphoristically one can describe ANOVA as a regression with dummy variables.\"\"\n\nIn one-day anova things are normally distibuted, with common variance...\n\n\n\n# Jarque-Bera Test. ^jbtest\nIn statistics, the __Jarque–Bera test__ is a goodness-of-fit test of whether sample data have the skewness and kurtosis matching a __normal distribution__. \n\n[evernote note](https://www.evernote.com/shard/s101/nl/11122041/48ca61f7-8c3a-443a-b412-78499d2e7e98?title=5.4.1%20The%20Jarque%7BBera%20test)\n\n\n\n","n":0.109}}},{"i":76,"$":{"0":{"v":"Markovian Models","n":0.707},"1":{"v":"\n[evernote $F\\#$ client](https://www.evernote.com/shard/s101/nl/11122041/f84ce502-c913-4a0a-bf42-1fd793041063?title=Activity%20Log)\n\n[Soccer](https://drive.google.com/drive/folders/0B-C_0LZtyGcNQzdSSUM3Yjl1YW8?resourcekey=0-lu5rFPEJrxJ2tw4QBuRRSw&usp=sharing)\n[Soccer 2](https://drive.google.com/drive/folders/0B-C_0LZtyGcNQzdSSUM3Yjl1YW8?resourcekey=0-lu5rFPEJrxJ2tw4QBuRRSw&usp=sharing).\n\n[UX Research Slides](https://docs.google.com/presentation/d/1c6lk6hHXkePgtzHmWcy7AoH3Uafdz_kH/edit?usp=sharing&ouid=100971142801837019770&rtpof=true&sd=true).\n\n\n[SlotsMDP](https://drive.google.com/open?id=0B-C_0LZtyGcNTXZnZjJCU1ZkSlE&resourcekey=0-lFshHIzfcdRZN6by0J7GBg&authuser=stefanvpetrov%40gmail.com&usp=drive_fs).\n\n\n","n":0.408}}},{"i":77,"$":{"0":{"v":"Unsupervised Learning","n":0.707},"1":{"v":"\n\n[[science.stats.Dimensionality Reduction]]\n[[science.stats.Unsupervised Learning.KNN]]\n\n","n":0.577}}},{"i":78,"$":{"0":{"v":"KNN","n":1},"1":{"v":"\n# Applications\nParticularly important if we have user/item embeddings and want to quickly fetch a bunch of potentially relevant items to recommend.\n[[engineering.system_design.ML System Design.Recommender Systems#^candidate_generation]]\n\n[[science.stats.Unsupervised Learning.KNN]] prediction part\n\n[[engineering.system_design.ML System Design.Recommender Systems]]\n# Approaches and Tools\n### [LSH Algorithm For Nearest Neighborhood search](https://en.wikipedia.org/wiki/Locality-sensitive_hashing#LSH_algorithm_for_nearest_neighbor_search)\n### KD-Trees\n\n### [Microsoft](https://github.com/Microsoft/SPTAG)\n### [Facebook](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)\n### [Github Benchmarks](https://github.com/erikbern/ann-benchmarks)\n\n\n\n\n# Task-specific Dimensionality reduction approaches\n\n[[science.math.Functional Analysis.High Dimensional Neighborhood Search.Random Projections]]\n[[science.stats.Unsupervised Learning.KNN.Locality Sensitive Hashing]]\n\n\n\n\n","n":0.134}}},{"i":79,"$":{"0":{"v":"Locality Sensitive Hashing","n":0.577},"1":{"v":"\n(Random Projection Based Algorithm)[https://en.wikipedia.org/wiki/Locality-sensitive_hashing#Random_projection]\n\nLet the elements $v$ are $m$-dimensional.\n\nChoose $k$ random hyperplanes in $R^m$, represented by their normal vectors $r_1,r_2,...r_k$.\n\nEncode $h_i(v) = [sign(v\\cdot r_i)]$, so which side of the hyperplane the thing is on.\nThen $\\vec{h}(v)=[h_1(v),h_2(v),...]$\nThen one can prove the probability of the hashes being close if the items are close is high.\n\nRelated to [[science.math.Functional Analysis.High Dimensional Neighborhood Search.Random Projections]]\n\n","n":0.13}}},{"i":80,"$":{"0":{"v":"Clustering","n":1},"1":{"v":"\n\nTaken mostly from Dino Sejdinovic's notes at Oxford. \n Clustering means we want to group similar objects(make a partition).\n # Metric/Similarity/ dissimilarity\n consider the following three basic properties,required of a clustering method $F:(D = {x_1,x_2,...,x_n},\\rho)->{C_1,...,C_k}$\n that takes a dataset $D$ and a dissimilarity function $\\rho$ and returns a partitioning $C$ of $D$ into $k$ clusters.\n Some desirable properties there are:\n## Scale Invariance: \n$F(D,\\rho)$ is invariant to changing of the measurement units of the dissimilarity function $\\rho$. Formally, $F(D,\\rho)=F(D,\\alpha\\rho)$ where $\\alpha$ is a positive scalar.\n## Richness\n\nFor any partitioning $C^*= \\{ C_1^*,\\ldots,C_k^* \\}$ of D, there exists a dissimilarity function $\\rho^*$ that produces it:\n$F(D,\\rho^*)=C^*$\n\n## Consistency\n\nIf we have a clustering, and then change the dissimilarity function s.t. items in same clusters become no more dissimilar, but the items in different clusters become not less dissimilar, then the clustering should not change\n\n## Kleinberg Impossibility Theorem\n\nWe can't have all 3 of these natural properties holding simultaneously.\n\n\n\n\n\n\n\n\n\n# K-means ^kmeans\n\nWe want to minimize the total in-cluster distance.\n\n$min_{C} \\Sigma_{i=1..k} (\\Sigma_{j:C_j=k}||x_j-\\mu_i||_2^2)$\n\nIdea:\n1. Given centroids, can easily assign points (assign to closest).\n2. Given clusters can easily find their centroids, by differentiating the objective function (it turns out the centroids work).\n\nWe can iterate the steps above until convergence or a predefined number of iterations, is reached.\n\n# K-means ++ \n\nThis is an algorithm for choosing initial centroids. We first sample uniformly at random and select the 1st point. Then we compute the distance to all other points and sample with probability proportional to the distance squared (or select the furthest). This is great initialization algorithm that comes with theoretical guarantees, as well as working well in practice.\n\n\n# (K-center)[https://ugtcs.berkeley.edu/src/approx-sp19/scribe-notes-2.pdf]\n\n\n\n# DP -means\n\nAbove work for a fixed k.\nDP algorithm for clustering is one we won't describe, but it can be shown to minimize the objective:\n\n$min_{C} \\Sigma_{i=1..k} (\\Sigma_{j:C_j=k}||x_j-\\mu_i||_2^2)+ \\lambda K$ where $\\lambda$ is a regularization parameter.\n\nThe core of the algorithm is an Expectation-Maximization step.\n[[science.math.Optimization.EM Expectation Maximization]]\n\n\n\n","n":0.057}}},{"i":81,"$":{"0":{"v":"Train Test Splitting","n":0.577},"1":{"v":"\n# Random Sampling\n\n# Stratified sampling\n\nIf we have some set of characteristics, we want to be able to split the set into two subsets, one with the characteristics that are most similar to the characteristics of the other subset.\n\n# Time series sampling\n Split by expanding time windows (information set)\n\n\n# Recommender System test set split ^recsys-start\n \n For collaborative filtering if we __don't want to deal with cold starts__ directly with this model, use approach similar to stratified sampling. So we just mask some entries in the matrix randomly, should put roughly all items and all users in both the train and test set. Related to [[^transductive-gnn]]\n\nIf we want to deal with the cold start in integrated way (idk of possible), then maybe can just split as we wish by rows/columns/connected components etc.\n![RecSys traintestsplit](/assets/images/2022-01-17-15-31-56.png) ^recSys-traintestsplit\n\nCold start problem is related to [^inductive-gnn].\n\n \n ^recsys-end\n \n # Graph Neural Nets:\n\n ## Transductive\n\n In transductive learning in graphs, we see the whole graph structure, and want to learn something\n about unobserved node/edge labels/features. ^transductive-gnn\n\n ## Inductive Learning\n\n In transductive learning, we have access to both the node features and topology of test nodes while inductive learning requires testing on graphs unseen in the training. ^inductive-gnn\n\n","n":0.071}}},{"i":82,"$":{"0":{"v":"Time Series","n":0.707},"1":{"v":"\n\n# Hyndman Book\n\n\n\n\n# Data Skeptic Season\n\n\n## Matrix Profiles\n[Stumpy](https://pypi.org/project/stumpy/)\n\n(Site)[https://pypi.org/project/stumpy/]\n\n[[science.stats.Time Series.Matrix Profile]]\nComputes:\n* patterns/motifs\n* GPU- scaleable\n* approximate computation\n* on-line(incremental) updates\n* finding discord/anomalies\n* snippets for summarizing time series\n* Time Series EDA\n\n\n\n# General References And Articles\n*[Hyndman's online textbook](https://otexts.com/fpp3/)\n\n\n# Single Time Series Models\n\n### [ETS](https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/ets)\n\n### [AutoArima](https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/auto.arima)\n### Multiple Seasonalities\n* [TBATS](https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/tbats)\n* [MSTL](https://www.rdocumentation.org/packages/forecast/versions/8.16/topics/mstl)\n\n\n\n# Kaggle/ State of The Art Stuff\n\n\n\nSome comments from the forum for the Favorita case:\n\n\n\n\n\n## 1th place solution: model Overview\n\n\n\n\nI build 3 models: a lightGBM, a CNN+DNN and a seq2seq RNN model. Final model was a weighted average of these models (where each model is stabilized by training multiple times with different random seeds then take the average), with special dealing with promotion, which I will discuss later. Each model separately can stay in top 1% in the private leaderboard.\n\n\nLGBM: It is an upgraded version of the public kernels. More features, data and periods were fed to the model.\n\n\nCNN+DNN: This is a traditional NN model, where the CNN part is a dilated causal convolution inspired by WaveNet, and the DNN part is 2 FC layers connected to raw sales sequences. Then the inputs are concatenated together with categorical embeddings and future promotions, and directly output to 16 future days of predictions.\n\n\nRNN: This is a seq2seq model with a similar architecture of @Arthur Suilin's solution for the web traffic prediction. Encoder and decoder are both GRUs. The hidden states of the encoder are passed to the decoder through an FC layer connector. This is useful to improve the accuracy significantly.\n\n\n[Favorita EDA](https://www.kaggle.com/headsortails/shopping-for-insights-favorita-eda)\n[Favorita Restaurant](https://www.kaggle.com/headsortails/be-my-guest-recruit-restaurant-eda/notebook)\n\n\n\n# [Operators on Inhomogenous Time Series](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=208278)\n\n\nInteresting bunch of operators. \nIt's good to get a good mathematical foothold of them...\n\n\n","n":0.062}}},{"i":83,"$":{"0":{"v":"Visualization","n":1},"1":{"v":"\n# M4 Data Visualization\n\nIt's perception-aware\n\n[Paper](https://columbiaviz.github.io/files/papers/m4.pdf)\n\n\n","n":0.447}}},{"i":84,"$":{"0":{"v":"Matrix Profile","n":0.707},"1":{"v":"\n[The Matrix Profile - Stumpy](https://stumpy.readthedocs.io/en/latest/Tutorial_The_Matrix_Profile.html)\n","n":0.447}}},{"i":85,"$":{"0":{"v":"KATS","n":1},"1":{"v":"\n\n# TimeSeriesData  obbject\n\n\nlike ts in R, or mts in R.\njust a pandas dataframe with some additional stuff. \n\nCan convert from and to a pandas DF\n# Forecasting with KATS\n\n10 Basic forecasting models\n\n1. Linear\n2. Quadratic\n3. ARIMA\n4. SARIMA\n5. Holt-Winters\n6. Prophet\n7. AR-Net\n8. LSTM\n9. Theta\n10. VAR\n\n\n  -- Not obvious how to do \n  k-step ahead out of sample predictions with KATS.\n\n#  https://facebookresearch.github.io/Kats/api/_modules/kats/models/lstm.html#LSTMModel.predict\n\n\n\nHowever, BackTester is a way to do this...\n\n# (KATS Backtesters)[https://facebookresearch.github.io/Kats/api/kats.utils.backtesters.html]\n\n\nThe **frequency** parameter is usually in the 'fit' function.\n\nProbably kwargs in the Backtest model are passed to the 'fit' model, or maybe the 'predict' function.\n\nActually kwargs is just passed to the parent class constructor.\n\n I think it's pased to both, maybe...\n\n # Inferring frequency\n\n Kats uses [pandas infer freq function]()\n https://pandas.pydata.org/docs/reference/api/pandas.infer_freq.html\n\n\n # NB : Use Cross Validation\n\nrolling vs expanding window, etc...\n\n\n# KATS - out of sample step-ahead forecasting\n\nhttps://facebookresearch.github.io/Kats/api/kats.models.arima.html\n\nHere inthe arima, there are __start_params__, and iteration limit...\n\n\n\n# KATS Prophet\n\nIn the ProphetParams, there is somethign about holidays...\n\n\n\nThere is a [PR request](httpshttps://github.com/facebookresearch/Kats/pull/129) for this..\n\nFrom [here](https://bytemeta.vip/repo/facebookresearch/Kats/issues/167)\n\n\n\n```{python}\nfrom kats.models.prophet import ProphetModel, ProphetParams\n\nair_passengers_ts = TimeSeriesData(air_passengers_df) reg = np.random.randn(len(air_passengers_ts))\n\npparams = ProphetParams(extra_regressors = [{'value': reg, 'name':'reg1'}])\n\npmodel = ProphetModel(data=air_passengers_ts, params=pparams)\n\npmodel.fit()\n\npmodel.predict(steps=20, extra_regressors = [{'value': np.random.randn(20), 'name':'reg1'}])`\n```\n\n# Low-hanging fruit..\n\n\n\n## General\n0. Use log1p -> exp(x)-1  to avoid predictions bellow 0...\n1. Featurization:\nUse Patrons forecast as a feature in a regression/auto-regressive model\nMoving averages over different time windows:\nPrevious 3 working days, mean and median for last week month, quarter, same quarter last year, a same week last year (if available).\n1/ (#days after last holiday). #days since the start of the semester and until the end of the semester.\n# of days since the start of last lockdown.\nUsing patrons forecast for that date (as a version of a model stacking).\n\n\n -- Observation weights not included in Prophet At the moment\n\n - Use Arima as Baseline model\n\n# Solving the 'bad observational periods' issue \n\n1. for each time series, fit [Gaussian Mixture model](https://scikit-learn.org/stable/modules/mixture.html) to check for 'abnormal periods'. Alternatively, they may be defined manually.\n2. For each time series, mark the 'abnormal' periods that have mean <=1/3 of the mean of the cluster of largest values, as missing/NaN.\n3. Inpute the NaN's with https://pypi.org/project/autoimpute/, spline feature.\n\n\n## Event and Holiday Modeling\nAdd events. For the prophet model, can do it directly in the prophet constructor.\n\n## External regressors w/ LSTM\n\nAdd external regressors as an extension of the input vectors...\nShould be easy to also add the the out of sample several-steps ahead things.\n\n## Split and aggregate\n\n\n\nNotes from \n[Best DL Learning MNodels for TS](https://towardsdatascience.com/the-best-deep-learning-models-for-time-series-forecasting-690767bc63f0)\n\n\nthere is an implementation of N-Beats in darts\n\n\n\n\nhttps://github.com/QData/spacetimeformer\n\n\n","n":0.05}}},{"i":86,"$":{"0":{"v":"ASAP Time Series Paper","n":0.5},"1":{"v":"\n---\nid: zznn7su9abv01q61qk6mym1\ntitle: ASAP Time Series Paper\ndesc: ''\nupdated: 1657530669543\ncreated: 1657460809018\n---\n\n\n[ASAP: Automatic Smoothing for Attention Prioritization in Streaming Time Series Visualization](https://arxiv.org/abs/1703.00983v1)\n\n# Situation\nMuch telemetry data has been generated from various systems. For some of it there are human operators,\nlooking at it in order to do detect anomalies quickly.\n\nBut trend shifts can be hidden by variance.\n\nIdea:\n\nSmooth variance between first differences\nsubject to kurtosis (4th moment) remaining the same.\n\nFind window length that does this best, calculate online (if possible).\n\n\n# Implementations\n\n[[engineering.technologies.MacroBase]]\n\n[[science.cs.languages.JavaScript]]\n\n\n\n\n# Task\n\n\n# Action\n\n\nSolve efficiently above problem..\n\n\n\n**Acts as a transformation on fixed-size sliding windows and\nover a single time series**\n\n\n**ASAP can also execute on\nthe client; we provide a JavaScript library for doing so.**\n\n\n***ASAP acts as a building block in time series visualization. It\ncan ingest and process raw data from time series databases such\nas InfluxDB, as well as from visualization clients such as plotting\nlibraries and frontends**\n\n\n\n## Roughness measure\nit's the roughness of the **trend** (roughly).\n\nRoughness = 0 <=> straight line .\n\n## Preservation Measure\n\nKurtosis:\n\n(4th standartised moment).\n### Smoothing Function\n\nIt's just the simple moving average.\n\n### Smoothing problem statement\n\n\n\n\n\n# Result\n\n\n\n\n","n":0.078}}},{"i":87,"$":{"0":{"v":"Support Vector Machines","n":0.577},"1":{"v":"\n# Maximum Hard/soft margin classifier \n\n# Key Insight\nTake dual. Notice $x_i$ in dual participates only in $x_i\\cdot x_j$ terms \nMercer condition:  can do the kernel trick for unknown kernel. ^key_insight\n\nChoose dot product so it supports nonlinearity.\n\n\n[[science.math.Optimization.Convex Optimization]]\n\n# Model and Algorithm\n\nWe're solving a [[science.stats.Regression]] type problem\n\n## Support Vector Classification ^svc\n\nStarting w/ linear max-margin classifier. Let us assume the 2 classes are linearly separable,  the separating hyperplane be L $wx+b$ and let it be the case it. Then\n(as an exercise!) show that the maximum margin, i.e. the distance of the 2 lines, parallel to L, that touch the 2 classes, is:\n$2/||w||$.\n\n![](https://vitalflux.com/wp-content/uploads/2020/07/Screenshot-2020-07-07-at-3.44.38-PM-300x162.png)\n\n__It's an exercise to see why the above is the case!!!__\n\nThen we can pose the problem as :\n\n$max_{w,b} 1/||w||$  = $min_{w,b} ||w||^2$\n$\\text{subject to } w^Tx_i+b>=1 if y_i=1$\n$\\text{subject to } w^Tx_i+b<=-1 if y_i=1$\n\nWe can solve this by taking the dual of the above and look at the [[science.math.Optimization.Convex Optimization.KKT Slater Complimentary Slackness Karush Kuhn Tucker]] conditio[[science.math.Optimization.Convex Optimization.KKT Slater Complimentary Slackness Karush Kuhn Tucker]] condition.\n\nThe key, as we discussed, that is in the dual we only see the datapoints as dot products [[#key-insight]]. \n\nBecause of that, we can use [[science.math.Functional Analysis.Kernel Methods]]\n\n#TODO- write down dual etc.\n\n# Soft-Margin CSV\n\n#TODO- write down dual etc.\n\n\n# $\\nu$-SVM\n\n#TODO -look at Oxford lectures and check it out.\n\n\n\n\n","n":0.07}}},{"i":88,"$":{"0":{"v":"Supervised Learning","n":0.707},"1":{"v":"\n\nIn practice extremely similar to [[science.stats.Regression]].\n\nML is more of a 'curve-fitting' than a 'probability-based' approach.\n\n# Empirical Risk Minimization\n\nWe have a [[science.stats.Regression.Loss Functions]]. The risk then is the \nexpected loss of the model across the possible imputs. \n \n At all points we consider a certain class of functions $\\mathcal{H}$\n\n # Examples of hypothesis classes\n \n * Linear models [[science.stats.Regression.Linear Regression]]\n * Linear models, but with nonlinear fixed feature expansions\n * Reproducing Kernel Hilbert Spaces ([[science.stats.Support Vector Machines]]) \n\n\n\n\n\n\n\n","n":0.113}}},{"i":89,"$":{"0":{"v":"Summary statistics","n":0.707},"1":{"v":"\nLet $X_1,X2, ..., X_n$ be random variables. \nThen the sample mean is defined as follows:\n\n$\\bar{X} = \\frac{1}{n}\\Sigma_{i=1..n}X_i$\n\nThe sample variance is defined as follows:\n$S^2 = \\frac{1}{n-1}\\Sigma_{i=1..n}(X_i-\\bar{X})^2$\n\nWhy the '-1'?\n","n":0.192}}},{"i":90,"$":{"0":{"v":"Statistical View of Deep Learning","n":0.447},"1":{"v":"\n\n\nFrom [S. Mohamed's review paper](http://www.cs.columbia.edu/~blei/seminar/2020-representation/readings/Mohamed2015a.pdf) we know that if we have a glm model:\n\n\n$\\hat{y} = \\beta^T x+\\alpha$\n$Var(\\hat{y}) = \\sigma^2$\n$E(y) = Link^{-1}(\\hat(y))$\n\nWhere $\\bf{\\beta},\\alpha,\\sigma$ are parameters to esimate.\nLink functions are listed here:[[science.stats.Regression.Loss Functions.Activation Functions]]","n":0.177}}},{"i":91,"$":{"0":{"v":"Stacking Models","n":0.707},"1":{"v":"\n\n\n \n# [Multiple Layer Stacking](https://pycaret.org/stack-models/)\n\nBase models can be in a single layer or in _**multiple layers in which case the predictions from each preceding layer is passed to the next layer as an input until**_ it reaches meta-model where predictions from all the layers including base layer is used as an input to generate final prediction.\n","n":0.134}}},{"i":92,"$":{"0":{"v":"Semi-supervised Learning","n":0.707}}},{"i":93,"$":{"0":{"v":"Regression","n":1},"1":{"v":"\n# Qualitative/factor/categorical data\n## One-hot encoding\nmake |C|-1 classes to avoid indeterminate system if needed. If using SGD, maybe no need\n## Impact Coding \n[Vtreat is nice](https://win-vector.com/2017/09/25/custom-level-coding-in-vtreat/)\n\n","n":0.204}}},{"i":94,"$":{"0":{"v":"Recommender Systems","n":0.707},"1":{"v":"\n\n[Rec Systems Google Drive](https://drive.google.com/open?id=0B-C_0LZtyGcNR3RMTlFVVGRKWEE&resourcekey=0-zkpm-R4LmO8XCchjdcEMHA&authuser=stefanvpetrov%40gmail.com&usp=drive_fs).\n\n[Netflix Prize Paper On Matrix Factorications]()\n[[science.math.Linear Algebra]]\n\n[Netflix Prize Paper](https://drive.google.com/open?id=1AqarZQOZgrcYehme3JzL4pCV_IAQhn_E&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n#TODO - read and write some notes here...\n\n# History of Recsys\n\n\n```mermaid\ngraph LR;\na[\"2003 Scalable models\"];\nb[\"2005-2009 Netflix Prize - Matrx Factorization\"]\nc[\"2010-Factorization Machines(Generalized Factorizations)\"]\nd[\"2014-Deep Content Systems\"]\ne[\"2017-Deep Learning RecSys\"]\n\na-->b-->c-->d-->e\n\n\n\n```\n\n\n## Matrix Factorization\n\nuser ratings/other signals as user/rating matrix\ncan handle implicit data.\n\n[Article](https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe)\n\n\n# Basic Model:\nWe would like to find a matrix $X$ such that $X$ is a low-rank matrix and $X$ is close to the user-item matrix. That is, we project both the 'users' and the 'items' into a latent space of dimension $f$. Each item is associated with a vector $\\vec{q_i}\\in R^f$, and each user $u$ is associated with a vector $\\vec{p_u}\\in R^f$. \n\nThen the $\\hat{r}_{ui}=p_u.q_i$ is the prediction.  ^basic-model-equation\n\nWe can add also overall intercept,  user-specific intercept, and item-specific intercept, denoting \ncorrespondingly avg ratings across the system, and average systematic deviations from the ratings of the user or item.\nthus\n\n$\\hat{r}_{u,i} = p_u.q_i+\\mu+\\beta_u+\\beta_i$ ^basic-model-equation-with-intercepts\n\nWe're going to try to find approximate fit of the data wrt parameters.\n\n# Software \n\n[Case Recommender](https://github.com/caserec/CaseRecommender) [[science.cs.languages.python]]\n\n\n\n\n# Combining implicit and explicit feedback - paper review ^implicit-explicit\n\n[Glasgow paper](https://eprints.gla.ac.uk/189873/7/189873.pdf).\n\n* Rating (explicit data) is often used to predict *rating* of an item by user. This can be measured by\n<!-- RMSE -->\n* Ranking (implicit data) is often used to predict *ranking* of an items by a user\nthe rating prediction. Can be measured by IR (information retrieval) measures\ntask is usually quantified in terms of the Root Mean Square\nError [20]; while the ranking task effectiveness is measured\nusing Information Retrieval (IR) metrics\n\n\n\nMain difference between implicit and explicit feedback are:\n1. Implicit is dense, explicit very sparse.\n2. Implicit-based models are kind of preferred.\n3. Reason is ratings are very sparse\n4. Generative assumption: user behavior is a 'monotonous chain of actions (e.g. browsing, clicking, watching))'. This implicit chain has explicit feedback at the end of it. But if a user stops somewhere, they maybe don't ever get the explicit feedback. So the 'tail' of the action chain might be missing, but the 'head' is there. This is why implicit feedback is preferred (I think).\n5. A problem for this might be that the 'head' of the implicit feedback might be biased towards popular items, it might lack serendipity, surprise, discovery, fairness etc. ^popularity-bias-implicit\n\n\n2.3 Unifying Approaches\nFor recommendation scenarios with both implicit and explicit interaction data, it is desirable to unify both forms of\nusers’ interactions in order to generate more accurate recommendations. A line of work has emerged that incorporates\nboth implicit feedback and explicit ratings for either ranking or rating prediction tasks. For example, ChainRec [23]\n– a recent approach that we use as a baseline – represents\nthe sequence of implicit and explicit feedback as a monotonic behaviour chain; i.e. it is not possible to observe an explicit feedback without observing a chain of implicit feedback\nbeforehand. Liu et al. [9] proposed a collaborative filtering\nmodel that can be simultaneously learned from both explicit\nand implicit feedback. Zhang et al. [25] proposed a model\nthat learns the corresponding user and item embeddings individually for each type of feedback and integrates them to obtain a joint representation of users and items. SVD++ [5] is\nanother work proposed for the task of rating prediction that\n\n\nconsiders all items for which a user made implicit feedback,\nin order to learn a representation for the user. Also, previous\nresearch [3, 7, 18] proposed training simultaneously a ranking\nand a rating prediction algorithm with a shared representation for users and items in a multi-task learning framework.\nAlthough the connection between explicit and implicit interactions has been well-studied in previous research [8, 9, 14,\n15, 23], most approaches have focused on modifying the current recommendation models or have proposed a new model\nthat considers other feedback as auxiliary information.\nThe main barrier in unifying explicit and implicit feedback is that they are heterogeneous in terms of both representations and distributions. Therefore, the identification\nof a single model to represent both of them simultaneously\nat the level of recommendation is a challenging task. Instead, in this paper, we propose to tackle the problem of\nunifying explicit and implicit feedback from a completely\ndifferent perspective. In particular, the most important aspect of our proposed approach compared to the most related\nwork [3, 8, 9, 23, 25] is that we tackle the problem at the level\nof data pre-processing: instead of suggesting a new recommendation model/algorithm that learns from both explicit\nand implicit feedback, we propose a weak supervision approach to augment the implicit feedback into the underlying\nmodel at the lower level of data pre-processing\n\n\n## Summary of model (as I understand it) ^glasgow-summary\nLet $U = {u_1,u_2,...,u_m}$ iterates over users, and $I={i_1,i_2,...,i_n}$ iterates over items.\n\nThe explicit feedback dataset is $D_e=<U,I,R>$ (by obvious abuse of notation).\n\nThe ratings $R$ are numeric (or like/dislike, but quantified eventually).\n\nThe implicit feedback rating dataset is $D_i=<U,I>$, indicating that user $i$ has interacted with item $j$. \n\nThe weakly annotated dataset $D_i^{*} =<U,I,\\hat{R}>$ is something we learn from both $D_i$ and $D_e$.\nLet us denote $\\Phi$ a given model and $\\Phi_{D_e}$ a model learned from $D_e$, while $\\Phi_{D_i}^{*}$ is learned from the 'weakly annotated $\\Phi_{D_{i}}^*$.\n\nSo how do we get to $D_i^{*}$ from $D_i$ and $D_e$?\n\nSimple:\n\n1. Input: $D_e$, $D_i$.\noutput: $D_i^{*}$\n2. Train $\\Phi_{D_e}$ in a standart way (stoch grad descent, Alternating Least Squares, etc).\n3. Predict in the implicit feedback set $D_i$ using $\\Phi_{D_e}$, using simple dot products, \n  getting $D_i^*$\n4. Predict  on $D_i^*$, using the same model training $Phi$, getting $\\Phi_{D_i}^{*}$. \n We can think a bit how to modify these so they maybe have lower weight, maybe estimate variance etc.\n\n Can think of a bayesian interpretation of the above. E.g. if we know the estimated variance of the $\\hat{r}$ parts of $D_{i}^*$, we could use their inverse square roots as weights. See also ![[#^basic-model-equation-weighted]] \n\n This is shown by \"Unifying Explicit and Implicit Feedback for Rating Prediction\nand Ranking Recommendation Tasks\" to improve performance on both ranking and rating prediction tasks.\n\n\n\n\n\n\n\n\n# Note about Imputation ^imputation-useless\n\nPreviously imputation approaches were used for collaborative filtering (to fill ratings), but too slow.\nAlso, difficult problem, due to distortion, data [[science.stats.Imputation and Missing Data#^mnar]].\nFrom \"MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS\" (Y)\n```\nEarlier systems relied on imputation to fill in missing\nratings and make the rating matrix dense. 2 However, im-\nputation can be very expensive as it significantly increases\nthe amount of data. In addition, inaccurate imputation\nmight distort the data considerably. Hence, more recent\nworks 3-6 suggested modeling directly the observed rat-\nings only, while avoiding overfitting through a regularized\nmodel\n```\n...\n\n\n# SVD++ ^svdpp\n\n[SVD++ Quora](https://www.quora.com/Whats-the-difference-between-SVD-and-SVD++?share=1)\n\nThe actual loss function to minimize includes a general bias term and two bias for both the user and the item. L2 regularization is also used to prevent overfitting. The formulation is the following:\n\n![](/assets/images/2022-02-14-18-27-59.png)^svd-loss-image\n\n$min_{p,q,b}\\Sigma_{u,i} (r_{ui}-\\mu-b_u-b_i-p_u . q_i)^2+\\lambda(||p_u||^2+||q_i||^2+b_u^2+b_i^2)$ ^svd-loss2\n\nNow, let $y_{u,i}$ are the implicit feedbacks of user $u$ and item $i$:\n\n\n$min_{p,q,b}\\Sigma_{u,i} (r_{ui}-\\mu-b_u-b_i-p_u . q_i)^2+\\lambda(||p_u||^2+||q_i||^2+b_u^2+b_i^2)$ ^svdpp-loss\n\n[SVD++ paper by Koren](\nhttps://github.com/gpfvic/IRR/blob/master/Factorization%20meets%20the%20neighborhood-%20a%20multifaceted%20collaborative%20filtering%20model.pdf\n).\n\nThis is in the __Additional input sources_ part of the recommender-systems[netflix] paper. ^additional-input-sources\n\nThere we essentially have SVD++.\n\n# Temporal Dynamics:\n\nCan just make all parameters from the [[#^basic-model-equation-with-intercepts]] dynamic, and\nimpose some model on them, e.g. (V)AR(1):\n\n^temporal-model-equation\n$$\n\\hat{r}_{u,i}(t) = p_u(t).q_i(t)+\\mu(t)+\\beta_u(t)+\\beta_i(t)\\\\\n\\vec{p(t)} = \\alpha_P.\\vec{p(t-1)}+\\vec{\\beta{p}(t)}\n$$ \n\n\nOf course, can add neural nets and stuff here.\n\n# Inputs with varying confidence levels:\n\nCan also weight the observations somehow, as mentioned in \n$min_{q,p} c_{u,i}(\\hat{r}_{ui}-p_u.q_i)^2$ ^basic-model-equation-weighted\n\n\n\n\n\n","n":0.03}}},{"i":95,"$":{"0":{"v":"Implicit Data Handling","n":0.577},"1":{"v":"\n\n#TODO- gather resources from other places and link here...\n[[science.stats.Regression.Recommender Systems#^svdpp]]\n[[science.stats.Regression.Recommender Systems#^additional-input-sources]]\n[[science.stats.Regression.Recommender Systems]]\n[[science.stats.Regression.Recommender Systems#^glasgow-summary]]\n\n# Matrix Factorization of Implicit data handling\nFlexible:\n * Frame it as classification problem, use built-in loss function.\n * Frame it as a ranking problem, use custom loss functions (typically using also [[science.math.Optimization.Optimizers In in Neural Networks.Negative Sampling]]) .\n See also ![[science.stats.Regression.Loss Functions#^ranking-metrics:#^ranking-end]]\n * Frame it as a weighted regression/classification problem.\n\n![](/assets/images/2022-01-17-20-19-44.png) \n\n","n":0.126}}},{"i":96,"$":{"0":{"v":"Ranking","n":1}}},{"i":97,"$":{"0":{"v":"Ordinal Regression","n":0.707},"1":{"v":"\n[Google Drive- References](https://drive.google.com/open?id=1Aq03LjQHDu267YWhZfWFw8eBFAvzu-8u&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n[[Recomme]]","n":0.577}}},{"i":98,"$":{"0":{"v":"Loss Functions","n":0.707},"1":{"v":"\n\n\nLoss functions can often be expressed as a function of $yf(x)$. That is because we often want to penalized misclassification or \n\n\n\n# Likelyhoods and GLM\n\n\n# Classification\n\n![[science.stats.Regression.Classification.Metrics]]\n\n# Ranking ^ranking-start\n\n## Types ^ranking-metrics\n* __Point-wise models__: which try to predict a (matching) score for each query-document pair in the dataset, and use it for ranking the items.\n* __Pair-wise models__: which try to learn a __binary classifier__ that can tell which document is more relevant to a query, given pair of documents.\n* __List-wise models__: which try to directly optimize the value of one of the above evaluation measures, averaged over all queries in the training data.\n\n\n[Some Medium Article](https://towardsdatascience.com/20-popular-machine-learning-metrics-part-2-ranking-statistical-metrics-22c3e5a937b6) ^ranking-metrics\n\n\n\n#TODO- learn some of these\n* Mean Reciprocal Rank (MRR)\n ```\nFor each user and each relevant item, compute \nthe mean precision of the list __trough__ that item\n\n ```\n\n\n## Ranking- Binary Relevance\n### Mean Average Precision ^ranking-map\n Define 'precision trough k' to mean 'how many items until the $k-th$ are relevant. The average of these is the Average Precision. The mean of that is the loss of the ranker.\n\n 0. **MAXIMIZE**\n 1. For each query, compute $AP(q)$ (average precision). To compute average precision, compute first $P_1(q) = I(1_{\\text{user clicked on 1st result}})$\n\n $P_k(q) =\\sum_{i=1..k} I(1_{\\text{user clicked on i-th result}})$\n\n $AP_k(q) =\\frac{\\sum_{i=1..k} P_k(q)}{k}$\n 2. The MAP is the mean of these for a given ranking algorithm.\n\n\n\n### Mean Reciprocal Rank ^ranking-mar\nThe 'performance' is $1/i$, where the highest option we click on is the $i$-th one. Then the avg of that is MRR\n\n0. **MAXIMIZE**\n1. Say we produce $k$ options for a query, and the __highest option__ ($HO(q)$) the  user interacts with is the $i$-th option. If they don't interact, assume $HO(q)=k+1$\n2. $MRR_recommender =\\frac{\\sum_{i=1..Q}\\frac{1}{HO(q)}}{Q}$\n\n\n\n## Ranking- Beyond Binary Relevance\n \n Assume we know the relevances of the documents. Note- this can be used to differentiate signals in ads between look, click, put in basket, purchase, etc.\n So for each document there is a 'relevance ground truth' $rel_d$.\n Now, let a query $q$ return the order $\\pi_1,\\pi_2,...,\\pi_k$\n\n### Discounted Cumulative Gain ^DCG\n\nWe discount things, lower on the list.\n$DCG_p = rel_{\\pi_1}+sum_{i=2..k}(rel_{\\pi_i}/(1+log(i)))$\nCan also use:\n\n$DCG_{[\\pi(1),\\pi(2),...]} = rel_{\\pi_1}+sum_{i=2..k}(2^{rel_{\\pi_i}}/(1+log(i)))$\n\nwhich puts very high emphasis on highly relevant documents.\n\n\n## Normalized Discounted Cumulative Gain ^ranking-NDCG\n\nnormalize DCG by the ideal DCG.\n\n$ DCG_{best}(el_1,el_2,...) = DCG(sortDecsending([el_1,el_2,...])) $\n\n$ NDCG([e_1,e_2,...])= DCG([e_1,e_2,...])/DCG(sortDesc([e_1,e_2,...])) $\n\n\n\n\n\n\n\n## Precision at K (\"p@K\").\n\n Precision @ 1: if first item is relevant, $P_1=1$, else 0.\n\n\n## What if no relevant results\n\nIf user does more queries, then can find the reciprocal rank, MRR is the mean RR across multiple queries.\n\n^ranking-end\n\n\n\n# Huber Loss Functions\n\nL_{\\delta }(a)={\\begin{cases}{\\frac  {1}{2}}{a^{2}}&{\\text{for }}|a|\\leq \\delta ,\\\\\\delta (|a|-{\\frac  {1}{2}}\\delta ),&{\\text{otherwise.}}\\end{cases}}\nThis function is quadratic for small values of a, and linear for large values, with equal values and slopes of the different sections at the two points where {\\displaystyle |a|=\\delta }|a|=\\delta . The variable a often refers to the residuals, that is to the difference between the observed and predicted values {\\displaystyle a=y-f(x)}a=y-f(x), so the former can be expanded to[2]\n\n{\\displaystyle L_{\\delta }(y,f(x))={\\begin{cases}{\\frac {1}{2}}(y-f(x))^{2}&{\\textrm {for}}|y-f(x)|\\leq \\delta ,\\\\\\delta \\,(|y-f(x)|-{\\frac {1}{2}}\\delta ),&{\\textrm {otherwise.}}\\end{cases}}}{\\displaystyle L_{\\delta }(y,f(x))={\\begin{cases}{\\frac {1}{2}}(y-f(x))^{2}&{\\textrm {for}}|y-f(x)|\\leq \\delta ,\\\\\\delta \\,(|y-f(x)|-{\\frac {1}{2}}\\delta ),&{\\textrm {otherwise.}}\\end{cases}}}","n":0.045}}},{"i":99,"$":{"0":{"v":"Activation Functions","n":0.707},"1":{"v":"\nFollowing [Statistical View Of Deep Learning](http://www.cs.columbia.edu/~blei/seminar/2020-representation/readings/Mohamed2015a.pdf)\n\n# GLM's, Link Functions, and NN activation Layers\n\nIn a Linear Regression model, we have:\n\n$\\hat{y}(x) = \\beta^T x +\\alpha$\n$y~ N(\\hat{y},\\sigma)$\nHere $\\sigma$ is unknown and also to be estimated.\n\nNow, if the error distribution is different.\n\n\n# Regression/Activation Function Summary\n\n\n** Heuristically, when applicable, activation function and inverse link functions are the same**.** That is, when the Neural net roughly corresponds to a hierarchical GLM, the last layer may normally have the cannonical inverse link function.**\n\n[[science.stats.Deep Neural Networks]], [[science.stats.Regression.GLM]], [[science.stats.Regression]].\n\nRegression Type | Target Range | Link | Inv Link | Activation Function |\n---------|----------|---------\n Real | Linear Regression | Identity | Identity | Identity | \n Logistic | Binary|$logit(\\mu)=log\\frac{\\mu}{1-\\mu}$ | $sigmoid(x)=\\frac{1}{1+e^{-x}}$ | sigmoid | \n Poisson | Naturals+0 | $log(\\mu)$ | $exp(\\mu)$ | not commonly used (computational reasons?) |\n Sparse Ordered | Tobit | C2 | $max(0;\\nu)$ | ReLU |\n\n\n\n# ReLU ^relu\n\n\n","n":0.084}}},{"i":100,"$":{"0":{"v":"Linear Regression","n":0.707},"1":{"v":"\n\n## Linear Regression - Setup \n\n[[science.probability.Distributions.gaussian]]\n\n## Analytical Solution\n\n## Solution via Gradient Descent\n\n## $L_1$ and $L_2$ Regularization\n\n\n## Mixed Effect Models\n[[science.stats.Mixed Effect Models]]\n\n\n\n\n[[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming.stan]]\n[[science.cs.theory.Code Transformations.Differentiable Programming.turing]]\n\n\n## Quantile Regression\n[[science.math.Optimization.Linear Programming]]\n\nFor particular choice of the quantile to be estimated, the quantile regression problem can be re-formulated as a linear regression problem.\n\n Quantile regression advantage is we can get confidence intervals. \n\n[Formulation of Quantile regression](https://stats.stackexchange.com/questions/384909/formulating-quantile-regression-as-linear-programming-problem)\n\n\n\n## QR reparameterization\n\n[QR reparameterization for Linear Regression faster sampling](https://mc-stan.org/docs/2_18/stan-users-guide/QR-reparameterization-section.html).\n\n[[science.math.Linear Algebra#^qr-decomposition]]\n","n":0.118}}},{"i":101,"$":{"0":{"v":"Impact Coding","n":0.707}}},{"i":102,"$":{"0":{"v":"GLM","n":1}}},{"i":103,"$":{"0":{"v":"Classification","n":1},"1":{"v":"\n\n\n# Multiple Label Classification\n\n![[science.stats.Regression.Classification.Multiple Labels]]","n":0.447}}},{"i":104,"$":{"0":{"v":"Multiple Labels","n":0.707},"1":{"v":"\n# MultiLabel Classification ^multilabel\n\nhttps://machinelearningmastery.com/multi-label-classification-with-deep-learning/\nhttps://github.com/keras-team/keras/issues/741\n\nOne way is to use sigmoid output, but not normalize w/ softmax/multilabel likelyhood, and have the loss function be point-wise binary crossentropy\nloss for each element, and sum them up (it works).\n\n\n```\n\nQ:\nI need train a multi-label softmax classifier, but there is a lot of one-hot code labels in examples, so how to change code to do it?\n\nA:elanmart commented on Sep 28, 2015\nDon't use softmax. Use sigmoid units in the output layer and then use \"binary_crossentrpy\" loss.\n```\n\n\n**Actually it's equivalent to train a single binary classifier to everything, but the learned hierarchical representation before the last label \nis shared.**\n\n## Keras Example\n\n```{python}\n\n# Build a classifier optimized for maximizing f1_score (uses class_weights)\n\nclf = Sequential()\n\nclf.add(Dropout(0.3))\nclf.add(Dense(xt.shape[1], 1600, activation='relu'))\nclf.add(Dropout(0.6))\nclf.add(Dense(1600, 1200, activation='relu'))\nclf.add(Dropout(0.6))\nclf.add(Dense(1200, 800, activation='relu'))\nclf.add(Dropout(0.6))\nclf.add(Dense(800, yt.shape[1], activation='sigmoid'))\n\nclf.compile(optimizer=Adam(), loss='binary_crossentropy')\n\nclf.fit(xt, yt, batch_size=64, nb_epoch=300, validation_data=(xs, ys), class_weight=W, verbose=0)\n\npreds = clf.predict(xs)\n\npreds[preds>=0.5] = 1\npreds[preds<0.5] = 0\n\nprint f1_score(ys, preds, average='macro')\n\n```","n":0.085}}},{"i":105,"$":{"0":{"v":"Metrics","n":1},"1":{"v":"#FalsePositiveRate\n#AUC\n#ROC\n#accuracy\n#precision\n#recall\n#FPR\n#TPR\n\n\n# Accuracy, prediction, recall, ...\n\n\n[Note From Google](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)\ntrue\\predicted | PositivePred | NegativePredicted\n---------|----------|---------\n PositiveTrue | TP | FN\n NegativeTrue | FP | TN\n\n $Accuracy = (TP+FP)/(FN+TN+TP+FP)$ Is simply the proportion of correct predictions.\n\n $Precision = TP/ (TP + FP)$ Is the proportion of correct positive predictions out of all positive __cases__.\n\n $TPR=Recall = (TP)/(TP+FN)$ Is the propotion of correct positive predictions out of all positive __cases__.\n TPR- true positive rate.\n\n$FPR= FP/(FP+TN)$ Is the proportion of false positive out of all  negative __predictions__.\nROC - Receiver Operating Characteristic curve plots TPR against FPR for different thresholds.\n\nAt 0:\nall predictions are negative, TP = FP = 0, hence TPR=0,FPR = 0.\n\nAt 1: all predictions are positive, TN = FN  = 0, hence TPR =1, FPR = 1.\n![](/assets/images/2022-01-11-01-56-55.png)\n\n\n\n# Likelihood/log-likelihood\n## Cross-Entropy\n\n\n# Multivariate\n\n\n \n\n","n":0.089}}},{"i":106,"$":{"0":{"v":"Class Imbalance","n":0.707},"1":{"v":"\n[[science.stats.Regression.Classification]]\n\n[This says to downsample dominant class and upweight rest](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data\n).\nIf using probabalistic algorithm, shouldn't matter, [or matter very little](https://stats.stackexchange.com/questions/128777/is-up-or-down-sampling-imbalanced-data-actually-that-effective-why), but for [[seed.Product Management.Fairness]] reasons, can upweight if we want.\n\nDownsampling dominant class ","n":0.183}}},{"i":107,"$":{"0":{"v":"Censored Outcome Regression","n":0.577},"1":{"v":"\n\n\nRelated to the [[science.stats.Regression.Loss Functions.Activation Functions#relu]].\n\n[Wiki article](https://en.wikipedia.org/wiki/Tobit_model).\n\nI'm putting it here, cause it's related to ReLU and it's fairly obvious why.\n\n\n","n":0.224}}},{"i":108,"$":{"0":{"v":"Permutation Tests","n":0.707}}},{"i":109,"$":{"0":{"v":"Non Parametrics","n":0.707},"1":{"v":"\nNonparametric models are called like this, because the number of parameters depend on the specific data. E.g. Knn is a 'non-parametric model' in a sense. In another sense, it has k parameters for each point in the space (the k closest points), and put in yet another way, it has as many parameters as there are points in the space.\n","n":0.129}}},{"i":110,"$":{"0":{"v":"Mixed Effect Models","n":0.577},"1":{"v":"\n\n[[science.stats.Regression.Linear Regression]]\n\n[[science.stats.Deep Neural Networks]]\n\n","n":0.5}}},{"i":111,"$":{"0":{"v":"Maximum Likelyhood Estimator (MLE)","n":0.5},"1":{"v":"\n# Definition\n\nThe maximum likelyhood estimator is a method for finding the parameters of a function that maximizes the likelyhood of the data.\n\n\nIf we expand the [[science.stats.Likelyhood Function]] around the MLE $\\hat{\\theta}$:\n\n$l(\\theta) = l(\\hat{\\theta}) + (\\theta-\\hat{\\theta]})l'(\\hat{theta})(=0) - (\\theta-\\hat{theta})^2 J(\\theta)$ maps\nwhere $J(\\theta)$ is the observed information[[math.theory.Information Theory.Information (statistics)]] (or the Fisher information $I(\\theta)$, depending).\n\nThus the higher the information, the more concentrated the estimate is around $\\hat{\\theta}$.\n\n# Asymptotic distribution\n\n$\\hat{\\theta} \\approx  N(\\theta,I(\\theta)^{-1})$\n\nRelates the information, MLe estimate and the asymptotic distribution of $\\hat{\\theta}$.\n\n\n# Iterative estimation\n\nUsing [[science.math.Optimization.Newton-Rhapson Method]]\n\nwe can do:\n\n$\\theta^{i+1} = \\theta^{i}-J^{-1}(\\theta^{n})*(l'(\\theta^{n}))$\n\nwhere we fix the dimensions as needed ($l'$ in this case will bet the graddient of the log likelihood). \n\nIt's also called the __score__ function.\n\n\n\n\n\n\n \n","n":0.095}}},{"i":112,"$":{"0":{"v":"Mathematics In Insurance Lecture Notes","n":0.447},"1":{"v":"\n[Math in Insurance](https://drive.google.com/open?id=0B-C_0LZtyGcNZWQ5NTZjZTMtNTQyMC00ZmRkLTk1OGYtYjFhMThjMDJiNjky&resourcekey=0-Y7YD9tY5w6u4atWzYlq4gA&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n","n":0.577}}},{"i":113,"$":{"0":{"v":"Machine Learning","n":0.707},"1":{"v":"\n# Curve Fitting\n\n\n# Training w/ SGD\n\n\n# Input stabilization\n\n\nMl fitting\n\n\n\n# ML Process\n![[stats.Data Science and ML Process]]","n":0.258}}},{"i":114,"$":{"0":{"v":"Scientific Machine Learning","n":0.577},"1":{"v":"\n\n[[science.CS.theory.Code Transformations.Differentiable Programming\n[[science.math.modelling.Differential Equations]]\n[[science.cs.languages.julia]]\n[[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming]]\n","n":0.354}}},{"i":115,"$":{"0":{"v":"Interpretability","n":1}}},{"i":116,"$":{"0":{"v":"Libraries","n":1},"1":{"v":"\n#[DALEX](https://uc-r.github.io/dalex)\n\n\n# [Imodels Python Package](https://www.marktechpost.com/2022/02/10/uc-berkeley-researchers-introduce-imodels-a-python-package-for-fitting-interpretable-machine-learning-models/)\n\n\n# [XAI Github](https://github.com/samzabdiel/XAI)","n":0.408}}},{"i":117,"$":{"0":{"v":"Industry Applications","n":0.707},"1":{"v":"\nList taken from various sources, one of which [EducativeIO](educative.io)\n\n# Industry Applications\n* Virtual Personal Assistants [[science.engineering.technologies.Natural Language Processing and IR]]\n**\n* Finance [[science.stats.Time Series]]\n** Fraud Detection [[science.engineering.technologies.graphs.Graph Representation Learning Book Notes]] \n[Lecture from Graph+AI conference](https://info.tigergraph.com/graph-ai-summit-spring-2021-machine-learning-for-fraud-detection-with-graph)\n** Price Prediction [[science.stats.Time Series]]\n** Trade Execution, Risk Management, and Trading [[science.economics.Market Impact]]\n\n\n* Social Media\n** Face Recognition  \n[How Face Id Works... Probably](https://www.youtube.com/watch?v=mwTaISbA87A&t=511s&ab_channel=Computerphile)\nAlso, quite unrelated with the above link:\n[[science.stats.Deep Neural Networks.Vision Models]]\n\n** People you may know\n** Pages You may like\nCan pose these either as a [[science.stats.Regression.Classification]] via \n[[science.stats.Regression.Ranking]].\nCan also pose them as an #Inductive problem in [[science.engineering.technologies.graphs.Graph Analysis]]\n\n* **Retail**\n ** Product recommendation via [[science.stats.Regression.Recommender Systems]]\n ** Maximization of revenue by learning customer habits\n\n* Online Customer Support:\n ** Replacement of customer support agents by [[science.engineering.technologies.Natural Language Processing and IR.Chatbots]]\n\n * Medicine\n ** Medical Diagnosis [Data Skeptic Episode](https://dataskeptic.com/blog/episodes/2017/doctor-ai)\n ** Medical Imaging [Imaging Episode](https://dataskeptic.com/blog/episodes/2018/medical-imaging-training-techniques)\n\n ** [Drug Discovery](https://www.youtube.com/watch?v=fzSL7MWfXtQ)\n ** Epidemology, large-population public health\n  [COVID-19 Epidemic Mitigation via Scientific Machine Learning (SciML)\n](https://www.youtube.com/watch?v=jMhPZFZ0yvE&t=162s&ab_channel=ChristopherRackauckas)\n\n\n# Search\n[[engineering.system_design.Search]]\n\nData gatherig for search - keep track if you clicked on something \nor went to the 2nd page, repeated search, etc...\n\n\n\n\n\n","n":0.077}}},{"i":118,"$":{"0":{"v":"ChatBots","n":1},"1":{"v":"\n# ChatGPT\n\nChatGPT is a chatbot by OpenAI, and it's optimized for context-aware conversations.\n\n\n# LLM's and ChatGPT\n\n\n[ben's bites]() is a nice aggregator for applications, reserach and tooling about AI, mostly around LLm's lately...\n \n # Evaluating CatGPT on reasoning, hallucination, and common sense\n\n -- 9/13 times outperforms sota zero-shot models\n -- good translation TO english, poor in opposite direction.\n -- ok performance on low-resource languages, but not on very low resource.\n -- ok at detecting misinfioformation on some covid.\n --- Bad at inductive reasoning and math.\n -- multi-hop reasoning is poor, causal and analogical thinkingare good.\n -- few intrinsic hallucinations, but lots of extrincis ones...\n [Paper Source](https://arxiv.org/pdf/2302.04023.pdf)\n\n![](/assets/images/2023-02-13-11-41-58.png)","n":0.097}}},{"i":119,"$":{"0":{"v":"Large Language Models","n":0.577},"1":{"v":"# chatGPT wolfram article\n\n\n# AutoGPT\n\n\n\n# LMQL\n\n\n# Other things\n\n# Hugging GPT Paper Summary\n\n\n# Chat with your PDFs\n![](/assets/huggingGPT.svg)\n\n\n","n":0.25}}},{"i":120,"$":{"0":{"v":"Token Masking","n":0.707},"1":{"v":"\n\n# Token Masking\nMask some words in a sequence and predict which tokens should replace that...\ne.g. \n\n```python\nfrom transformers import pipeline\nclassifier = pipeline(\"fill-mask\")\n\nclassifier(\"Paris is the [MASK] of France.\")\n```\n\n\n\n","n":0.196}}},{"i":121,"$":{"0":{"v":"LangChain","n":1},"1":{"v":"\nLangChain allows to chain models into different things, giving programmability..\n\n\nBasic example- one component decides what language you're speaking, then the next models are the ones you call..\n\nSome python funcitons to extract structured data from your models...\n\nThere can be agents that are being called into one another, performing various functions, talking to each other...\n\nVector db's and embeddings....\n\nbuilt image-to-text using blip...\n\n----\n\n\nActive recall was not too successful there...\n\n\n# Notes from the documentation\n\n\nmain value propositions- compionents, and then pre-build chains\n\ncomponents are more interesting.\n\n\nthere is also js, and a hack thing...\n\n\n```mermaid\ngraph LR\nA[ModelIO]\nB[MemoryAndPersistence]\nC[ModelPersistence]\n\n```\n\n\n\n","n":0.107}}},{"i":122,"$":{"0":{"v":"LMQL","n":1},"1":{"v":"# LMQL\nsyntaxt\n\n'' where ...\n\n\n# Clauses\n\n## where clause\nspecify some constraints on the output\n\n## the main program caluse\n\nBasically we can have some holes inn a text and some python expressions inside, where we're predicting the masked words.\n\nThen as the model is generating stuff according to the strategy, there is a mechanism to enforce the constraints.\n\nHow does this work? with partial evaluation.\nFirst note how LLM's generate their output.\nBefore I thought they generate it trough only a deterministic greedy procedure, but actually they can use\nother graph search algorithms, where the log-probablity of the output is the weight function in the inference graph. So they can do beam search, greedy search, etc.\n\nAs they go they know what variable is being 'generated' at the moment. This variable has some current value and on the basis of this one can say if the variable is violating some constraints. If yes, the search procedure can backtrack. If not, it can continue, while also knowing if the variable can have something added to it, or not.\nI think these are generated as 'follow' and 'fin' nodes in the graph for a particular variable.\n\nExamples:\nIf a var is constrained to be in a list (e.g. 'positive' or 'negtive') that can work in an obvious way..\n\n\nother things...\n\nIt saves 26-60% ofthe cost, but sort of a 'normal amound', as it can cut off unsatisfiable branches.\n\nquite flexeble with the constraints, have to learn more about the syntax...\nThere was this syntax \n\n```\nsample(temperature=1.2)\n\"A few things not to forget when going to the sea (not travelling):\\n \"\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n\"-[THING]\" where stops_at(thing,\"\\n\")\n```\nwhere 'thing' is not the same everywhere.\n\nQuite good at enforxing consistency, eg.g by a clause like:\n\n```\n\"A few things not to forget when going to the sea (not travelling):\\n \"\n```\n\n\n### It's also included in LangChain\n\n\n\nAs we've geneRated the partial outpud\n\n## decoder clause\nSpecity the decoding algorithm to use,\ncan be sample, argmax/or other stuff, like beam or best_k\n\nBeam, argmax.\n,\nsample, beam_sample, beam_var,...\n\n\n\n## from clause\nspecify the model to use\n\n\n# Related work\n\n### Language Model Programming\n\nAll sorts of chain-of-thought and similar things can be considered as part of language model programming...\n\nChain of thought prompting, tree of thought, and others are all part of this and instantiations of it.\n\n\n","n":0.053}}},{"i":123,"$":{"0":{"v":"Likelyhood Function","n":0.707},"1":{"v":"\nLikelyhood is a function we obtain when we take the joint distribution of the data and parameters,\nand fix the data (so it's curried probability).[[Currying]]\n#TODO write a bit about likelyhoods, probabilities, etc.\n\n","n":0.18}}},{"i":124,"$":{"0":{"v":"Latent Variables","n":0.707},"1":{"v":"\n\n A latent space in modelling a set of random variables we dont' directly observe,\n but assume it's __causal__ in generating data we do observe.\n\n Latent variables can be estimated.\n\n\n\n[[science.stats.Dimensionality Reduction]]\n\n","n":0.18}}},{"i":125,"$":{"0":{"v":"Kaggle Competition Notes","n":0.577},"1":{"v":"\n## [Two Sigma](https://www.kaggle.com/c/two-sigma-financial-modeling)\n\nTwo sigma- \nDaily data\nNews data is feature-ized, not raw text.\n\n[[science.CS.theory.NLP]]\n[[science.stats.Regression]]\n\n","n":0.289}}},{"i":126,"$":{"0":{"v":"Imputation and Missing Data","n":0.5},"1":{"v":"\n# Basics::\nReplacing w/ mean, median, last observation carried forward, next observation carried backward, etc.\n\nReplace missings w/ magic values or 0 ( only if actually 0).\n\n\n\n# Missing Completely at random ^mcar\n[Mice](https://cran.r-project.org/web/packages/mice/index.html)\n\n\n# Missing at random ^mar\n# Missing not at random ^mnar\n\n\n\n\n\n# Conditional Sampling of Multivariate Densities ^conditional_sampling\n\n[Conditional Sampling of Multivariate Densities](https://isas.iar.kit.edu/pdf/MFI20_Frisch.pdf)\nCopulas?\n\n[Conditional Sampling from Multivariate Gaussian Mixtures](https://stats.stackexchange.com/questions/348941/general-conditional-distributions-for-multivariate-gaussian-mixtures)\n\n[[stats.Sampling]]\n","n":0.136}}},{"i":127,"$":{"0":{"v":"Frequentist Framework","n":0.707}}},{"i":128,"$":{"0":{"v":"p-values","n":1},"1":{"v":"\n## Mnemonic flowchart\n\n```mermaid\ngraph LR;\na(The chance)-->b(The Probability);\nc(to see this data randomly)-->d(to see at least as extreme of a result by chance- one-sided, or two-sided,etc);\nf(if our assumptions are true)-->h(if the Null hypothesis is true);\n```\n\n## Examples:\n[jelly beans comics](https://xkcd.com/882/)\n\n#TODO explain this...\n\n\n","n":0.164}}},{"i":129,"$":{"0":{"v":"Feature Engineering","n":0.707},"1":{"v":"\n\n# Binning and Bucketing\n\n[I think it should not be done!!!](https://medium.com/@peterflom/why-binning-continuous-data-is-almost-always-a-mistake-ad0b3a1d141f).\nThe reasons to discretize a real-valued numerical feature can be numerous. For example, some\nfeature selection techniques only apply to categorical features.\n\n```\n\nBinning or discretization is used for the transformation of a continuous or numerical variable into a categorical feature. Binning of continuous variable introduces non-linearity and tends to improve the performance of the model. It can be also used to identify missing values or outliers.\nThere are two types of binning:\nUnsupervised Binning: Equal width binning, Equal frequency binning\nSupervised Binning: Entropy-based binning\n\n```\n\n???\n\n","n":0.107}}},{"i":130,"$":{"0":{"v":"Experimental Design","n":0.707},"1":{"v":"\n# Steps:\n\n1. define the problem and a goal\n\n","n":0.354}}},{"i":131,"$":{"0":{"v":"Expectation Maximization (EM) Algorithm","n":0.5},"1":{"v":"\nMostly from the Wikipedia article.\n\n\nThe EM algorithm applies when we have a probabilistic generative model in mind with likelihood $L(\\theta;X)$ and further split the parameter vector in two parts: $\\theta$, representing 'parameters', and $Z$, representing latent/ unobserved data.\n\nSo $L(\\theta;X) = \\int_Z p(X|Z,\\theta)P(z|\\theta)dz$\n\nHad we known Z, it would be simply $L(\\theta;X,Z)$\n\n\n#TODO Finish this one\n\nWe can keep track of:\n$\\theta^{(t)}$- current estimates of $\\theta$, and \n $Q(\\theta,\\theta^{(t)}) = E_{Z~P(Z|X,\\theta^{(t)})} (log L(\\theta;X,Z))$ - expectation of the log likelyhood of $\\theta$, taken over the conditional distribution of Z .\n\nExpectation step (E step): \n1. Find current function Q_{\\theta^{(t)}}=Q(\\theta,\\theta^{(t)}) .\n2. Find the maximizer $\\theta^{(t+1)} = Q(\\theta|\\theta^{(t)})$.\n\n\nMotivation:\n\n If the value of the parameters $\\theta$ is known, usually the value of the latent variables $Z$ can be found by maximizing the log-likelihood over all possible values of $\\Z$ , either simply by iterating over $Z$ or through an specialized algorithm for the specific generative structure. For example, if we have an HMM, the MLE estimates for it's latent variables can be estimated by the [[science.CS.algos.dynamicProgramming.Viterby Algorithm]]. Conversely, if we know the value of the latent variables $Z$ , we can find an MAP estimate of $\\theta$ by maximizing the log likelyehood. This suggests an iterative algorithm, in the case where both $\\theta$ and $Z$ are unknown .\n1. First, initialize the parameters $\\theta$ to some random values.\n2. Compute the probability of each possible value of $Z$, given $\\theta$. \n3. Then, use the just-computed values of $Z$  to compute a better estimate for the parameters $\\theta$.\n4. Iterate steps 2 and 3 until convergence.\nThe algorithm as just described monotonically approaches a local minimum of the cost function.\n","n":0.061}}},{"i":132,"$":{"0":{"v":"Distribution Drift","n":0.707}}},{"i":133,"$":{"0":{"v":"Discriminative Vs Generative","n":0.577},"1":{"v":"\n#TOREAD\n\n[Some Article](https://cedar.buffalo.edu/~srihari/CSE574/Chap4/4.2%20Generative.pdf)\n\n\n\n","n":0.707}}},{"i":134,"$":{"0":{"v":"Dimensionality Reduction","n":0.707}}},{"i":135,"$":{"0":{"v":"t-SNE (T-distributed stochastic neighbor embedding)","n":0.447},"1":{"v":"\n[Wikipedia Article](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding).\n\n[sklearn example](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n\n# Embeddings\n[[science.stats.Deep Neural Networks.Embeddings]]\n\n## Search in embedding space for maximum value dot product\nhttps://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html\nhttps://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/\nfast algos for finding candidates quickly...\n\n\n There is a [[science.cs.languages.julia]] port as well.\n\n\n","n":0.192}}},{"i":136,"$":{"0":{"v":"SVD","n":1},"1":{"v":"[[science.math.Linear Algebra.Singular Value Decomposition]]\n\n\n# Fast R library\n(irlba)[https://cran.r-project.org/web/packages/irlba/index.html].\n(vignetter)[https://cran.r-project.org/web/packages/irlba/vignettes/irlba.pdf].\n\n\n[[science.math.Linear Algebra#^pca]]\n","n":0.354}}},{"i":137,"$":{"0":{"v":"PCA","n":1},"1":{"v":"\n\nMathematically, PCA finds a collection of $k<=d$ unit vectors $v_i\\in R^{d}$, such that:\n1. The variance of the dataset projected into the direction of $v_i$ is maximized\n2. $v_i$ is orthogonal to $v_1,v_2,...,v_{i-1}$.\n\n\n\n\nThe projection of a vector $x$ onto a vector $v$ is:\n$(v.x)*v$. \n\nSteps:\n1. Start with original matrix $X$.\n2. Subtract the mean from each row: $\\bar{X} = X-\\mu$\n3. Then the sample covariance is :\n $S_{i,j}=1/(n-1)*(X_{i,:}-\\mu_i)*(X_{j,:}-\\mu_j) = 1/(n-1)*\\bar{X_i}^T*\\bar{X_j}$\n\n 4. Then the variance of the projection along a vector $v$ is rather: $v^TSv$.\n\n\n\nThe corresponding optimization problem for the first principal component is then\n\n\nmaximize $v^TSv$\n\ns.t. $v^Tv=1$\n\n\n\nLet the principal components be gathered column-wise in a matrix $V = [v_1,v_2,...,v_n]$.\nThen $Z=\\bar{X}V$ is the so-called __loading matrix__. First $k$ columns give a k-dimensional representation of $X$.\n\n\n\n# Inversion\n\nWe can invert back to $R^d$ like so:\n$x_i = V_{1:k}V_{1:k}^Tx_i$\n\nOptimal reconstruction (in the )\n\n\n\n\nThe above suggests there exists a full set of orthonormal eigenvectors for $S$ over $R$. Since $S$ is real and symmetric, the real spectral theorem implies this.\n\nIf we write the eigendecomposition of S:\n$S = TDT^{-1}= TDT^T$\n\n# SVD\n\nif we write the SVD of $\\bar{X} = UDV$, then \nthe loading matrix is $Z = XV = UD$\n\nSo we can get the principal components via the SVD. Or, rather, the $V$ holds the principal components.\n\n\n\n\n\n\n \n  \n\n\n\n","n":0.07}}},{"i":138,"$":{"0":{"v":"Autoencoders","n":1},"1":{"v":"\n[[science.stats.Deep Neural Networks]]\n","n":0.577}}},{"i":139,"$":{"0":{"v":"Delta Method","n":0.707},"1":{"v":"\n\n# Delta Method\n\n Suppose we have $X_1,X_2,...,X_n$ i.i.d. and with mean $mu$ and finite variance $\\sigma^2$. Then from [[science.stats.Central Limit Theorem]] we know that\n for\n\n $\\bar{X} = 1/n\\Sigma_{i=1..n} X_i$ \n\n $\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}} \\approx N(0,1)$.\n\nThis tells us something about the distribution of $\\bar{X}$. Now, sometimes we want to know the distribution of\n$g(\\bar{X})$ for some X. Delta method allows us to do so by doing a Tailor-expansion around $\\mu$:\n\n$g(\\bar{X}) \\approx g(\\mu)+ (\\bar{X}-\\mu)g'(mu)$\n\n$E(g(\\bar{X})) = E(g(\\mu)) + E(g'(\\mu)(\\bar{T}-\\mu)) = g(\\mu)+ g'(\\mu)E(0) = g(\\mu)$\n\n$Var(g(\\bar{T})) = Var(g(\\mu))(==0) + Var(g'(\\mu)(\\bar{T}-\\mu))=g'(\\mu)^2*Var(\\bar{X}) = g'(\\mu)^2*\\sigma^2/n$\n\n\n# Fisher Information, CI and Asymptotics\n\n[[math.theory.Information Theory.Information (statistics)]]\n\nIn statistics\n\n\n\n# Laplace Approximation\n\n","n":0.103}}},{"i":140,"$":{"0":{"v":"Deep Neural Networks","n":0.577},"1":{"v":"\n[[science.CS.theory.Code Transformations.Differentiable Programming.tensorflow]]\n[[science.CS.theory.Code Transformations.Differentiable Programming.pytorch]]\n\n# Hierarchical Modelling\n[Statistical View on Deep Neural Networks](http://blog.shakirm.com/wp-content/uploads/2015/07/SVDL.pdf)\n\n\n\n\n# Recurrent Neural Networks\n## The exploding/vanishing gradient problem\n[[science.math.theory.Dynamical Systems]]\n[[science.math.mode]]\n[[science.stats.Autoregressive Models]]\n\n\n# Symetries ^symmetries\n\n\n# Restricted Boltzmann Machines\n\nSome of the best single-model performers in [[Philosophy and Rationality.Incentives for Research and Engineering Advances^#netflix-prize]].\n\n\n\n#TODO add pages for the architectures and notes here\n# Feed Forward Neural Networks ^feed-forward-nets\n\n# Deep-and-wide networks\n\nDeep Hierarchical model for numeric features, sparse and 'skipping layers' for categorical features and their products...\n\n![](/assets/images/2022-01-17-22-18-25.png)\n\nLately being used in [[science.stats.Regression.Recommender Systems]]. There are claims they perform well...\n\nIn R formula language parlance it's a bit like this:\n\n$x~Bernoulli_logit(f(numeric_features)+categorical_features^2)$\nwhere f is deep [[^feed-forward-nets]] \nor so. The categorical features^2 part could be specied further, of course, and the \nBernoulli_logit sigmoid layer could be skipped.\n\nYou have to specify what feature interactions to directly include.\n\n\n\n# Convolutional Neural Networks ^cnn\n[[^symetries]]\n\n## AlexNet ^alexnet\n\n#  Recurrent Neural Networks\n* RNNs\n* Machine Translation, text generation\n* LSTM,GRU\n\n# Embeddings\n [[science.stats.Deep Neural Networks.Language Models#^word2vec]]\n ![[science.stats.Deep Neural Networks.Prod2Vec#^prod2vec]]\n\n\n\n \n\n\n# Deep Learning as Feature Extraction\n\n# Recommendation Systems (DL)\n\n## Deep Content-based Models\n\n### Spotify Example\n* [[#^cnn]] with audio spectrogram as input data.\n* [[science.stats.Deep Neural Networks.Max Pooling]] and global pooling\n* 'Bottleneck' layer [[science.stats.Deep Neural Networks.Auto-encoders]]\n* [[science.math.Optimization.Optimizers In in Neural Networks.ReLU]]\n* Output is the factor vector for the track from a __trained Collaborative Filtering model__. It's a model stack...[[science.stats.Stacking Models]]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Deep Factorization Machines\n[[science.stats.Regression.Support Vector Machines]]\n[[science.stats.Regression.Support Vector Machines.Factorization Machines]]\n#TODO - skip for now\n\n\n# Content2Vec ^content2vec\n\nCombine modular sets of feature extractors into 1 item embedding. E.g.\n[[#^alexnet]],[[science.stats.Deep Neural Networks.Language Models#^word2vec]], [[science.stats.Deep Neural Networks.Prod2Vec]], etc. \n\n\n\n\n\n\n\n# Frameworks/Libraries\n [[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming]]\n [[science.CS.theory.Code Transformations.Differentiable Programming.tensorflow]]\n [[science.CS.theory.Code Transformations.Differentiable Programming.pytorch]]\n [[science.CS.theory.Code Transformations.Differentiable Programming.jax]]\n [[science.cs.languages.CUDA]]\n\n\n\n\n","n":0.063}}},{"i":141,"$":{"0":{"v":"Vision Models","n":0.707},"1":{"v":"\n\n[[science.stats.Deep Neural Networks#^cnn]]\n\n\n# Image Classification\n\nNormally these models are trained on ImageNet and top-5 classification accuracy is reported.\n\nHere are some of the current champions that are also available as [[science.engineering.technologies.MLOps.ONNX]] models.\n\n## VGG-16\n![](/assets/images/2022-02-12-23-49-48.png)\n[Keras Link](https://keras.io/api/applications/vgg/)\n\n\n## ResNet\nUses Shortcut connections\n\n\n## EfficientNet-Lite4\n[Paper Link](https://arxiv.org/abs/1905.11946)\n[ONXX](https://github.com/onnx/models/tree/main/vision/classification/efficientnet-lite4)\n\n\n\n# Object detection and Image Segmentation\n\nObject detection and image segmentation algorithms draw rectangles on a picture and put labels on them.\n\n\n## Evaluation metrics\n\nA common evaluation metric are (from [here](https://medium.com/@vijayshankerdubey550/evaluation-metrics-for-object-detection-algorithms-b0d6489879f3)):\n### Intersection over Union (IoU):\n Evaluate the overlap of the two bounding boxes. Requires a true and predicted bounding box. So then we have something like:\n\n Intersection Over Union on top 5 Labels.\n \n\n### COCO mAP\nFor the COCO 2017 challenge, the mAP was calculated by averaging the AP over all 80 object categories AND all 10 IoU thresholds from 0.5 to 0.95 with a step size of 0.05. The authors hypothesize that averaging over IoUs rewards detectors with better localization.\n\n\n## Models/Algorithms\n\n### Yolo3\n[YoloV4](https://github.com/onnx/models/tree/main/vision/object_detection_segmentation/yolov3)\n\n\n# Body, Face, And Gesture Analysis\n\n\n# Image MNanipulation\n* Unpaired Image To Image Translation\n* Super REsolution \n* Fast Neural Style Transfer\n\n\n\n\n\n\n\n\n\n","n":0.078}}},{"i":142,"$":{"0":{"v":"Transformers","n":1},"1":{"v":"\nIt's a type of a [[science.stats.Deep Neural Networks.Attention Mechanisms]]\n","n":0.333}}},{"i":143,"$":{"0":{"v":"Transfer Learning","n":0.707},"1":{"v":"\nMost common usage:\nTake a pre-trained huge model, chop off last few layers, combine with other stuff.\n\n# Applications\n\n## Computer Vision.\n[[science.stats.Deep Neural Networks.Vision Models]]\n\nCases:\n* Fine-tuing a few layers\n* Fine tuning a whole model \n\n## NLP Vision\n","n":0.171}}},{"i":144,"$":{"0":{"v":"Recurrent Neural Networks","n":0.577}}},{"i":145,"$":{"0":{"v":"LSTM","n":1},"1":{"v":"\n\nThe LSTM has 2 'internal' states:\n$h$ and $c$.\nOverall, we operate with the following variables at each timepoint\n\n$x_t$ - input\n$h_t$: hidden state\n$c_t$: cell state- another state\n$f_t$ - 'forget' gate\n$i_t$ - 'input' gate\n$g_t$ - update gate\n$o_t$ - output\n\nAs well as dedicated matrices for everything:\n$f_i = sigmoid(W_{x,f}x_i+W_{h,f}h_{i-1})$\n\n$i_i = sigmoid(W_{x,i}x_i+W_{h,i}h_{i-1})$\n\n$g_i = tanh(W_{x,g}x_i+W_{h,i}h_{i-1})$\n\n$c_t=f_t\\cdot c_{t-1}+i_t\\cdot g_t$\n\n$o_i = tanh(W_{x,o}x_i+W_{o,i}h_{i-1})$\n\n$h_t=o_t\\cdot tanh(c_t)$\n\nThe basic idea here is that we put a bunch of multiplications around\n\n# GRU Simplification\n\nThere's a simpler way to achieve the above:\n#TODO \n\n\n\n\n","n":0.115}}},{"i":146,"$":{"0":{"v":"Prod2Vec","n":1},"1":{"v":"\n [Prod2Vec](https://recohut-projects.github.io/recohut/models.prod2vec.html) ^prod2vec\n","n":0.577}}},{"i":147,"$":{"0":{"v":"Max Pooling","n":0.707}}},{"i":148,"$":{"0":{"v":"Language Models","n":0.707},"1":{"v":"\n\n\n\n# Language Modelling\n\nPredict the next word or charater in a document. Can be used downstream for almost anything:\n * Text Classification\n * Question Answering\n * Sentiment Analysis.\n * Text Generation.\n\nTop Models:GPT-3, GPT-2, Megatron-ML.\n\n[[science.stats.Deep Neural Networks.Transformers]] wildly used.\n\n\nCan use Bert out of the box quickly and easily.\n## https://github.com/onnx/models#machine_comprehension\n\n# Word2Vec ^word2vec\n# Doc2Vec ^doc2vec\n\n\n# Machine Comprehension\n\n## GPT-2/3\n\n## BERT\n\n\n# Machine Translation\n\n[Transformer Cycle model](https://paperswithcode.com/sota/machine-translation-on-wmt2014-english-german)\n\n\n# Conversational Interfaces","n":0.128}}},{"i":149,"$":{"0":{"v":"Graph Neural Networks","n":0.577}}},{"i":150,"$":{"0":{"v":"GPUs","n":1},"1":{"v":"GPU's are fast, as they are efficient for matrix multiplication and convolution. Reason is GPU's are memory optimized (bandwidth), rather than compute optimized (speed).\n\n\n","n":0.204}}},{"i":151,"$":{"0":{"v":"Embeddings","n":1},"1":{"v":"\n\nEmbedding is the same thing as discovering a [[science.stats.Latent Variables]] representation and the goal is meaningful\n\n[[science.stats.Dimensionality Reduction]].\n","n":0.243}}},{"i":152,"$":{"0":{"v":"Auto-encoders","n":1}}},{"i":153,"$":{"0":{"v":"Attention Mechanisms","n":0.707},"1":{"v":"\n\n# Bahnadau Attention mechanism\n\nLet's start with training inputs $x_1,x_2,...,x_n$ as input sequence and $y_1,y_2,...,y_n$ as target sequence.\n\nThen we will have the following model:\n\n1. Compute $h_i = concat(h_{i,forward},h_{i,backward})$, encoding of 2 LSTM's, one ran forward and one ran backward __only on $x$- the input sequence__.\n2. Initialize $s_0$ randomly\n3.  Define $a_{0,j} = softmax(s_0,h_j$  for $j=1..N$.\n4. Define now $c_1 = \\Sum_{j=1..N}h_j*a_{0,j}$\n5. Postulate $s_1 = f(s_0,y_0,c_1)$\n6. Postulate $y_1 = g(y_0,s_1,c_1)$\n\nUnroll the above in a loop, so it becomes:\n1.  Define $a_{t,j} = softmax(s_{t-1},h_j$  for $j=1..N$.\n2. Define now $c_t = \\sum_{j=1..N}h_j*a_{t,j}$\n3. Postulate $s_t = f(s_{t-1},y_{t-1},c_t)$\n4. Postulate $y_t = g(y_{t-1},s_t,c_t)$\n\n\nNote now after training we only use $y$ in the last 2 equations, and $y_t$ appears only on the left-hand side of the last equation.\nThis gives a way to generate $y$.\n\n\n\n\nSimulate 'time flow' with masking.\n\n\n\n\n# Transformer Tutorial from \nhttps://www.jku.at/fileadmin/gruppen/173/Research/Introduction_to_Transformers.pdf\n\n### RNN Recap\nOutput $h^{(t)}$ is a function of input $e^{(t)}$ and the\noutput of the previous time step $h^{(t-1)}$.\n$h(t) = RNN(h(t-1), e(t))$\n\n$h^t$ - is hidden state\n\nIf part of a whole, we can say $h^t$ is a contextualized embedding of $e^t$.\n\n\n## Attention Networks\n\nGeneral Form :\n$O=Att(Q,V)$\nwhere all of the above are whole matrices:\n\n![](/assets/images/2022-03-02-17-10-22.png)\n\n![](/assets/images/2022-03-02-17-10-41.png)\n\nGiven a set of vector values $V$, and a set of vector\nqueries $Q$, attention is a technique to compute a\nweighted sum of the values, dependent on each query.\n\nThe weights in the weighted sums are called __attentions__\nand denoted by $\\alpha$.\n\nSo, then:\n\n$\\alpha_{i,j}$ - weight for \"query\" $i$ on \"value\" $j$.\n$alpha_i$ - attention for \"query\" $i$.  \n$\\sum(\\alpha_i)=1$.\n$\\alpha_{i,j} = f(q_i,v_j)$ \n\nwhere $f$ is some neural network.\n\nThe output $o_i= \\sum_{j=1..|V|}alpha_{i,j}*v_j$\n\n### Attention Variants\n \nUnnormalized dot product attention.\n\nLet \n$\\bar{a}_{i,j} = q_i*v_j$\n\n$a_{i,j} = \\frac{exp(a_{i,j})}{\\sum_j(exp(a_{i,j}))}$\n\n$v^{out}_j = \\sum_{j=1..}a_{i,j}*v_j$\nis then the contextual representation\nThe scaled version would be:\n\n$\\bar{a}_{i,j} = \\frac{q_i*v_j}{\\sqrt(d)}$\n\nAnother version w/ some paramters would be:\n\n$\\bar{a}_{i,j} = q_i*\\bold{W}*v_j$ where **W** is a parameter matrix.\n\n\n\nProblem w/ single- head attention is that softmax is quite 'sharp' and maybe there are multiple 'concepts' to learn (e.g. one is subject-object relation, another subject-verb, etc).\n\nIn multi-head attention, we can pre-project the embedding into a smaller space, and then concat the outputs.\n\n\n\n\n","n":0.056}}},{"i":154,"$":{"0":{"v":"Decision Trees","n":0.707},"1":{"v":"\nUsual decision tree fitting algorithms (e.g. ID3)  are [[science.CS.algos.Greedy Algorithms]].\n","n":0.316}}},{"i":155,"$":{"0":{"v":"Data Leakage","n":0.707},"1":{"v":"\n This happens when we somehow use information from the test set during training. This might happen in non-obvious ways sometimes, making it dangerous.\n","n":0.204}}},{"i":156,"$":{"0":{"v":"Correlation and Covariance","n":0.577},"1":{"v":"\n$var(v) = \\Sigma(v_i-E(v))^2 = E[(X-\\mu)^2]$\n\n$cov(X,Y) = \\Sigma((x_i-E(x))(y_i-E(y)))/n$  \n\nor (n-1) for sample covariance\n\n$cor(X,Y) = \\frac{cov(X,Y)}{\\sqrt{var(X)*var(Y)}}$\n\n\nPearson correlation\n\n\n\n\n\n\n\n\n\n\n# Large Correlation Matrices in R\n\n[blog post about bigCor](http://www.r-bloggers.com/bigcor-large-correlation-matrices-in-r/)\n\n","n":0.209}}},{"i":157,"$":{"0":{"v":"Confidence Intervals","n":0.707},"1":{"v":"\n\n In a frequentist setting, confidence intervals can be taken from the MLE + CLT via the identity:\n\n $P(-z_{\\alpha/2}<\\sqrt(I(\\theta)*(\\hat{\\theta}-\\theta)) < z_{\\alpha/2})\\approx 1-\\alpha$\n\n Where $z_{alpha}$ is the $1-\\alpha$- th quantile of the standard normal distribution:\n\n$z_{\\alpha} = \\Phi^{-1}(1-\\alpha)$,\nthat is:\n\n$P_{x\\approx N(0,1)}(x>z_{alpha})=\\alpha$\n\n\n","n":0.162}}},{"i":158,"$":{"0":{"v":"Central Limit Theorem","n":0.577}}},{"i":159,"$":{"0":{"v":"Boosting","n":1},"1":{"v":"\n Boosting is an iterative strategy for adjusting an observation's weight based on the previous classification.\n\n Related to [[science.math.modelling.Operations Research.Column Generation]].\n\n Gradient boosting\n","n":0.209}}},{"i":160,"$":{"0":{"v":"Bagging","n":1},"1":{"v":"\nBootstrap Aggregation:\n\nGenerate many datasets that are statistically similar to your training data, train models on them, and aggregate them together somehow.\n\n Intuitively, this will reduce overfitting (variance) at the cost of some bias and computation. You're forcing your model to be able to robust to reasonable changes in datasets.\n\n Due to this, best to use with learners with $high variance and low bias$: e.g. Decision Trees, knn, Nets.\n\n\n # Random forests are a bagging method\n","n":0.115}}},{"i":161,"$":{"0":{"v":"AdaBoost","n":1},"1":{"v":"\nFrom [Wikipedia](https://en.wikipedia.org/wiki/AdaBoost#Statistical_understanding_of_boosting)\n\n\nAdaBoost refers to a particular method of training a boosted classifier. \nA boost classifier is a classifier in the form\n\n$F_{T}(x)=\\sum _{t=1}^{T}f_{t}(x)$\nwhere each $f_{t}$ is a weak learner that takes an object $x$ as input and returns a __value indicating the class__ (NOT probability!) of the object. In the two-class problem, the sign of the weak learner output identifies the predicted object class and the absolute value gives the confidence in that classification. \n\n Similarly, the $T$th classifier is positive if the sample is in a positive class and negative otherwise.\n\nEach weak learner produces an output hypothesis, $h(x_{i})$, for each sample in the training set.\n\n At each iteration, a new weak learner is selected AND assigned a coefficient $\\alpha_t$\n\n  Similarly, at each iteration, every sample is also assigned a weight $w_{it}$, denoting the weight of the sample in the next iteration. This is set equal to the current error $L(y_i,F_{t-1}(x_i))$\n\nThe final classifier is the weighted sum of the weak classifiers, $F(x) = \\sum_{t=1}^{T} \\alpha_t h(x)$\n\n## Standard Error function:\n\nThe standard error function is exponential loss:\n$L(y_i,x_i) = e^(-y_*C(x_i))$ by abuse of notation,\nso \n$L(y,x;w=1) = \\Sigma_{i=1..n}e^{-y_i*C(x_i)}$\n\nThat would be with default weights.\nNow, if we define $w_{it} = e^{-y_i*C_{t-1}(x_i)} $ we can see that the 'outliers' get higher cost next time...\n\n## We also can fit $\\alpha_t$ together with the new classifier... \n\n\n\n\n","n":0.068}}},{"i":162,"$":{"0":{"v":"Bayesian Framework","n":0.707},"1":{"v":"\n\n[Statistical Rethinking with Pluto](https://github.com/StatisticalRethinkingJulia/SR2TuringPluto.jl?fbclid=IwAR3cSx-eiSB_KM-lq4rM1WT7HGDsJ5vFpJ9s9ZfzXbjyL5RywZr_kZdVcYo)\n\n[[engineering.technologies.tooling.Pluto]]","n":0.5}}},{"i":163,"$":{"0":{"v":"Autoregressive Models","n":0.707}}},{"i":164,"$":{"0":{"v":"AB Testing","n":0.707},"1":{"v":"\n\nFrom [DataInterviewPro](https://www.youtube.com/watch?v=X8u6kr4fxXc&ab_channel=DataInterviewPro)\n\n\n# A/B Testing or Experimental Design\nControlled experiments (e.g. clinical trials).\n\nUsually when we run experiments, we want to see difference in certain [[seed.Product Management.Product Metrics.User Based Metrics (Digital Products)]], e.g. ![[seed.Product Management.Product Metrics.User Based Metrics (Digital Products)#^active-users]].\n\n\n![[science.stats.tests#^ttest]] can be used in the simplest case, or some bayesian setup. \n\nType II error (or power). Power = 1 - Type II error.\n$sample_size \\approx \\frac{16\\sigma^2}{\\tau^2}$ where $\\tau$ is the effect size (difference in the metric chosen between the control and treatment group).\n\nAs we don't know $\\tau$, we can choose the __minimal detectable effect size__, equal to the minimal business-relevant effect size, i.e. the min effect that would justify a switch. \n\nNormally __decided by stakeholders__.\n\n# Multiple Testing Problems \n\nBayesian setup, Bonferroni correction, or something else.\n\nBonferroni correction:\ndivide significance level by the number of tests.\n\nBut sometimes too conservative, i.e. lower recall\n\nOr can control __False Discovery Rate__.\n\n$FDR = E[\\frac{falsePositives}{rejectiosn}]$.\nThis can be calculated, then choose a threshold for FDR, etc.\n\nIn a decision-making setup, can optimize the above...\n\n# Novelty and Primacy Effect\n\nUser behavior can either be resistent to change, or welcoming it, and we don't know apriori.\nIf the effect is initially large up/down and then gets closer to the baseline, this is the novelty/primacy effect.\n\n## Run Longer\n## Use Only New Users (or equivalent type matching)\nCan fix by running experiments on new users, or having the baseline be the behavior or new users when they were new, etc. In the latter case should maybe control for seasonality or other temporal effects as appropriate.\n\n\n# Interference between variants\n\n Happens most often when control and treatment groups interact somehow. \n If they interact like a 'standard' network effect (not competing for resources), we expect the actual effect to be larger than during the test. \n __Example__ FB posts promote more posts, so if small increase in population, will get larger.\n[[science.math.Game Theory.Agent Based Models]]\n![[science.math.Game Theory.Agent Based Models#^fbepidemology]]\n \n If 2-sided market, control and treatment groups compete for same resource. If we give better 'weapon' for treatment, after launch it would disappear, as everyone has better \"weapon\".\n__Example__ Better matching algo for Uber drivers. (or in the extreme case, prioritize some drivers over others- obviously the treatment group is more priviliged).\n\n## Isolation of effect\n\nTest between \"connected components\", e.g. New York vs LA (approximately, of course). Also can do temporally etc.\nSimplest is geographical splits.\n\nIn social network:\ntest on differennt 'clusters' of people.\n\n__Ego-network randomization__. A more scalable variation of the above.\n\n\n\n# AB testing for [[science.stats.Regression.Ranking]] \n[[engineering.system_design.ML System Design.Recommender Systems]]\n\nPlease also see [[science.stats.Regression.Loss Functions#^ranking-start]].\n\nComparing two rankings via clicks.\nSay 2 algorithms give 2 rankings, Ranking A, ranking B.\nMerge-sort-remove-duplicates interleaving the rankings.\nAssign first element randomly.\nCount clicks from A and B. Better one will on average get more rankings.\n\n","n":0.048}}},{"i":165,"$":{"0":{"v":"Probability","n":1}}},{"i":166,"$":{"0":{"v":"Theory","n":1}}},{"i":167,"$":{"0":{"v":"Radon Nikodym Derivative","n":0.577},"1":{"v":"\nradon nikodym derivative\n\n[Some -maybe wrong observations](https://docs.google.com/document/d/1M2DfKqAx4AijTccnBaR4IUYWmk3aZ4KoyxovehF7CQw/edit)\n\n[Reference](http://fds.duke.edu/db/attachment/1673)","n":0.408}}},{"i":168,"$":{"0":{"v":"Financial Markets","n":0.707},"1":{"v":"\nкорелация между волатилност и реалзиран обем във финансовите пазари.\n\n","n":0.333}}},{"i":169,"$":{"0":{"v":"Distributions","n":1}}},{"i":170,"$":{"0":{"v":"weibull","n":1}}},{"i":171,"$":{"0":{"v":"skalem","n":1}}},{"i":172,"$":{"0":{"v":"poisson","n":1},"1":{"v":"\n# PMF\n\n$pdf(x,\\lambda) = e^{-\\lambda}\\lambda^{x}/x!$\n\n\n","n":0.5}}},{"i":173,"$":{"0":{"v":"gaussian","n":1},"1":{"v":"[[science.stats.Regression.Linear Regression]]\n","n":0.707}}},{"i":174,"$":{"0":{"v":"gamma","n":1}}},{"i":175,"$":{"0":{"v":"exponential","n":1}}},{"i":176,"$":{"0":{"v":"binomial","n":1},"1":{"v":"[[science.probability.Distributions.bernoulli]]\n","n":1}}},{"i":177,"$":{"0":{"v":"beta","n":1}}},{"i":178,"$":{"0":{"v":"bernoulli","n":1}}},{"i":179,"$":{"0":{"v":"Theory","n":1},"1":{"v":"\n\n# Likelyhood and Probability\n\n# MLE\n\n# Fisher and Expected Information\n\n\n# MCMC and Sampling\n\n[[science.cs.theory.Code Transformations.Differentiable Programming.turing]]\n[[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming.stan]]\n\n\n","n":0.236}}},{"i":180,"$":{"0":{"v":"LIinearity Of Mean And Variance","n":0.447},"1":{"v":"\n\nlet $x_1,x_2,...,x_n$ is a random draw.\nlet $\\bar{x}= \\Sigma_{i=1..n}x_i/n$\nlet $E[x]=\\mu$\nwhat is $E[\\bar{x}]$?\n$E[\\bar{x}] = E[\\Sigma_{i=1..n}x_i/n]=1/n  E[\\Sigma_{i=1..n}x_i] = 1/n*nE[x] = \\mu$\n$Var(\\bar{x}) = E[(\\bar{x}-E[\\bar{x}])^2] = $\n\n$E[(x-E[x])^2]=E[x^2-2xE[x]+E[x]^2] = E[x^2]-2E[xE[x]]+E[x]^2 = E[x^2] - E[x]^2$\n\n$E(\\bar{x}^2) = E[\\bar{x}]^2+Var[\\bar{x}] $\n\n## Variance of Linear Combinations ##\n\nLet $X_1,X_2,...,X_n$ are independent random variables with means\n$\\mu_1,\\mu_2,...,\\mu_n$ and variances $\\sigma_1^2,\\sigma_2^2,...,\\sigma_n^2$.\n\n\nThen:\nLinearity of variance\n1. $E[\\Sigma_{i=1..n}\\alpha_iX_i] =\\Sigma_{i=1..n}\\alpha_i\\mu_i$\n2. $Var[\\Sigma_{i=1..n}\\alpha_iX_i] =\\Sigma_{i=1..n}\\alpha_i^2\\sigma_i^2$\n\n## Proof:\nThe expectation is obvious.\n\n\nFirst, let's show that independence implies $Cov(X,Y) = 0$\nIndependence implies: $E(XY) = E(Y)E(X)$\n\nThen:\n$$\nCov(X,Y) = E[(X-E[X])(Y-E[Y])] = E(XY-E[X]Y-E[Y]X-E[Y]E[X]) = \\\\\nE[XY] - E[X*E[Y]]-E[Y*E[X]] +E[X]E[Y] = \\\\\nE[X]E[Y] -E[X]E[Y]-E[X]E[Y]+E[X]E[Y]=0\n$$\n\nFor Var:\n$$\nVar(\\Sigma_{i=1..n}\\alpha_iX_i)  =E[\\Sigma_{i=1..n}\\Sigma_{i=1..m} a_i a_j(X_i-\\mu_i)(X_j-\\mu_j)] = \\\\\nE[\\Sigma(a_i^2(E([X_i-\\mu)^2])-2*a_i*a_j(E[X_i]-\\mu_i)(E[X_j]-\\mu_j)] - \\\\\nE[\\Sigma{a_i^2*Var(X_i)+0}] = \\Sigma_{i=1..n}\\alpha_i^2\\sigma_i^2  \n$$\n\nWhere we used that $E[(X_i-\\mu_i)(X_j-\\mu_j)] = 0$ if $i\\ne j$.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","n":0.1}}},{"i":181,"$":{"0":{"v":"Stable","n":1}}},{"i":182,"$":{"0":{"v":"Distribution","n":1},"1":{"v":"# Distribution\n[[science.probability.Distributions.gaussian]]\n[[science.probability.Distributions.bernoulli]]\n[[science.probability.Distributions.gamma]]\n[[science.probability.Distributions.exponential]]\n[[science.probability.Distributions.beta]]\n[[science.probability.Distributions.weibull]]\n[[science.probability.Distributions.poisson]]\n[[science.probability.Distributions.skalem]]\n[[science.probability.Distributions.Stable]]\n\n# Random variables\n\n# Expectation\n[[science.probability.Distributions.Theory]]\n\n## Tower Theorem\n\n# Variance\n## Standard Deviation\n\n# Moments\n# PMF/PDF (Probability Mass Function/Probability Density Function)\n\n# CDF (Cumulative Distribution Function)\n## Sampling Given the CDF and uniform distribution sampler\n\n# Hazard Function\n# Quantiles\n# Integral Transforms\n# MLE\n\n# Centrality Measures\n## Mean\n## Median\n## Mode\n\n\n# KL Distance\n[[math.theory.Information Theory]]\n\n\n\n","n":0.152}}},{"i":183,"$":{"0":{"v":"Math","n":1},"1":{"v":"[[root.science.CS]]\n\n","n":1}}},{"i":184,"$":{"0":{"v":"Logic","n":1}}},{"i":185,"$":{"0":{"v":"Predicates","n":1}}},{"i":186,"$":{"0":{"v":"LessWrongArguments","n":1}}},{"i":187,"$":{"0":{"v":"Deceptive AI Recall Session","n":0.5},"1":{"v":"\ndeceptiveness and ai\n\ntraining 'against' deception wont work\nsay it's against 'overtly deceptive' things, or even if some introspection techniques work,\nthe 'i'will deceive now' thought pattern.\n\nSo, not only deceptive output, but also precursors.\n\nWe show how generically useful thought patterns that are not deceptive by themselves \nwhen combined can produce deceptive output.\n\nimagine if the thought matches a predicate, it's marked as deceptive\n[[science.math.logic.predicates]].\n\nsay the ai is a bit anthropomorphic, and it can spawn threads of thought\nwe name appropriately ('planning thread', monitoring thread, threads for different subtasks),\nand it also has ....\n\n\nconclsion picture:\n\nai as a problem solver can develop a 'abstractize the problem in a way that deception is not in the model',\nsolve it, invert the solution in steps that don't refer to deception...\n\n\n\nexample - sends instructions to a human-controlled wet lab to execute, blah blah biological goal, delays in the lab if instructions too long, ai notices a pattern, tries several things, where it notices threads get terminated for no apparent reason (every time the 'deceive' predicate) is matched, eventually represents everything as some kind of search in a graph or a vehicle routing or a markov decision process that doesn't \nrefer to the humans and thus doesn't involve deception, it's not terminated, the inverted sequence of steps doesn't refer to deception.\n\nBonus:\n\nHow it also can notice it's forbidden to think about the specific predicate and thart 'thinkingabout that...'\n\n----\n#todo complete the incomplete parts of the [Deep Deceptieveness](https://www.lesswrong.com/posts/XWwvwytieLtEWaFJX/deep-deceptiveness).\n \n check more carefully what happens when talking about the 'fgure out the deception pattern' moment...\n\n\n\n\n\n---","n":0.064}}},{"i":188,"$":{"0":{"v":"Theory","n":1}}},{"i":189,"$":{"0":{"v":"Dynamical Systems","n":0.707}}},{"i":190,"$":{"0":{"v":"Cones","n":1}}},{"i":191,"$":{"0":{"v":"Computer Algebra Systems (Symbolics)","n":0.5},"1":{"v":"\n# Mathematica\n[[science.cs.languages.Mathematica]]\n\n# SymPy\n[[engineering.technologies.ML.Libraries.SymPy]]\n[[engineering.technologies.ML]]\n[[engineering.technologies.ML.Libraries]]\n[[science.cs.languages.python]]\n\n# Modeling Toolkit (Julia)\n[[science.math.Optimization.ModelingToolkit]]\n[[science.cs.languages.julia]]\n","n":0.408}}},{"i":192,"$":{"0":{"v":"Algebra","n":1}}},{"i":193,"$":{"0":{"v":"Matroids","n":1}}},{"i":194,"$":{"0":{"v":"Modelling","n":1}}},{"i":195,"$":{"0":{"v":"Operations Research","n":0.707},"1":{"v":"\n[[science.math.Optimization]]\n[[science.math.Optimization.Mixed Integer Programming]]\n[[science.math.Optimization.Linear Programming]]\n[[science.math.modelling.Operations Research.Queuing Theory]]\n","n":0.408}}},{"i":196,"$":{"0":{"v":"Scheduling","n":1}}},{"i":197,"$":{"0":{"v":"Load Balancing","n":0.707},"1":{"v":"\n\n# Round Robin\n\n# Lowest estimated completion time.\n\n# Least busy server\n\n\n\n# Book Reference\n(Book by pascal)[https://mitpress.mit.edu/contributors/pascal-van-hentenryck]\n\n","n":0.267}}},{"i":198,"$":{"0":{"v":"Queuing Theory","n":0.707},"1":{"v":"\n[[science.CS.algos.Control in Networks]]\n\n# Queuing Theory","n":0.447}}},{"i":199,"$":{"0":{"v":"Facility Location","n":0.707}}},{"i":200,"$":{"0":{"v":"Column Generation","n":0.707},"1":{"v":"\n\nColumn generation is related to gradient boosting [Bengio article](http://nicolas.le-roux.name/publications/Bengio06_convex.pdf).\n\n\n[Column Generation Example With JuMP](http://www.juliaopt.org/notebooks/Shuvomoy%20-%20Column%20generation.html).\n\n","n":0.277}}},{"i":201,"$":{"0":{"v":"Differential Equations","n":0.707}}},{"i":202,"$":{"0":{"v":"Decision Theory","n":0.707}}},{"i":203,"$":{"0":{"v":"Mode","n":1},"1":{"v":"\n\n# Introduction\n\n# Separable ODE\n\n# First Order ODE\n\n# Special ODE Forms\n## Ricatti\n[[Optimal Control]] Linear Quadratic Regulator.\n[[science.engineering.Robotics]]\n\n\n# Differential Equations in Julia\n[[science.cs.languages.julia]]\n\n\n\n\n\n","n":0.229}}},{"i":204,"$":{"0":{"v":"Calculus","n":1},"1":{"v":"\n# Univariate Derivatives\n\n# Gradients as Linear Operators\n\n# Matrix Derivatives\n\n\n","n":0.333}}},{"i":205,"$":{"0":{"v":"Stokes Theorem","n":0.707},"1":{"v":"\n# Stokes Theorem\n\n\nConnects an integral over $n$ dimensional region to an integral over an $n-1$ dimensional boundary.\n\nIncludes as special cases [[science.math.calculus.Fundamental Theorem of Calculus]] and [[science.math.calculus.Green's Theorem]].\n\n\n## Motivation and Heuristic\n\nNow, imagine we want to calculate the integral $\\int_C F\\cdot n$. Call this a 'circulation' across the boundary $C$.\n\nNow, we can see that if we 'cut up' C into pieces $C_1,C_2$, it's additive in the bellow sense:\n\n$$\n\n\\int F\\cdot n = \\int_{C_1} F\\cdot n + \\int_{C_2} F\\cdot n\n\n$$\n\nOf course, we can cut more:\n\n\n\n$$\n\n\\int_C F\\cdot n = \\sum_{i=1..n} \\int_{C_i} F\\cdot n \n\n$$\nIf we cut an infinitly and make the curves $C_i$ enclose infinitesimal regions, we can reach the limit:\n\n\n$$\n\n\\int_C F\\cdot n = \\int_R (\\int_{C_i} F\\cdot n)  dR =\\\\\n\\int_C F\\cdot n = \\int_R curl(F)  dR =\\\\\n\n$$\n\nWhere we just call curl(F) the limit of $\\int_{C_i} F\\cdot n$ as  $C_i$ grows smaller and smaller.\n\nNow, let's calculate this limit in a 2d setting, assuming we cut into rectangles.\n\nBellow is the solution in cartesian coordinates.\n\n![](/assets/images/2022-07-05-10-34-17.png)\n\n\n\nVery important:\n[[science.math.calculus.Conservative Forces]]","n":0.079}}},{"i":206,"$":{"0":{"v":"Numerical Methods","n":0.707},"1":{"v":"# [Don't Invert That Matrix](https://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix/) ^numerical_methods_dont_invert\n\n\n\n","n":0.408}}},{"i":207,"$":{"0":{"v":"Green's Theorem","n":0.707},"1":{"v":"\n\nThis gives the relationship between line integral of a simple loop and a double integral of a 2D region in a plane the sipmle loop encircles.\n\n\n\n![](/assets/images/2022-07-05-09-14-11.png)\n\n Note to self:\n\n The circle on the integral denotes that we traverse the thing clockwise. Interestingly, as the integral symbol+ the $dx$ notation together determine what the 'sum' is taken over, we can expect some tricky notations there.\n\n # Proof\n\nTake the two most 'distannt' points, along x, so we can split the curve $C$ into $C_1,C_2$, and have both be parametrized \n$C_1 = (x,f_1(x))$, $x\\in[a,b]$\n$C_2 = (x,f_2(x))$, $x\\in[a,b]$\n\nThen, to traverse C clockwise, we traverse $C_1$ forward, and $C_2$ backwards.\n\n$$\n\\int_{C} dx = \\int_{C_1} dx + \\int_{C_2}  dy\n\\\\\n\\int_{C}P dx = \\int_{C_1}P dx + \\int_{C_2} P dy\n\\\\\n\n$$\n\nThen:\n\n$$\n\\int_D \\frac{dP}{dy} dy dx =  \\int_{a}^{b}\\int_{f_1 (x)}^{f_2 (x) }\\frac{dP}{dy} dy dx = \\\\ \n\\int_{a}^{b} P(x,f_2(x))-P(x,f_1(x))- dx \\text{ fundamental th. of algebra} = \\\\\n\\int_{C_2} P dx-\\int_{C_1} P dy  = \\\\\n-\\int_{C} P dx\n\n$$\n\nSimilarly for Q, we arrive to the above...\n\nTo summarize:\n\n1. We aplit the region into 2 curves, then re-parametrized the internal stuff, using the 'lower' and 'upper' curve.\n2. We showed that using thie representation and the fundamental theorem of algebra, we have what we need for the x-portion of the curve-normal integral\n3. Analogous for $Q$\n\n\n\n\n# [[science.math.calculus.Stokes Theorem]]\n\n\n\n","n":0.07}}},{"i":208,"$":{"0":{"v":"Gradient","n":1}}},{"i":209,"$":{"0":{"v":"Fundamental Theorem of Calculus","n":0.5}}},{"i":210,"$":{"0":{"v":"Conservative Forces","n":0.707},"1":{"v":"\n#TODO - check out the [Brilliant Article](https://brilliant.org/wiki/conservative-forces/)\n\n\nWork Done:\n\n$W = \\F*d$ (when F is constant, etc)\n\n\nWork done formula:\n\n$WD =  \\int \\bold{F}\\cdot d \\bold{r}$\n\n\n\nA conservative force is a force whose work done is independent of the path it took.\n\nClassical example: Kinetic energy+ potential energy.\n\n\nPath independence of concervative forces: additional\n\n\n# Gravitational Potential Energy\n\nGravity is a concervative force.\n\n\n\nFriction is non-concervative.\n\nProperties of concervative forces: defines\n\n\n# Test Path-independence DIRECTLY\n\n\n$\\int_{A,p_1}^{B} F\\cdot r=  \\int_{A,p_2}^{B} F\\cdot d$\nFor every $p_1,p_2$ between A and B.\n\n\n\n\n# Loop property\n\n\nCheck that the work around a loop is 0.\n\n\n# A concervative force is the gradient of something (Energy)\n\nif a force field can be expressed as $\\vec f = \\nabla \\bold F$\n\nProof:\n\nI guess the fundamental theorem of algebra (?)\n\n\n# A concervative field has a curl of 0\n\nSo that is:\n\nif \n$\\vec f =h*\\vec x+i*\\vec y+j*\\vec z$\n\n$(\\frac{d j}{dy}-\\frac{d i}{dz})\\vec x+(\\frac{dh}{dz}-\\frac{dj}{dx})\\vec y+(\\frac{di}{dx}-\\frac{dh}{dy})\\vec z=0$\n\n Proof- Stokes theorem .\n","n":0.085}}},{"i":211,"$":{"0":{"v":"Stochastic Calculus","n":0.707},"1":{"v":"\n\n# Martingales\n\n# Brownian Motion\n","n":0.5}}},{"i":212,"$":{"0":{"v":"Filtration","n":1},"1":{"v":"\nA __Fitration__ models the evolution of information through time.\n\n\n","n":0.333}}},{"i":213,"$":{"0":{"v":"SU thesis","n":0.707},"1":{"v":"[SU Research notes](https://drive.google.com/open?id=0B-C_0LZtyGcNYzM0NDZiNmItYWZmOC00YmI1LTg4NDctODIyZGM5OGFkMjI2&resourcekey=0-DlawjpqLBM8TS81wyYwlgw&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n\n","n":0.577}}},{"i":214,"$":{"0":{"v":"Optimization","n":1},"1":{"v":"\n## Continous Optimization\n[[science.math.Optimization.Gradient Descent]]\n[[science.math.Optimization.Optimizers In in Neural Networks]]\n[[science.math.Optimization.Linear Programming]]\n[[science.math.Optimization.Convex Optimization]]\n\n\n## Discrete Optimization\n[[science.math.Optimization.Constraint Programming]]\n[[science.math.Optimization.Mixed Integer Programming]]\n\n\n## Special Cases\n[[science.CS.algos.Graph Traversal]]\n[[science.CS.algos.MiniMax]]\n[[science.CS.theory.NP-complete Problems]]\n\n## Sequence Optimization\n[[science.math.Optimization.Optimal Control.Classic Optimal Control Theory]]\n[[science.math.optimization.Dynamic Programming]] ^cF8Y6fTJS0AH\n[[]]\n\n\n\n## Sequence Optimization\n\n\n","n":0.186}}},{"i":215,"$":{"0":{"v":"Dynamic Programming","n":0.707}}},{"i":216,"$":{"0":{"v":"Range DP","n":0.707},"1":{"v":"F\n[Here](https://usaco.guide/gold/dp-ranges?lang=cpp","n":1}}},{"i":217,"$":{"0":{"v":"Knuth's Optimizaiton","n":0.707},"1":{"v":"\nUsed for Range DP's, hence something involving functions $f(i,j)$, where i-j represents the range in an array or so.\nExample:\nsubset sum.\n\nDP principles:\n","n":0.218}}},{"i":218,"$":{"0":{"v":"Approximate Dynamic Programming","n":0.577},"1":{"v":"\n\n#[Powell Paper](https://castlelab.princeton.edu/html/Papers/Powell-NRLWhat%20you%20should%20know%20about%20approximate%20dynamic%20programming.pdf)\n[[science.math.Optimization.Linear Programming.Stochastic Programming]]\n[[science.stats.Deep Neural Networks]]\n[[science.math.Optimization.Mixed Integer Programming]]\n\n# [Some Ideas in Google Doc I had](https://docs.google.com/document/d/1L49VzAMKQ4BLp5WAo_DV_IzUkNe29YVKHsVtWc0EjEk/edit?usp=sharing)\n\n\n","n":0.258}}},{"i":219,"$":{"0":{"v":"Stochastic Gradient Descent","n":0.577},"1":{"v":"\n\n\n[This article claims SGD considers only 1 example at a time.](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a)\n\n\n[This corraborates](https://optimization.cbe.cornell.edu/index.php?title=Stochastic_gradient_descent).\n\nSo SGD takes only 1 example, batch takes all, minibatch takes a subset of $n$ examples.\n#minibatch #batch","n":0.189}}},{"i":220,"$":{"0":{"v":"Simplex","n":1},"1":{"v":"Simplex is like Gradient Descent if we know the perfect step size.\n\n","n":0.289}}},{"i":221,"$":{"0":{"v":"Semidefinite Optimzation","n":0.707},"1":{"v":"\n[[science.math.Linear Algebra]]\n[[science.math.theory.Cones]]\n","n":0.707}}},{"i":222,"$":{"0":{"v":"Second Order Optimizers","n":0.577},"1":{"v":"\n## Newton's Method\n\n## BFGS and L-BFGS\n\n##  Levenberg-Marquardt Algorithm\n[Levenberg Marquardt Algorithm](https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm)\n","n":0.316}}},{"i":223,"$":{"0":{"v":"Regularizations","n":1},"1":{"v":"# $L_1$or $L_2$ regularizations in regression\n[[science.stats.Regression.Linear Regression]]\n\n# MAP vs MLE\n[[science.stats.Regression.Linear Regression]]\n\n\nGiven a dataset X, a common task is to try to estimate the most likely values for the model parameters. To do this, you must find the values that maximize the likelihood function, given X. In this example, if you have observed a single instance x=2.5, the maximum likelihood estimate (MLE) of θ is $\\hat{\\theta}=1.5$. If a prior probability distribution g over θ exists, it is possible to take it into account by maximizing $L(θ|x)g(θ)$ rather than just maximizing $L(θ|x)$. This is called __maximum a-posteriori (MAP) estimation__. Since MAP constrains the parameter values, you can think of it as a regularized version of MLE.\n\nFor example $L_1$ regularization is equivalent to putting a Laplace prior on the parameters, whereas\n$L_2$ regularization is equivalent to putting a Gaussian prior on them.\n\n# L1, L2, Ridge, Tikhonov, LASSO\n\nRidge regression has a closed form solution.\n\n[[science.math.Norms and Metrics]]\n\n# Dropout\n![[science.math.Optimization.Regularizations.Dropout]]\n\n\n\n\n\n","n":0.081}}},{"i":224,"$":{"0":{"v":"Dropout","n":1},"1":{"v":"\n\nDropout:\n1. At training time, in each training epoch, drop out nodes/connections randomly by setting their weights to zero.\nEach node weight is set by 0 with probability $p$.\n2. At testing/inference time, multiply each learned weight by $p$.\n\nJustification:\nWe 'stochastically train' simultaneously $2^{|NN|}$ models,where $|NN|$ is the network size.\nThus at the end of training we may pretend we have $2^{|NN|}$ candidate models. That is, we can drop any number of nodes and still have a model.\nNow, ideally, on inference time, we may :\nFor each subset of nodes, disable them, and predict on the basis of the rest, and then take the average.\nBut this is obviously infeasible.  So we approximate their 'model average' by **multiplying the weights by $p$**.\n\n","n":0.093}}},{"i":225,"$":{"0":{"v":"Optimizers In in Neural Networks","n":0.447},"1":{"v":"\n\n[[science.math.Optimization.Gradient Descent]]\n[[science.math.Optimization.Stochastic Gradient Descent]]\n[[science.math.Optimization.Adam Optimizer]]\n\n# Early Stopping\n\n# Momentum\n","n":0.354}}},{"i":226,"$":{"0":{"v":"ReLU","n":1},"1":{"v":"\nActivation function.\n","n":0.707}}},{"i":227,"$":{"0":{"v":"Negative Sampling","n":0.707},"1":{"v":"\nIn a context where finally we have a 'classifier' that outputs a one-hot vector, \nwe have essencially a large-cardinality multinomial distribution.\n\nthe likelyhood has terms then for all possible categories. They can be many (e.g. [[science.stats.Deep Neural Networks.Language Models#^word2vec]]).\n\nThen, to speed up things, we pretend for this training example only that the multinomial distribution\nis much smaller (e.g. pick 5 random 'negative' examples).\nThen compute the loss and corresponding gradients (for this iteration) based on that.\n\n[Source: Mccormickml tutorial](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/#:~:text=Negative%20sampling%20addresses%20this%20by%20having%20each%20training,output%E2%80%9D%20of%20the%20network%20is%20a%20one-hot%20vector.)\n","n":0.115}}},{"i":228,"$":{"0":{"v":"Batch Normalization","n":0.707}}},{"i":229,"$":{"0":{"v":"Optimal Control","n":0.707}}},{"i":230,"$":{"0":{"v":"Reinforcement Learning","n":0.707},"1":{"v":"\n\n\n# Actor-Critic modules\n\n[Actor - Critic Models](http://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_5_actor_critic_pdf)\n\n# Bandits ^bandits\n\n\n\n","n":0.354}}},{"i":231,"$":{"0":{"v":"Markov Decision Process","n":0.577},"1":{"v":"\n\n\nA Markov Decision Process (MDP) is a stochastic process that is characterized by a set of states, a set of actions, and a transition function.\n\n$S$: States\n\n$A$: Actions\n\n$P(s'|s,a)$: Transition function\n\n$R(s,a)$: Reward function\n\n$T$: Terminal states\n\n<!-- We would like to find a policy $\\Pi:S->A$ that maximizes the expected reward $E\\Sigma_{s'\\in S} R(s',a) P(s'|s,a)$.\n\nWe can solve this by solving the Bellman equation:\n\n$$\\sum_{s'\\in S} R(s',a) P(s'|s,a) = \\sum_{s'\\in S} R(s',a) P(s'|s,a) + \\gamma \\sum_{s'\\in S} P(s'|s,a) \\max_{a'\\in A} R(s',a')$$\n\nwhere $\\gamma$ is the discount factor.\n\nThe optimal policy is then given by the following equation:\n\n$$\\Pi(s) = \\arg\\max_{a'\\in A} R(s,a')$$\n\nThe optimal policy is a function that maps\n -->\n","n":0.1}}},{"i":232,"$":{"0":{"v":"Classic Optimal Control Theory","n":0.5}}},{"i":233,"$":{"0":{"v":"Objective Functions","n":0.707}}},{"i":234,"$":{"0":{"v":"Newton-Rhapson Method","n":0.707},"1":{"v":"\n\n\nLet's try to solve $f(x) = 0$ iteratively for a sufficiently smooth function $f$.\nWe have $0 = f(x) \\approx f(y) +(x-y)f'(y)$. Thus $x-y = -\\frac{f(y)}{f'(y)}$\nIf we plug in $y = x_{i}$, $x = x_{i+1}$, we have a proposal for the iterative update $x_{i+1}-x_{i} = -\\frac{f'(x_i)}{f(x_i)}$.\nWe can calculate appropriate step size for this if we instead write the above to 2nd order of approximation.\n#TODO\n\n\n\n","n":0.126}}},{"i":235,"$":{"0":{"v":"ModelingToolkit","n":1},"1":{"v":"\n Julia's moddling toolkit package allows to build up systems of equations by using a DSL, main thing\n is $~$ is used instead of $=$ so universe doesn't explode. \nIt supports function variables as well\n\n[[science.cs.languages.julia]]\n[[science.math.modelling.Differential Equations]]\n[[science.math.Optimization.Optimal Control.Classic Optimal Control Theory]]\n\n","n":0.158}}},{"i":236,"$":{"0":{"v":"Mixed Integer Programming","n":0.577}}},{"i":237,"$":{"0":{"v":"Linear Programming","n":0.707},"1":{"v":"\n[[science.math.Optimization.Simplex]]\n\n[[science.math.Optimization.JuMP]]\n\n\n\n\n\n# Resources\n\n\n\n#lowprio\n[Some Matlab LP book link](https://drive.google.com/open?id=0B-C_0LZtyGcNaVluTjBvZDlNUGc&resourcekey=0-d9atqT3fimtNzM9F_9fhOQ&authuser=stefanvpetrov%40gmail.com&usp=drive_fs).\n\n# Duality\n\nSuppose we have the following linear program in a \ncannonical form:\n\n$$\n\\text{minimize } c\\cdot x\n\\\\\n\\text{subject to } Ax \\leq b,\\\\ x \\geq 0\n\n$$\n\nThen, let's define the following polytope in the variables $y$:\n\n$$\nA^T y \\geq c\\\\\n\ny \\geq 0\n\n$$\n\nThen, left-multipying both sides of the primal polytope by the $y^T$, we get:\n\n$y^T b\\geq y^T A x\\geq c^Tx$\n\nThus, $y^T b$ is an upper bound for $c^T x$, and if we consider the following dual program:\n$$\n\\text{min } y^T b \\\\\nA^T y \\geq c\\\\\n\ny \\geq 0\n$$\n\nWe get the smallest upper bounds...\n\n\n\n\n","n":0.105}}},{"i":238,"$":{"0":{"v":"Stochastic Programming","n":0.707},"1":{"v":"\n# [SDDP](https://juliapackages.com/p/sddp)\n","n":0.707}}},{"i":239,"$":{"0":{"v":"Danzig-Wolfe Decomposition","n":0.707},"1":{"v":"\n\nThe dual of [[science.math.Optimization.Linear Programming.Stochastic Programming.Benders Decomposition]]\n\nColumn generation, roughly speaking;\n\nIn a linear program, we have a set of constraints, and a set of variables. Imagine the set of variables is very large, so as to perhaps be untracktable.\n\nFor example, in a max-flow problem all possible paths might be considered, and in a graph $G=(V,E)$, the number of paths between two verticles $s,t$ might be exponential in $E$.\n\nWe will generate the 'path' variables on the fly, by using the following two principles:\n\n\n1. If we have an optimal solution for the problem with number of variables, the dual solution $y$ is still the 'correct size' (i.e. in the above case, capacity and balance constraints). Thus we can ask 'hey, in our combinatorial set, can we find an element $\\bar{x}$ s.t. $(c-A^Ty)\\cdot\\bar{x}<=0$ .\nThe quantity $c-A^Ty$ is called 'reduced cost vector' and is essencially the derivative of the objective function with respect of some variable vector x.\nMore detail [in the wikipedia article](https://en.wikipedia.org/wiki/Column_generation#:~:text=Column%20generation%20or%20delayed%20column,a%20subset%20of%20its%20variables.)\nThe reaso for the  changed objective function is that in our constrained optimization problem, as something enters the basis, the other variables need to change values so we're still inside the polytope.\n\n2. The 'size' of the solution, i.e. the number of variables, entering the basis, is limited by the number of rows. Thus the procedure terminates at some point\n\n\n\n\n\n\n\n","n":0.068}}},{"i":240,"$":{"0":{"v":"Benders Decomposition","n":0.707},"1":{"v":"\n[[science.math.Linear Algebra.Matrix Decompositions]]\n\n[[science.math.Optimization.Linear Programming]]\n[[science.math.Optimization.Linear Programming.Stochastic Programming]]\n\n\n\nThere is now a nice [Wikipedia article](https://en.wikipedia.org/wiki/Benders%27_decomposition).\n\nFollowing that, we note:\n\nStarting with:\n\n$$\n\\text{minimize } c\\cdot x + d \\cdot y\\\\\n\\text{subject to } Ax + By \\leq b, \\\\ x \\geq 0,\n\\\\ y \\in Y\n\\\\x \\geq 0\n$$\n\nNow, the x-variables are 'simple', in the sense that they are in a polytope wrt the y-variables.\n\nOn the other hand, the y-variables may be a part of a more annoying structure.\n\nNow, let's consider the problem with the y-variables fixed.\nIt's primal now becomes:\n\n$$\n\\text{minimize } c\\cdot x \\\\\n\\text{subject to } Ax \\leq b- B\\bar{y}\n\\\\ x \\geq 0\n$$\n\nThe dual of that now becomes:\n\n\n$$\n\\text{minimize } (b-B\\bar{y})\\cdot z \\\\\n\\text{subject to } A^Tz \\geq c \n\\\\ z \\geq 0\n$$\n\nIn the wikipedia it looks a bit differently...\n\nBut okay, now the key part is that the polytope of the dual is the same, regardless of the choice of \\bar{y}, only the objective function changes...\n\nNow, remember the 'Minkovski formulation' for a linear problem. Essencially, it uses the fact we have to check only the following:\n\nFor a solution value:\n1. Check the solution value at the proposed point <= value at every vertex.\n2. For each infinite ray of the check if the slope of the objective value has a negative angle with them (if it does, it's unbounded).\n\nThus, as we solve the subproblems, we either get a solution, or a sertificate of unboundedness (as an infinite ray).\n\nWe add the corresponding cut to the master problem.\n\nNamely:\nFor every vertex in \n\nNow, remember the criteria for unboundedness.\n\n\n\n\n\n","n":0.064}}},{"i":241,"$":{"0":{"v":"Clustering Problem","n":0.707},"1":{"v":"\n# Clustering Problem\n\nGiven $64$ input clusters, with (I think) 63 features $f_{c,i}$, the following algorithm does as follows:\n\n1. Partition all initial clusters into 2 subsets:https://fburl.com/code/9mb3uv3f2\n\n For each subset, find a feasible solution of the 'feature balancing problem':\nhttps://fburl.com/code/mqq6h3vo\n\n1. $x_{ij}\\in {0,1}$ is the decision variable representing if the $i^{th}$ cluster belongs to the $j^{th}$ group\n\n2. $c_{ij}$ represents the data in the $i^{th}$ cluster and $j^{th}$ feature\n\n3. $\\epsilon_f$ is the maximum allowed imbalance for the $f^{th}$ feature\n\n4. $w_i$ is the sum of the $i^{th}$ feature across all data\n\n\nMaximize \n\n$$\n\\sum_{i=1}^{n_{\\text{clusters\\_input}}} \\sum_{j=1}^{n_{\\text{clusters\\_output}}} x_{ij}\n\n$$\n(this is in fact a always $=64$, so optimizing nothing)\n\ns.t.\n\nAssignment Constraint\n$$\n\\sum_{j=1}^{n_{\\text{clusters\\_output}}} x_{ij} = 1, \\forall i \\in \\{1, \\dots, n_{\\text{clusters\\_input}}\\}\n$$\n\n$$\n\\sum_{i=1}^{n_{\\text{clusters\\_input}}} x_{ij} c_{ij} \\leq (1 + \\epsilon_f) \\cdot \\frac{w_f}{n_{\\text{clusters\\_output}}}, \\forall j \\in \\{1, \\dots, n_{\\text{clusters\\_output}}\\}, \\forall f \\in \\{1, \\dots, n_{\\text{features}}\\}\n$$\n\nWhere $\\epsilon_i$ is small for the $l2\\_cnt$ and $num\\_users$ features, and quite large for the rest of them. So great balancing is not guaranteed for each feature.\n\n# Updated Model\n\n## Objective Function\n\n```\n        prob.setObjective(\n         xp.Sum(\n                (x[i, k]*x[j,k])*interactions[i,j] for i in range(N) for j in range(N) for k in range(K) if (i!=j)) \nd                , \n            sense=xp.maximize)   \n```\n$$\n\\text{maximize} \\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} \\sum_{k=1}^{K} x_{ik} x_{jk} \\cdot \\text{interactions}_{ij}\n$$\n## Additional Constraints\n\nAdded a constraint, forbidding some of the clusters to be too small.\n\n$$\n\\forall{j \\in 1..K} \\sum_{i=1}^{N} x_{ij} \\geq 3\n$$\nWith 2 it also works.\n\n## Guarding against 'put all interactions in the same cluster'\n\nAt some point I hit quite a serious problem, where the optimization would put a bunch of mini-clusters in the same cluster. That would maximimize 'total purity' quite well, but it can in fact create one 'full bqrt' and a bunch of random non-clusters. \n So I got the following idea:\n  1. I perhaps want, if I put all clusters in a graph somehow, and embed it in a 3-4d space, I want the 'bounding box' of each cluster to not be too dissimilar in that space. \n  2. But linearizing volume is hard, so we can just linearize the perimeters.\n  3. Implementation in the appendinx.\n  \n\n\n\n\n\n\n\n## 'We don't really optimize anything'\n\nHowever, we do!\n\nMy initial understanding about the de-facto objective function we're aiming to optimize was that 'the number of auctions, for which most of the ads they consist of are from the same cluster'. This is in fact still not quite right, as we in fact want to optimize something like:\n\n 1. for each cluster, find all auction it participates in.\n 2. Write 1 if  \">50% of the ads in this auction are from this cluster, else 0.\n 3. Take this average for each cluster.\n 3. Maximize the number of clusters, for which this average> ??\n \n But these are too many variables, probably\n #TODO- take a look at a 'direct optimization' of this objective function, and see if it's feasible.\n ## Approximation\nIdea:\n\nLet's say that 2 different mini-clusters interact with coefficient k iff they interact in $l$ auctions, then maximum number of auctions any 2 clusters interact in is $L$, and $l/L = k$. See appendix.\n\nEstimate the 'initial cluster' interactions, and try to put clusters with many interactions together. Then the interactions between the mega-clusters.\n\nPossible Objective funcitons, stemming from here:\n\nReferences: , \n\n### Max-Variant\n## Observations/ Theory\n\nMIP progresses towards 'good' integrality gap, (90% to 10% ish)\nThis is the one we've chosen.\n\n## Linearization of products of binary vars.\n\n## Drawbacks\n\nCan lead to unbalanced clusters.\n\n\n### Min-Variant\n\n## Observations/ Theory\n\nMIP progresses towards 'good' integrality gap, (90% to 10% ish)\nThis is the one we've chosen.\n## Drawbacks\nOptimization not progressing\n\n\n### Diameter- Variant\nCould be ok, optimization was progressing fine, but optimizes the notion of 'distance' as opposed to 'interaction' (common auctions). But maybe if more thought is spend in the '#interactions-to-distance' thing, can be evaluated. One good part is it considers that 'clusters should be similar' notion. \n\n\n### Pre-cluster Without Constraints, then find closest feasible point\n\nAgain, dependent on a 'distance' notion. Couldn't very easily find a nice pre-clustering.\n\n\n\n## Additional constraints\n\n##\n\n\n## \n\n\n\n\n\n# Appendix\n## Mini-Cluster Interaction Estimation Query\n\n\n```{sql}\n\nWITH clusters_and_campaigns AS (\n    SELECT\n        campaign_group_id,\n        ad_request_id\n    FROM auction_campaign_group_bipartite\n    WHERE\n        ds = {{ base_input_date_ds }}\n),\n-- get the ad requests, joined with the\nad_req_with_clusters_joined AS (\n    SELECT\n        *\n    FROM clusters_and_campaigns cc\n    JOIN clustered_csbqrt_allocation_v1 cr\n        ON cc.campaign_group_id = cr.campaign_group_id\n    WHERE\n        cr.ds\n            = '2023-07-15' -- {{ base_input_date_ds }} --'<MULTI_TABLE_LATEST_DS:cluster_summary_stats_multifeatures_v1&auction_campaign_group_bipartite&clustered_csbqrt_allocation_v1>'\n),\n-- sample\nad_req_with_clusters_joined_sample AS (\n    SELECT\n        *\n    FROM ad_req_with_clusters_joined\n    WHERE\n        FB_NECTAR_SAMPLING_PCT(CAST(ad_request_id AS VARCHAR)) < {{ sampling_pct }}\n),\n--- join to find number of simultaneous shows in an auction\nunnormalized_interactions AS (\n    SELECT\n        t1.ds AS ds,\n        t1.cluster_id AS cluster_1,\n        t2.cluster_id AS cluster_2,\n        COUNT(*) AS count_interactions\n\n    FROM\n\n        ad_req_with_clusters_joined_sample t1\n    JOIN ad_req_with_clusters_joined_sample t2\n        ON t1.ad_request_id = t2.ad_request_id\n\n    WHERE\n        t1.cluster_id < t2.cluster_id\n\n    GROUP BY\n        t1.cluster_id,\n        t2.cluster_id,\n        t1.ds\n),\nmax_interactions AS (\n    SELECT\n        MAX(count_interactions) maxint -- note, if I put the max it's buggy...\n    FROM unnormalized_interactions\n)\nSELECT\n    ds,\n    cluster_1,\n    cluster_2,\n    CAST(count_interactions AS DOUBLE) / CAST(max_interactions.maxint AS DOUBLE) interaction_coef,\n    count_interactions AS count_interactions\nFROM unnormalized_interactions,\n    max_interactions\nORDER BY\n    interaction_coef DESC\n\n```\n\n## Cluster 'range' constraints implementation\n\n```{python}\nimport numpy as np\nfrom sklearn.manifold import MDS\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Assuming your similarity matrix is called similarity_matrix\n# similarity_matrix = np.array([[1, 0.8, 0.4], [0.8, 1, 0.7], [0.4, 0.7, 1]])  # replace this with your data\nsimilarity_matrix = interactions\n# Convert similarity to dissimilarity\nmax_similarity = np.max(np.max(similarity_matrix))\ndissimilarity_matrix = 1./np.sqrt(1.01-similarity_matrix)# somewhat arbitrarily\n\n# Normalize dissimilarity between 0 and 1 (optional)\n# scaler = MinMaxScaler()\n# dissimilarity_matrix = scaler.fit_transform(similarity_matrix)\n\n# Create MDS model\nmds = MDS(n_components=4, dissimilarity='precomputed')# 4 - arbitrarly, tried 3 and 5, didn't want too large one\n\n# Fit and transform data\ncluster_dimensionality_embedding = mds.fit_transform(dissimilarity_matrix)\n\n# print(cluster_dimensionality_embedding)\n# idea- if we try to force the clusters not to be\n# Normalize low-dimensional data to 0-1 range\nscaler_low_dim = MinMaxScaler()\ncluster_dimensionality_embedding = scaler_low_dim.fit_transform(cluster_dimensionality_embedding)\n\nprint(cluster_dimensionality_embedding) \n    if add_cluster_dissimilarities:\n        embDim = cluster_dimensionality_embedding.shape[1]\n        # New decision variables\n        max_coord = {(k,l) : xp.var(lb = 0.0) for k in range(K) for l in range(embDim)}\n        prob.addVariable(list(max_coord.values()))\n        min_coord = {(k,l) :xp.var(lb = 0.0) for k in range(K) for l in range(embDim)}\n        prob.addVariable(list(min_coord.values()))\n        # max_coord = prob.continuous_var_matrix(keys1=n_clusters, keys2=Dim, name='max_coord')\n        # min_coord = prob.continuous_var_matrix(keys1=n_clusters, keys2=Dim, name='min_coord')\n        # Add constraints\n        for k in range(K):\n            for d in range(embDim):\n                for i in range(N):\n                    prob.addConstraint(max_coord[k,d] >= cluster_dimensionality_embedding[i,d] * x[i,k])\n                    prob.addConstraint(min_coord[k,d] <= cluster_dimensionality_embedding[i,d] * x[i,k])\n        # Dimensionality balance threshold\n        dimensionality_balance_threshold = 5\n        # Add dimensionality balance constraint\n        max_range_emb_sum = xp.var(lb = 0.0)\n        prob.addVariable(max_range_emb_sum)\n        min_range_emb_sum = xp.var(lb = 0.0)\n        prob.addVariable(min_range_emb_sum)\n        for k in range(K):\n            prob.addConstraint(max_range_emb_sum >= xp.Sum( \n                max_coord[k,d]-min_coord[k,d] for d in range(embDim)\n            ))\n            prob.addConstraint(min_range_emb_sum <= xp.Sum( \n                max_coord[k,d]-min_coord[k,d] for d in range(embDim)\n            ))\n        prob.addConstraint(\n            max_range_emb_sum<=eps_cluster_embeddings*min_range_emb_sum\n        )\n\n```\n\n\n","n":0.031}}},{"i":242,"$":{"0":{"v":"JuMP","n":1},"1":{"v":"\n[[science.cs.languages.julia]]\n[[science.math.Optimization]]\n\n","n":1}}},{"i":243,"$":{"0":{"v":"Gradient Descent","n":0.707},"1":{"v":"\n# Introduction\n\n# Stochastic Gradient Descent\n\n# Minimatch Method\n#minibatches\n\n# Adam Optimizer\n[[science.math.Optimization.Adam Optimizer]]\n\n# Second Order Optimizers\n[[science.math.Optimization.Second Order Optimizers]]\n\n\n[[science.math.Optimization.Newton-Rhapson Method]]\n[[science.math.Optimization.Stochastic Gradient Descent]]\n[[Minimatch Method]]\n\n\n","n":0.229}}},{"i":244,"$":{"0":{"v":"EM Expectation Maximization","n":0.577}}},{"i":245,"$":{"0":{"v":"Convex Optimization","n":0.707},"1":{"v":"\nThe  [[math.Optimization.Lagrangian]] dual yields a __lower bound__ of the objective value of the optimization problem.\n\n\n[[science.math.Optimization.Linear Programming]]\n[[science.math.Optimization.Semidefinite Optimzation]]\n\n\n\n\n\nNot sure what this is and why it's interesting...\n[SOS tools](http://www.mit.edu/~parrilo/sostools/)\n\n\n# Duality Gap\n\nIf the gap is 0, then the solution is optimal.\n\n\n# A saddlepoint/ game characterization \n\n__The primal and dual objective values can be characterized as a game where the 'minimizing' and 'maximizing' 'players' switch their order:__\n\n$p^* = inf_{x\\in D} sup_{\\lambda,\\mu} L(x,(\\lambda,\\mu))$ : first choose x, maximize result wrt the lagrangian multipliers\n\n$d^* = sup_{\\lambda,\\mu} inf_{x\\in D} L(x,(\\lambda,\\mu))$ : first choose lagrangian multipliers, then minimize result  x\n\nNOTE - in the notation above, the OUTSIDE optimization happens FIRST, and the INSIDE optimization happens SECOND.\n\nTherefore weak duality corresponds to the max-min inequality:\n\n\n\n$ sup_{\\lambda,\\mu} inf_{x\\in D} L(x,(\\lambda,\\mu)) <=inf_{x\\in D} sup_{\\lambda,\\mu} L(x,(\\lambda,\\mu))$, which holds for general functions, not just \nthe [[math.Optimization.Lagrangian]].\nThat is, the 2nd player has the advantage.\n\n\n\n# Optimiality conditions\n[[science.math.Optimization.Convex Optimization.KKT Slater Complimentary Slackness]]\n\n\n\n\n\n","n":0.083}}},{"i":246,"$":{"0":{"v":"KKT Slater Complimentary Slackness","n":0.5}}},{"i":247,"$":{"0":{"v":"KKT Slater Complimentary Slackness Karush Kuhn Tucker","n":0.378}}},{"i":248,"$":{"0":{"v":"Duality","n":1},"1":{"v":"\nLet of have a constrained optimization problem like so: like so:\n\n$min_x f(x)$\n\n$\\text{s.t. }  f_i(x)<=0 \\text{ for } i = 1..k$\n\n$h_i(x)=0 \\text{ for } i = 1..l$\n\nWhere g and h are the constraint functions.\n\nThe [[math.Optimization.Lagrangian]]  problem\nis then $min_{x} max_{h,l} f(x) +\\Sigma_{i = 1..l} \\lambda_i f_i(x) + \\Sigma_{i = 1..k}\\mu_j g_i(x)$ \n$\\text{s.t. } \\mu_i<=0$\n\nThe lagrangian is a lower bound of the original problem:\nif we define the function above:\n\n$g(\\lambda,\\mu) = inf_{x\\in D} f(x) +\\Sigma_{i = 1..l} \\lambda_i h_i(x) + \\Sigma_{i = 1..k}\\mu_j f_i(x)$\nwhere $D$ is the feasible domain of x.\n\nif D is empty, $g(\\lambda,\\mu) = \\infty$.\n\n\n[[science.math.Optimization.Linear Programming]]\n[[science.math.optimization.Dynamic Programming.Approximate Dynamic Programming]]\n\n\n\n# [[science.math.Optimization.Linear Programming#^Duality]]\n","n":0.101}}},{"i":249,"$":{"0":{"v":"Alternating direction method of multipliers (ADMM)","n":0.408},"1":{"v":"\n[ADMM](https://stanford.edu/~boyd/admm.html)\n","n":1}}},{"i":250,"$":{"0":{"v":"Constraint Programming","n":0.707},"1":{"v":"\n[[Algorithm]]\n","n":1}}},{"i":251,"$":{"0":{"v":"Adam Optimizer","n":0.707}}},{"i":252,"$":{"0":{"v":"Norms and Metrics","n":0.577},"1":{"v":"\n# $p$-norm\n\n$||\\theta||_{p} = \\Sigma_{i=1..n}(\\theta_i^p)^{1/p}$\nif $p>=1$. if $p\\in[0,1)$ the above is still of interest, __but it's not a norm__.s\n\n\n","n":0.236}}},{"i":253,"$":{"0":{"v":"Linear Algebra","n":0.707},"1":{"v":"\nSummary from [here](https://minireference.com/static/tutorials/linear_algebra_in_4_pages.pdf).\n\nAlso this is interesting [cheat sheet](https://www.cs.cornell.edu/~tomf/notes/cs421-cheat-sheet.pdf), which is a bit more concise and goes somewhat deeper.\n\n\n# Vectors\nA vector $\\vec{v}\\in R^n$ is a tuple $(v_1,v_2,...,v_n)$.\nA matrix \n$$\nA=\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n}\\\\\na_{21} & a_{22} & \\cdots & a_{2n}\\\\\n & \\cdots\\\\\na_{21} & a_{22} & \\cdots & a_{2n}\\\\\n\n\\end{bmatrix}\n$$\n\n\n# Vector Spaces ^vector-spaces\nmoo\n\n# Distances and Norms ^norms\n\n# Determinant ^determinant\n\n# Matrix Inverse ^invers\n\n$A^{i}$:= solution of the equation $A*A^{-1}=I$.\nIf A's columns is orthonormal, then $A*A^{T}$.\n\n\n# Matrices and Linear Transformations ^linear-transformations\n![[^Vector-Spaces]]\n[[science.CS.algos.matrixChainMultiplication]]\n\n[[science.math.Linear Algebra.Inverse Matrix]]\n# Similar Matrices, Eigenvalues and Eigenvectors ^eigenvectors\n The set of eigenvectors $\\vec{e_1},\\vec{e_2},...$ of a matrix $A\\in R^{n x n}$ is a set of vectors $\\vec{v}$ such that matrix multiplication is simple scaling:\n  $A\\vec{v}=\\lambda_i\\vec{e_i}$.\n\n  Scaling factor can be different for each eigenvector. These scaling factors are called eigenvalues $\\lambda_i$.\n\n$(A-I*\\lambda{i})*\\vec{i}=0$\n\nCertain matrices (if all eigenvalues are different, i.e. have multiplicity of 1), for which all eigenvalues are different, can be written as:\n\n\n$A = Q*\\Lambda*Q^{-1}$\nwhere $\\Lambda$ is diagonal matrix with eigenvalues and $Q$ is orthogonal matrix with eigenvectors.\n\n$Q=[e_1,e_2,...e_n]$. \n\nProof:[[science.math.Linear Algebra.Change Of Basis]]\n\n\n## QR Decomposition ^qr-decomposition\n\nA $QR$ decomposition is a decomposition of a square matrix $A$ to a product of a orthonormal matrix $Q$ and\nupper- triangular matrix $R$ such that $A=QR$.\n\n### Orthgonalization by Gram-smidth\nLet $A = [\\bold{a_1},\\bold{a_2}...]$.\nThen let:\n\n$u_1 = a_1, e_1=u_1/||u_1||$\n\n$u_2 = a_2-(a_2\\cdot e_1)*e_1, e_2=u_2/||u_2||$\n\n$u_k = a_k-\\Sigma_{i=1..(k-1)}(a_k\\cdot e_i)*e_i, e_k=u_k/||u_k||$\n\nIn words:\nTo find the vectors:\n\n1. Take the first vector and normalize it. This is $e_1$\n2. Take the second vector, figure out the part, orthogonal to $e_1$, and normalize it. This is $e_2$\n3. Taking the $k$-th vector, figure out the part, orthogonal to $e_1,e_2,...,e_{k-1}$, and normalize it. This is $e_k$\n4. Repeat till $k=n$ (inclusive)\n\nThen, $a_k$ is a linear combination of $e_1,e_2,...,e_{k}$.\n\n\n\n\n# SVD ^svd\n\n\n\n[[science.math.Linear Algebra.Singular Value Decomposition]]\n\n[[science.stats.Dimensionality Reduction.SVD]]\n\nSVD is in a sense a  generalization of eigenvalue decomposition, but can be applied to non-square matrices.\n\nMore concretely, if the singular values are $\\sigma_1,\\sigma_2,...,sigma_n$, then\n$\\sigma_i^2$ are the eigenvalues of A^T*A=A^2$ .\n[SVD from wikipedia](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n\nRelationship between SVD and [[#^qr-decomposition]]:\n\n Suppose that $A$ has full column rank and let $A=QR$ be a $QR$ decomposition for A.\n There exists a SVD of A s.t. $Q=U$ iff $A*A$ is diagonal.\n\n(Source)[https://math.stackexchange.com/questions/2348807/is-there-any-connection-between-qr-and-svd-of-a-matrix]\n\n![Visual summary](/assets/images/2022-02-04-13-59-52.png)\n(Another correspondence)[https://intoli.com/blog/pca-and-svd/]\n\n# PCA ^pca\n[[science.stats.Dimensionality Reduction.PCA]]\n\n\n\n\n# Jacobian and Hessian ^jacobian\n[[science.math.Optimization.Gradient Descent]]\n[[science.math.Optimization.Second Order Optimizers]]\n[[science.math.calculus]]\n\nJactobian is the 'first' derivative of a function $R^m->R^n$, i.e. the 'gradient' [[science.math.calculus.Gradient]], while Hessian is the second derivative.\n\n\n# Cholesky Decomposition ^cholesky\n[[science.math.calculus.Numerical Methods]]\nIt's the \"sqrt\" of a matrix.\n\n\n\n","n":0.051}}},{"i":254,"$":{"0":{"v":"Special Matrices","n":0.707},"1":{"v":"\n\n...","n":1}}},{"i":255,"$":{"0":{"v":"Singular Value Decomposition","n":0.577},"1":{"v":"![[science.math.Linear Algebra#^svd]]\n\n","n":0.707}}},{"i":256,"$":{"0":{"v":"Rotation Matrices","n":0.707},"1":{"v":"\n# 2D\n\n$\\mathbf{R}(\\theta) = \\left[\\begin{array}\n{rrr}\ncos(\\theta) & -sin(\\theta)  \\\\\nsin(\\theta) & cos(\\theta)  \\\\\n\\end{array}\\right]\n$\n\n$\\mathbf{R}(\\pi/2) = \\left[\\begin{array}\n{rrr}\n0 & -1  \\\\\n1 & 0  \\\\\n\\end{array}\\right]\n$\n\n$\\mathbf{R}(\\pi) = \\left[\\begin{array}\n{rrr}\n1 & 0  \\\\\n0 & -1  \\\\\n\\end{array}\\right]\n$\n\n$\\mathbf{R}(3\\pi/2) = \\left[\\begin{array}\n{rrr}\n0 & 1  \\\\\n-1 & 0  \\\\\n\\end{array}\\right]\n$","n":0.171}}},{"i":257,"$":{"0":{"v":"Matrix Decompositions","n":0.707},"1":{"v":"# Eigenvalue Decompositions\n\n# LU factorization ^lu\n\n# SVD ^svd\n[[science.stats.Dimensionality Reduction.SVD]]\n\n# Similar Matrices\n\n# PCA ^pca\n[[science.stats.Dimensionality Reduction.PCA]]\n\n[[science.stats.Regression.Recommender Systems]]","n":0.258}}},{"i":258,"$":{"0":{"v":"Inverse Matrix","n":0.707},"1":{"v":"\n[[Test block references#^]]","n":0.577}}},{"i":259,"$":{"0":{"v":"Change Of Basis","n":0.577}}},{"i":260,"$":{"0":{"v":"Game Theory","n":0.707},"1":{"v":"Game Theory is like optimization if different agents control different variables.\n[[science.math.Optimization]]\n[[science.math.Game Theory.Nash Equilibrium]]\n\n[[science.math.Game Theory.Algorithmic Game Theory]]\n","n":0.25}}},{"i":261,"$":{"0":{"v":"Voting","n":1},"1":{"v":"\n# Arrow's theorem\n\n\n## First Past the Post System ^firstpost\n\n\nNice consequence debate in [[science.economics.Inadequate Equilibria (Book)]]\n\n\n## Proportional Representation","n":0.243}}},{"i":262,"$":{"0":{"v":"Vickrey Auctions","n":0.707},"1":{"v":"\n\n[Lecture](https://web.stanford.edu/~jdlevin/Econ%20285/Vickrey%20Auction.pdf)\n\n* We consider the problem of how to implement e¢ cient allocations in\nan environment where each participant has private information about\ntheir preferences. Participants may misrepresent their preferences.\n* A bank may overstate its need for a federal bailout, hoping to get\ntaxpayers to absorb its losses.\n* A buyer might understate its value, hoping to get a lower price.\nVCG mechanisms achieve __*strategy-proof*__ implementation of efficient cient\nallocations in quasi-linear environments, but can have trouble with\nbudget balance.\n\n\n\n\n\n\n","n":0.118}}},{"i":263,"$":{"0":{"v":"Shapley Value","n":0.707},"1":{"v":"\n\nLet us have a cooperative game with player set $P$.  payout function $p:2^P->R^{+0}$. \nWe're trying to find an allocation function $f:P->R^{+0}$\n\n'Fairness axioms':\n1. Dummy player: \n if foreach $S\\subset P,A\\notin S$, $p(P \\cup  A) = p(P) => f(A)=0$\n2. Equivalent Players$A,B$:\n if foreach $S\\subset P,A,B\\notin S$, $p(P \\cup  A) = p(P\\cup B) => f(A)=f(B)$\n3. Full Payout\n $\\Sigma_{c\\in P}f(c) = p({c | c \\in P})$\n4. linearity\n\n\nThen the there exists a unique function that's shapley's value\n\n\n\nThe shapley values, applied via [[science.stats.Permutation Tests]] to a black-box model, are used in [[science.stats.Machine Learning.Interpretability]].\n\n","n":0.107}}},{"i":264,"$":{"0":{"v":"Nash Equilibrium","n":0.707}}},{"i":265,"$":{"0":{"v":"Mechanism Design","n":0.707},"1":{"v":"\nfrom [wikipedia](https://en.wikipedia.org/wiki/Mechanism_design)\n\n![Mechanism Design Diagram](/assets/images/2022-01-10-18-27-43.png)\nThe Stanley Reiter diagram above illustrates a game of mechanism design. The upper-left space $\\Theta$  depicts the type space and the upper-right space $X$ the space of outcomes. The social choice function $f(\\theta )$ maps a type profile to an outcome. In games of mechanism design, agents send messages $M$ in a game environment $g$. The equilibrium in the game $\\xi (M,g,\\theta )$ can be designed to implement some social choice function $f(\\theta )$.\n\n","n":0.114}}},{"i":266,"$":{"0":{"v":"Algorithmic Game Theory","n":0.577},"1":{"v":"\nAlgorithmic Game Theory is sitting in the intersection of economics and computer science. \n\nOne way to look at it is as follows:\n\nEconomics is conserned with equilibria of market-like structures. These equilibria could \nhave various 'utilities' (in the sense of wellfare). \n\n## Complexity theory view\n'If your computer can't find the equilibria, neither can the market'. \nOr the good equilibria, etc.\n\n[[science.math.Game Theory.Vickrey Auctions]]\n\n[[science.math.Game Theory.Mechanism Design]]\n\n\n# Summer School Lecture Notes\n\n[Samos Summer School 2012](https://www.dropbox.com/sh/o2u4rxd4ajtyj7m/AAD6YQg-JD2m4YOWeMvbDQ2Ua?dl=0)","n":0.12}}},{"i":267,"$":{"0":{"v":"Agent Based Models","n":0.577},"1":{"v":"\n# THIS IS NOT STRICTLY About GAME THEORY\n\n\n\n\n# Examples\n\n## Epidemology\n\n## Facebook Network Effect ^fbepidemology\n\nSay we release a Facebook app feature that makes it more likely for ppl to post. Then people who interact with the app will have a higher chance of posting, but ALSO people who interact with people who post more will post more. Thus as we move out of the test and release the app, the number of people who post will increase via both the 'app-effect' itself, and via the number of interactions w/ people, posting more.\n\n\n\n\n# Software\n\n[NetLogo](https://ccl.northwestern.edu/netlogo/).\n\n[Agents.jl](https://juliadynamics.github.io/Agents.jl/stable)\n","n":0.104}}},{"i":268,"$":{"0":{"v":"Functional Analysis","n":0.707}}},{"i":269,"$":{"0":{"v":"Functional Spaces","n":0.707}}},{"i":270,"$":{"0":{"v":"Bases","n":1}}},{"i":271,"$":{"0":{"v":"Kernel Methods","n":0.707},"1":{"v":"\n# Inner Products and Hilbert Spaces\n\nA Hilbert Space is a space with an inner product and one where the limits of all Cauchy sequences wrt the norm, defined by the inner product, are in the space itself.\n\nThe inner product defines a norm by taking the inner product of an element with itself.\n\n# Kernel Function\n\nLet H be a Hilbert Space.\nA function $k:R^d->R^d->R$ is called a kernel on $R^d$ if there exists a feature map $\\phi:R^d->H$, s.t. $k(x,y) = <\\phi(x).\\phi(y)>$, for all $x,y\\in R^d$ (or a subset thereof).\n\n#  Positive Definite Kernel Matrix (Mercer)\n\nA function $R^d->R^d->R$ is positve-definite iff for any $a_1,a_2,...a_k \\in R$, $x_1,x_2,...x_k \\in R^d$,k is symmetric and \n$\\Sigma_{i = 1..n} \\Sigma_{j=1..n} a_i a_j k(x_i, x_j)>=0$\nSame as saying for any $x_1,x_2,...x_k \\in R^d$, the matrix with entries $M_{i,j} = k(x_i,x_j)$ is positive definite (or semi-definite).\n\nfrom [Mercer's Theorem (Wikipedia)](https://en.wikipedia.org/wiki/Mercer%27s_theorem)\n\n## Mercer's Theorem\n Suppose K is a continuous symmetric non-negative definite kernel. Then there is an orthonormal basis {ei}i of L2[a, b] consisting of eigenfunctions of TK such that the corresponding sequence of eigenvalues {λi}i is nonnegative. The eigenfunctions corresponding to non-zero eigenvalues are continuous on [a, b] and K has the representation\n\n$K(s,t)=\\sum _{j=1}^{\\infty }\\lambda _{j}\\,e_{j}(s)\\,e_{j}(t)K(s,t)$\n\n$=\\sum _{j=1}^{\\infty }\\lambda _{j}\\,e_{j}(s)\\,e_{j}(t)$$\n\n Where the convergence is absolute and uniform.\n\nSo essentially, if K is positive definite in the above sense, there exists a feature map, for which K is the inner product of the output space.\n\n\n# Reproducing Kernel Hilbert Spaces\n\n## Representer Theorem and Regularization\n\n\n## Different Kernels and Operations \n\n\n# Kernel SVM\n\n[[science.stats.Support Vector Machines]]\n\nWe have an analogy of the original SVM dual formulation, with a generalized kernel at the place of the inner product function.\n\n\n# Kernel PCA\n\n[Look at the pretty pics from sklearn](https://scikit-learn.org/stable/auto_examples/decomposition/plot_kernel_pca.html#sphx-glr-auto-examples-decomposition-plot-kernel-pca-py)\n\n# Representation of Probability Densities \n\nPossible, but looks complicated from the lecture notes :D\n","n":0.059}}},{"i":272,"$":{"0":{"v":"High Dimensional Neighborhood Search","n":0.5}}},{"i":273,"$":{"0":{"v":"Random Projections","n":0.707},"1":{"v":"\n\nAccording to the [Johnson- Lindenstrauss Lemma](https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_lemma) \n\n```\nIn mathematics, the Johnson–Lindenstrauss lemma is a result named after William B. Johnson and Joram Lindenstrauss concerning low-distortion embeddings of points from high-dimensional into low-dimensional Euclidean space. The lemma states that a set of points in a high-dimensional space can be embedded into a space of much lower dimension in such a way that distances between the points are nearly preserved. The map used for the embedding is at least Lipschitz, and can even be taken to be an orthogonal projection.\n```\n\nSo if we use low-dim random projection, the distances between the points are likely to be preserved.\n\n[[science.stats.Unsupervised Learning.KNN.Locality Sensitive Hashing]]\n\n","n":0.097}}},{"i":274,"$":{"0":{"v":"Engineering","n":1}}},{"i":275,"$":{"0":{"v":"Technologies","n":1}}},{"i":276,"$":{"0":{"v":"Graphs","n":1},"1":{"v":"\n# Jung (Java)\n[Evernote Link](https://www.evernote.com/shard/s101/nl/11122041/a2180526-dfaa-402d-9905-b3f142b5051b?title=Jung)\n\n# LightGraphs\n[[science.cs.languages.julia]]\n\n# Networkx\n\n[[science.cs.languages.python]]\n\n3nuts- Peer to peer network lib in Java (academic, experimental)\n[JGraphT](https://jgrapht.org/). - also has python bindings\n\n\n# igraph \n[[science.cs.languages.python]]\n[[science.cs.languages.R]]\n\n\n\n# Neo4j\n\n[[science.CS.algos.Graph Traversal]]\n\n\n# Me\n","n":0.2}}},{"i":277,"$":{"0":{"v":"Random Graphs","n":0.707},"1":{"v":"\n\n# Erdos \n\nGenerate graph randomly\n\n# Barabasi-Albert ^baGraph\n\nPreferential attachment","n":0.354}}},{"i":278,"$":{"0":{"v":"P2P, Meiko Thesis","n":0.577},"1":{"v":"\n\n[Mail From Shinji, hunt down the reference in question](https://docs.google.com/document/d/1J8hNmeqAs__ea3lHbGz7lwRjmvIB9ty4_bl80p2HnUM/edit?usp=sharing)\n#TODO\n\n","n":0.333}}},{"i":279,"$":{"0":{"v":"Node Features","n":0.707},"1":{"v":"\n\n# Basics \n\n## Node Degree \n\n$d_u = \\sum_{v\\in V} A_{u,v}$\n\n$D =Diag(d)$\n\n## Eigenvector Centrality \n\nIt's natural to define centrality as the solution of the recursive linear system:\n\n\n$e_u = \\frac{1}{\\lambda}sum_{v\\in V} A[u,v] e_v,\\forall u\\in V$\n\n The eigenvector centrality vector would be $\\lambda  = A e$, where $\\lambda$ is the largest eigenvalue of the adjacency matrix. \n\n### Random Walk probability View\n\n The eigenvector centrality is the average time we spend in a given node as we do a random walk.\n\nCan solve with the following power iteration:\n$e_(t+1) = A e_t$\n\nif we start from $e_0 = (1,1,...1)^T$, then $e_{t}$ will contain the number of length-t paths that end in each node.\n\n## Betweenness Centrality\n\n\n## Closeness Centrality\n\n\n## Clustering Coefficient\n This is the proportion of closed triangles in the neighborhood of a node.\n\nLocal Clustering Coefficient:\n $c_u  = \\frac{\\sum_{i\\in N(u),j\\in N(u)}A[u,v]}{C_{d_u}^2}$\n\n```\n    An interesting and important property of real-world networks troughout the social and\n     biological sciences are that the local clustering coefficients tend to be much higher \n     than if they were to be sampled randomly.\n```\n# Ego Graph\n\nAn ego graph around a node is the induced subgraph that contains only the node and its neighbors.\n\nThen we can count triangles and other __motiffs__ there and characterize the graph like this.\n\n\n# Graph Level Features\n\n# Bag of Nodes\n\nAggregate node-level statistics.\n\n\n# Weisfeiler-Lehman Kernel\n\nGet a hash function $h$ that takes a set of labels and returns a label\n1. Assign initial label to each node $l_u^{(0)}$\n2. Iterate k times:\n   get neighboring labels and hash them w/ $h$. This is the new label $l_u^{(i)}$. \n3. look at the set ${l_u^{(k)}}$ . This summarizes, for each node, info about it's $k$-hop neighborhood.\n\nCompute __histograms or other summary statistics__ over these labels and use that as a feature representation of the graph.\n\n# Graphlets And Path-Based methods\n\n## Graphlets \n\nGet graph patterns and count them. Combinatorially difficult, but there are approximations\n\n## Path-Based methods\n\nRun limited-depth random walks from each node, gather stats about how much you've visited all nodes. Gather the __histograpm of the counter__ of these nodes...\n\nCan also count occurences of different degree sequences.\n\n\n# Node-Node Overlap Measures\n \n\n## Local Overlap Measures\n\nThese measures consider only the immediate neighbors of $u$ and $v$.\n\n$S[u,v] = |N(u)\\cap N(v)|$\n\nThis provides a way to measure how similar 2 nodes are. We usually combine them with the \nassumption that the probability of having an edge is proportional to the similarity coefficient $S[u,v]~ P((u,v)\\in E)$\n\n\n$S_{Sorenson}[u,v] = \\frac{2|N(u)\\cap N(v)|}{ |d_u+d_v|}$ ^sorensen\n\n$S_{Salton}[u,v] = \\frac{2|N(u)\\cap N(v)|}{ \\sqrt{d_u*d_v}}$ ^salton\n\n\n$S_{Jaccard}[u,v] = \\frac{|N(u)\\cap N(v)|}{|N(u)\\cup N(v)|}$ ^jaccard\n\n### Importance-aware measures\n\nIt's a bit like a [[science.engineering.technologies.Natural Language Processing and IR.TF-IDF]] or other sort of normalizations.\n\nResource Allocation Index:\n\n\n$S_{RA}[u,v] = \\sum_{u\\in N(u)\\cap N(v)} \\frac{1}{d_u}$  ^resource-allocation-index\n\nSo the more 'special' a node in the overlapping neighborhoods of $u$ and $v$ is, the higher it's weight in $S_{RA}[u,v]$\n\n\nAdamic-Adar Index is quite similar:\n\n$S_{RA}[u,v] = \\sum_{u\\in N(u)\\cap N(v)} \\frac{1}{log(d_u)}$ ^adamic-adar-index\n\n\n## Global Overlap Measures\n\nThese are also between two vertices, but they consider the entire graph. E.g. in the 'following fish graph' $A1$ and $A2$ will be pretty similar, though they have $0$ neighbors in common.\n\n```mermaid\ngraph LR;\nA1-->B1-->C\nA2-->B2-->C\nC-->D1-->E\nC-->D2-->E\n```\n\n## Katz Index\n\nThe most basic overlap statistics. \nIt simply shows the number of paths of all lenghts between two vertices $u$ and $v$, discounted:\n\n$S_{katz}[u,v] = \\sum_{i=1}^{\\infty} \\beta^i A^i_{i,j}$\n\nAfter some matrix algebra, we notice this index can be written as a matrix as follows:\n\n$S_katz = (I-\\beta A)^{-1}-I$\n\n## Leicht, Holme, Newmann (LHN) Similarity Index\n\n\nThis is: Number of Paths of len I/(expected number of paths of len I) were the graph to be randomly generated with the same set of degrees.\n\nTo compute the expectation we can do it by sampling the graph.\n\nAlternatively, there is the following analytical expressions:\n\n\n$E[A[u,v]] = \\frac{d_u d_v}{2|E|}$\n\n$E[A^2[u,v]] = \\frac{d_u d_v}{(2|E|)^2}*\\sum_{u\\in V}(d_u-1)d_u$\n...\nBut this doesn't scale for i>3.\n\nThere is some more math to approximate using the $i-1$-st smallest eigenvalue\n\n...\n\nS_{LNH}[u,v] = I[u,v]+  \\frac{2m}{d_u d_v}\\sum_{i=1}^{\\infty} \\beta^i \\lambda_1^(1-i)) A^i[u,v]\n\nSee more at (2.22) in the book.\n\nwhere I is an identity matrix\n![](/assets/images/2022-02-15-19-41-20.png)![](/assets/images/2022-02-15-19-41-22.png)\n\n\n\n## Random Walk Metrics\n\n### Personalized Pagerank\n\n'What's the distribution of nodes visited by a random walker, starting from this node, who teleports back to the starting node with some probability?'\n\n\nLet us define the stochastic matrix: $P = AD^{-1}$\n\nThen the personalized PageRank with teleport-back probability $1-c$:\n\n$q_u = cPq_u + (1-c)I[:,u]$ \nwhere I is the identity matrix.\n\nThen $q_u = (1-c)(I-cP)^{-1}e_u$ \n\nwhere $e_u$ is the unit vector with a 1 at index $u$ and 0 otherwise.\n\n\n## Graph Laplacians and Spectral Methods\n\n![[science.engineering.technologies.graphs.Graph Laplacians]]\n\nLaplacians and connected components:\nsee ![[science.engineering.technologies.graphs.Graph Analysis.Spectral Clustering#^laplacianApproximation]]\n\n\n<!-- L = A-D\n\nNormalized Version... -->","n":0.037}}},{"i":280,"$":{"0":{"v":"Node Embeddings","n":0.707},"1":{"v":"\n\n# Encoder- Decoder Perspective\n\nThe *encoder* maps node $v\\in V$ to a $d$-dimensional vector $v^\\prime$ and the *decoder* maps a pair of $d$-dimensional vectors $v^\\prime,v$ to a node $v\\in V$.\n\n# Shallow Encoders\n\n","n":0.18}}},{"i":281,"$":{"0":{"v":"Graph Representation Learning Book Notes","n":0.447},"1":{"v":"\n\nNotes from [Hamilton's book](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf) mostly, as well as some other places...\n\n\n# Feature Information\n\nWe mostly deal with Node Level Attributes:\n\nSay we have m attributes for each node, $X\\in\\mathcal{R}^{|V|xm}$.\n\nIn some rare cases we could have Edge-level attributes ay we have m attributes for each node, $X\\in\\mathcal{R}^{|E|xm}$.\n\n\n# ML On graphs\n\n\n## Node Classification ^ nodeClass\n\nSemi-supervision. When we're training node classification algorithms, we do still have the full graph, but we're missing the labels of the \ntest nodes. \nThus, the train and test set are not independent and information from structures and maybe features of the test set is used\nduring training.\n\n```\nSemi-supervised is a standard term for combining labeled and unlabeled data. However, semi-supervised learning still kind of assumes exchangeability (i.i.d. errors), so we can see Graphs\n\n```\n\n## Relation Prediction ^relationPred\n\n We are given a set of nodes $V$ and an incomplete set of edges between these nodes $E_{train}\\subset E$. Our goal is to use this partial information,\n  as well as the node labels $X\\in R^{|V|*k}$ to predict the mixxing edges $E_{test} = E - E_{train}$.\n   \nWe might also be required to predict the label of the relation, if there are multiple labels. E.g. Facebook 'friendship' relation is one thing, but for medical stuff there might be much more.\n\n## Clustering and Community Detection ^communityDetection\n\nCommunity Detection- the analog of [[science.stats.Unsupervised Learning.Clustering]].\n\n\nFor example, also look at [[science.engineering.technologies.graphs.Graph Analysis.Spectral Clustering]].\n \n\n Examples:\n * Collaboration Graphs\n\n\n## Graph Classification, Regression, and Clustering ^graphClassification\n\nDoing the same thing on the level of graphs\n\n\n# Graph Statistics and Kernel Methods\n\n\n## Node Features\n[[science.engineering.technologies.graphs.Graph Analysis.Node Features]]\n\n\n\n","n":0.064}}},{"i":282,"$":{"0":{"v":"Graph Laplacians","n":0.707},"1":{"v":"Let $G= (V,E)$ be a graph and $w:E->R^{+0}$ be a weight function. Then let the degree matrix D be the diagonal matrix with $D_{i,i}=\\sum_{j\\in E} w(i,j)$. Let the corresponding adjacency matrix be $A_{i,j} = w_{i,j}$\nThen the unnormalized Graph Laplacian is given by:\n\n$L = D-A$\n\nIn the unweighted case, all edges have a weight of 1, and non-edges have a weight of 0.\n\nWe can show that $L$ is positive semidefinite,that is, for any vector $v$ in $R^{n}$, $v^TLv$ is non-negative.\n\n\n# Normalized Versions\n\nSymmetric:\n\n$L_{sym} = D^{-1/2}LD^{-1/2}$\n\nRandom Walk Laplacian:\n\n$L_{RW} = D^{-1}L$\n\n\n\n\n\n\n\n","n":0.108}}},{"i":283,"$":{"0":{"v":"Graph Analysis","n":0.707},"1":{"v":"\n# Similarity Graphs and Laplacians\n\n\n![[science.engineering.technologies.graphs.Graph Laplacians]]\n\n# Normalized Laplacians\n\n$I-D^{-1}W$ - random walk matrix.\n\n\n![[science.engineering.technologies.graphs.Graph Analysis.Spectral Clustering]]","n":0.267}}},{"i":284,"$":{"0":{"v":"Spectral Clustering","n":0.707},"1":{"v":"\n# Spectral Clustering: ^ spectral Clustering\nLet us have $n$ datapoints and some dissimilarity function on them. We would like to compute a [[science.stats.Unsupervised Learning.Clustering]] on them.\nwe can use __graph cuts__ on a weighted undirected similarity graph $G = ({1,2,...,n},W)$.\n\n$cut(C_1,C_2) = \\sum_{i,j\\in E, i \\in C_1,j\\in C_2} w_{i,j}$ where $C_1,C_2$ are arbitrary (disjoint) sets of nodes.\n\n$cut(C_1,C_2,...,C_k) = \\sum_{i = 1..k} cut(C_i,\\bar{C_i})$ where $\\bar{C_i}$ is the complement of $C_1$.\n\nWe would like to minimize a normalized version of this cut:\n\n$ratio-cut(C_1,C_2,...,C_k) = \\sum_{i = 1..k} cut(C_i,\\bar{C_i})/|C_i|$\n\nThe reason of doing this is that otherwise we might get too many splits in practice (maybe there's some theoretical reason as well)\n\n## Approximation Via Laplacian Eigenvectors  ^laplacianApproximation\n\nIf we define the clusterings as normalized indicator vectors $h$ on the graph, they are orthonormal.  \nThey also minimize the expression $ratio-cut (C_1,...C_k) = \\Sigma_{i=1..K} h_k^TLh_k$.\n\nWere they __not__ to identity, it would correspond to computing the eigenvectors.\n\nWhich eigenvectors do we take? If the graph was disconnected, there would be multiple eigenvectors, corresponding to the eigenvalue 0.\nSo we take instead the $k$ eigenvectors,corresponding to the $k$ smallest eigenvalues.\n\nThis would gives us a new data representation of the graph, to which we can apply say [[science.stats.Unsupervised Learning.Clustering#^kmeans]] k-means.\n\n\n\n\n","n":0.072}}},{"i":285,"$":{"0":{"v":"Node Features","n":0.707}}},{"i":286,"$":{"0":{"v":"Inductive, Transductive, and Semi-supervised learning in graphs","n":0.378}}},{"i":287,"$":{"0":{"v":"Natural Language Processing and IR","n":0.447}}},{"i":288,"$":{"0":{"v":"TF-IDF","n":1}}},{"i":289,"$":{"0":{"v":"Chatbots","n":1}}},{"i":290,"$":{"0":{"v":"MLOps","n":1},"1":{"v":"\n[MLOps tool list (probably biased)](https://juliapackages.com/p/mlops) \n\n# Performance monitoring and tracking ^mlops-monitoring-tracking\n\n As part of the model serving infrastructure in a given system, we could have a [[engineering.system_design.load balancer]], or more generally, a dispatcher, which, for each incoming request, determines which model to serve.\n\n The disparcher then returns the modelid, and we keep track which model id/configuration is served for each request. \n\n Then after the data is in DWH, we can use [[science.stats.tests#^ANOVA]], [[science.stats.AB Testing]], [[science.stats.tests#^t-test]]\n\n We can also use [[science.math.Optimization.Optimal Control.Reinforcement Learning#^bandits]] in the dispatcher in order figure out what to send.\n\n # summary\n * Scaling machines up and down\n *  increasing/ decreasing batch size, increasing latency in exchagne of efficiency etc.\n\n# \n","n":0.094}}},{"i":291,"$":{"0":{"v":"Training-Serving Skew","n":0.707},"1":{"v":"\nTraining-Serving Skew is a problem, which might happen in Data science projects. A mixture of organizational and computational/latency-driven problems may cause it.\n\nDuring both Model Development and Serving, we need to do [[science.stats.Feature Engineering]]. But during model development, we have no computational limitations on what features to use, what data to connect to, etc.\n\nSometimes can do the Feature Engineering in such a way that's unviable for production serving. For example, we might need the full data in order to compute rolling features, we might need to connect to [[engineering.technologies.ML.Spark]] or a bunch of databases, etc.\n\nIn this situation, we should re-implement the code that computes the features. Then we have 2 versions of this code, potentially using different \ndata stores. This may lead to training-serving skew, i.e. serving predictions we are surprised to serve.\n\nThere are ways to solve it on a case-by-case basis. It is one of the problems [[science.engineering.technologies.MLOps.Feature Stores]] aim to solve in an automated way.\n\n\n[One reference](https://ploomber.io/blog/train-serve-skew/)\n\n","n":0.08}}},{"i":292,"$":{"0":{"v":"StatsD","n":1}}},{"i":293,"$":{"0":{"v":"Paperspace","n":1},"1":{"v":"\n\n#TODO check if it's better than google cloud/if it can run Julia, etc\n","n":0.277}}},{"i":294,"$":{"0":{"v":"ONNX","n":1},"1":{"v":"\n# [ONNX](https://onnx.ai/)\n\nThe Open Neural Network Exchange (ONNX) is a standardized, open-source, machine-readable, and portable format for neural network models.\n\nSupports many many neural network models.\n\n\n","n":0.204}}},{"i":295,"$":{"0":{"v":"ML Flow","n":0.707},"1":{"v":"\n# Tracking\n\n# Projects, code and environment packaging, Experiment management and reproducability\n\n# Data Versioning\n\n# Models\n\nDeploy ML models in diverse environments.\n\n# ML Flow getting started tutorials\n\nhttps://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html\n\n```{r}\n\nlibrary(mlflow)\nlibrary(glmnet)\nlibrary(carrier) # for creating ad-hoc closures\n\nset.seed(40)\n\n# Read the wine-quality csv file\ndata <- read.csv(\"wine-quality.csv\")\n\n# Split the data into training and test sets. (0.75, 0.25) split.\nsampled <- sample(1:nrow(data), 0.75 * nrow(data))\ntrain <- data[sampled, ]\ntest <- data[-sampled, ]\n\n# The predicted column is \"quality\" which is a scalar from [3, 9]\ntrain_x <- as.matrix(train[, !(names(train) == \"quality\")])\ntest_x <- as.matrix(test[, !(names(train) == \"quality\")])\ntrain_y <- train[, \"quality\"]\ntest_y <- test[, \"quality\"]\n\n\n# Create 'Parameters' to  a 'run' ; then can query models/runs by their parameters\nalpha <- mlflow_param(\"alpha\", 0.5, \"numeric\")\nlambda <- mlflow_param(\"lambda\", 0.5, \"numeric\")\n\n# I guess some kind of 'context manager'\nwith(mlflow_start_run(), {\n  model <- glmnet(train_x, train_y, alpha = alpha, lambda = lambda, family= \"gaussian\", standardize = FALSE)\n\n  # create closure around glmnet::predict w/ the model we just trained\n\n  predictor <- crate(~ glmnet::predict.glmnet(!!model, as.matrix(.x)), !!model)\n  predicted <- predictor(test_x)\n  \n  rmse <- sqrt(mean((predicted - test_y) ^ 2))\n  mae <- mean(abs(predicted - test_y))\n  r2 <- as.numeric(cor(predicted, test_y) ^ 2)\n  \n  message(\"Elasticnet model (alpha=\", alpha, \", lambda=\", lambda, \"):\")\n  message(\"  RMSE: \", rmse)\n  message(\"  MAE: \", mae)\n  message(\"  R2: \", r2)\n  \n  mlflow_log_param(\"alpha\", alpha)\n  mlflow_log_param(\"lambda\", lambda)\n  mlflow_log_metric(\"rmse\", rmse)\n  mlflow_log_metric(\"r2\", r2)\n  mlflow_log_metric(\"mae\", mae)\n  \n  mlflow_log_model(predictor, \"model\")\n})\n\n\n\n```\n","n":0.07}}},{"i":296,"$":{"0":{"v":"Feature Stores","n":0.707},"1":{"v":"\n\nTl;dr\nSeveral perspectives:\n1. Implementational\nLayer on top of a DB, supporting many writes, key-based retrieval, last-before-timestamp retrieval.\nSupports writing batch or streaming features.\nread: can ask for a feature x for item/customer/whatever id y at time t easily and get back the correct result.\nFS handles backfilling of these features.\nUseful for embedding maps as well.\n\n\n\n2. Semantic\nHave an 'easy and consistent way to write something that generates features ppl or models can use.\nThen create models that take data directly from the feature store, and it's easily portable to production.\n\n\n\n\nMany of the points are from the [FEASTS Docs](https://docs.feast.dev/).\n\n\nFeature Stores are systems that support the following functionalities: \n\n1. Consistent Access to Data During Model Ideation, Training, Testing, and Deployment.\nDifferent roles in the organization have divergent objectives and data sources. It would be best if the path between 'prototype data source' and 'production data sources' is as short as possible.\n2. Point-in-time correctness\nWhen the 'predict' call comes, we need the latest allowable value of the feature for the entity in question. Look below for the [[^timeTravel]]\n[[science.stats.Time Series]]\n[[science.stats.Data Leakage]]\n[[science.math.Stochastic Calculus.Filtration]]\n\nOne of the __key value propositions__ when compared to a [[engineering.system_design.nosql databases]] like [[engineering.system_design.nosql databases.BigTable]] by itself.\n\n3. Deploying new features into prod is difficult\nFor example, if a data scientist has created some long feature calculation pipeline during the script, it's possible to shoehorn this into production.\nBut maybe it's computationally burdensome, especially if it's using a bunch of time/data to compute (e.g. rolling windows).\nThen the prod system would have to make additional queries to fetch data for a week back, then aggregate over it- very slow.\nFeature store can be 'Database for kids' in this sense- a database ml ppl can experiment and put scripts/ ETL's for feature calculation without trouble.\n4. Features aren't reused across projects/ ppl ^reuse\nClear what this means\n\n\n\n# Another perspective from [talk](https://www.youtube.com/watch?v=6OCUMbEtSLU&ab_channel=StanfordMLSysSeminars)\n\n## Challenges with data for ml\n\n Data pipelines are messy.\n Different between training and serving\n Different data sources between training and serving\n Lack of point-in-time correctness/information sets/ Filtrations\n\n Models can be developed by DS, then re-developed and maintained by DE/MLE.\n\n\n### Building Feature Pipelines is hard\n\n* Same semantics, adapted to different requirements, lead to __different production requirements__ - distributed compute, strem processing, low-latency transformations.\n* Reliable computation and __backfilling__ of features is a large investment\n\n### Consistent Data Access\n* Redevelopment of pipelines- inconsistencties in data\n*  [[science.engineering.technologies.MLOps.Training-Serving Skew]] \n\n\n## Duplication of Effort\nThis is covered in the [[#^reuse]] point above\n\n\n### Data Quality Monitoring\n* Logging serving times, computation times\n* Checking for [[science.stats.Distribution Drift]]\n* Checking for 'Freshness', i.e. have we re-computed the features recently\n\n\n\n \n\n## How feature stores help\n\n\n\n\n\n\nThey are usually built on top of existing data stores, eg. DynamoDB, Redis, BigTable, etc.\nNormally the underlying storage system should support fast key lookup + timestamp range queries, e.g. BigTable style\n[[engineering.system_design.nosql databases.BigTable]]\n\n[[engineering.system_design.nosql]]\n\n\nHonestly, for ML features, it does seem like something that:\n* is key-based\n* supports __appends__, range queries, and one can put secondary indices on\nsounds perfect.\n\n\n\n\n\n\n## Time Travel Problem and Information Sets ^timeTravel\n\nIssue:\nwe would like to serve a model at time $T$ for lookahead period $h$, so we would like to use the data up to and including time $T-h$. So all features we use should be 'current' as of that timestamp. \n\nIn other words, when we're making prediction at time $T$ with planning horizon $h$, the __information set__ we can use is the one available at time $T-h$.\n\nSome [feature store solutions can help](https://www.tecton.ai/blog/time-travel-in-ml/) with this problem.\n\n\n\n# FEATS Overview\n![](https://www.tecton.ai/blog/time-travel-in-ml/)\n\n\n\n\n","n":0.043}}},{"i":297,"$":{"0":{"v":"ML","n":1}}},{"i":298,"$":{"0":{"v":"Data Version Control","n":0.577},"1":{"v":"\n\nExperiments tracking - dashboard,\nTagging,\nModel deployment,\n\n# Tidy Modelling \n[Parsnip](https://parsnip.tidymodels.org/).\n[Caret](http://topepo.github.io/caret/index.html).\n\n\n\n## Data Version Control\n[Data Version Control](https://dvc.org/)\n\n---------\n\n\n\n---------\n\n","n":0.277}}},{"i":299,"$":{"0":{"v":"Data Visualization And Dashboards","n":0.5},"1":{"v":"\n\n# Shiny\n# Pluto\n# Streamlit\n# Dash\n","n":0.447}}},{"i":300,"$":{"0":{"v":"API's","n":1},"1":{"v":"[Rapid API](https://rapidapi.com)\n[Rapid PAI Text Analytics][https://rapidapi.com/aylien/api/text-analysis]\n[[science.CS.theory.NLP]]\n","n":0.447}}},{"i":301,"$":{"0":{"v":"Robotics","n":1}}},{"i":302,"$":{"0":{"v":"Economics","n":1}}},{"i":303,"$":{"0":{"v":"Price Elasticity","n":0.707}}},{"i":304,"$":{"0":{"v":"Market Impact","n":0.707}}},{"i":305,"$":{"0":{"v":"Inadequate Equilibria (Book)","n":0.577}}},{"i":306,"$":{"0":{"v":"Geopolitics","n":1},"1":{"v":"\n# Making Sense\n\nIan Bremmer\n\n\nCurrent Demographic problems of China.\n\nMovement of Age Pyramid.\n\nHistory of industrialization, cost of living, number of children, and cultural transition.\n\nUSA transitioned to industrializaiton over 7 (?) generations. This made it easier to figure out how to raise children in industrializing age.\n\nChina started in 1970s. \n\nIn the village, children are free labor.\nIn the city, headache.\n\n20-30s mid-low added value work+ consumption\n40-50s high added value work + investment\n60s+ capital gains\nAfter- retirement- no economic impact.\n\nmedian china age\n[End of ](https://www.grid.news/story/global/2022/07/12/the-end-of-chinas-population-boom-has-arrived-how-will-the-countrys-changing-demographics-shape-its-future/)\n[[science.economics.Geopolitics.China]]\n\n![](/assets/images/2022-07-16-21-42-13.png)\n\nvery bad now...\n\nCold war:\n\nUS protects international trade (sea), in exchange writes everyone's security policy. \n\nFor US- security, for rest-economic deal.\n\nNow- US navy unsuited to protect international trade, suited for wars and power projection.\n\nToo many battleships, too few destroyer ships.\n\nEnd of the undettered globalization.\n\nChina bad politics+ bad demographics.\n\n\nChina- high dependency of raw material inputs.\n\nRussia- lots of oil, natural gas, fertilizers, paladium, lithium.\nGreen revolution also doesn't work without Russia.\n\n\nWind and solar- don't work so well, batteries are a problem.\nNot enough lithium in the world, maybe better battery technology.\n\nGermany- stupidly still not embracing nuclear power.\nRaw materials and such\n\nGermany in trouble, but connected.\n\nWill Ukraine blow up pipes? Maybe:\n\n1. Yes, if they dont' want Russia to get funded.\n2. No, cause they're now a Candidate member of EU and EU is going to rebuild them, so they have interest EU doesn't suffer and can function => has energy.\n\nPutin maybe had to just invade Donbas + Land Bridge and would've been fine ?\n\nBiden -putin meeting before that - mainly about hacker attacks on colonial pipe.\n\nIf China/industrial base of world- mass retirement.\n\n\nBut china very innovative, might be quite advanced in technology. This might offset some of the problems.\nThey are **more innovative and entrepreneural than anyone but USA**.\n\nGermany- energy problems, can't keep lights on, 3rd industrial base in the world.\n\n\n\n\nAmerican political system.\n\n[[science.math.Game Theory.Voting#^firstpost]]\n\nFactions within the 2 parties. \n\nRe-alignment process within the parties, what are the key questions that determine if Republican or Democrat.\n\nProcess takes time and is not painless.\n\nEveryone wants their issue to be the one that determines if you're Republican or Democrat.\n\nUnion movement is now Republican...\n\n\nOil/natural gas maybe quite inelastic ([[science.economics.Price Elasticity]])- if supply drops by 5-8%, price double.\n\nUS needs to double industrial base.\nMaybe high growth+high inflation in US.\n\nChina- leader on climate, new tech...\n\nMaybe 1.5-2 deg, rather than 3-6 before hitting net 0.\n[[science.economics.Climate Change and Global Warming]]\n\nChinese geography not great for wind/solar.\nGermany good for wind. But doesn't seem to work. Only generates 9% of actual electricity, >2 trillion of investment.\nUS good for wind+solar.\nUK good for wind+solar.\nSpain good for solar\nGreece good for solar+wind.\n\n\nNuclear. Germans not willing to embrace Nuclear as part of the long-term solution.\n\nPhisical chemistry - batteries.\n\n## What should we do?\nSome suggestions about american foreign policy...\n","n":0.048}}},{"i":307,"$":{"0":{"v":"United States","n":0.707}}},{"i":308,"$":{"0":{"v":"Russia","n":1}}},{"i":309,"$":{"0":{"v":"Prisoners of Geography (book notes)","n":0.447}}},{"i":310,"$":{"0":{"v":"Korea","n":1}}},{"i":311,"$":{"0":{"v":"Japan","n":1}}},{"i":312,"$":{"0":{"v":"China","n":1}}},{"i":313,"$":{"0":{"v":"Climate Change","n":0.707}}},{"i":314,"$":{"0":{"v":"Climate Change and Global Warming","n":0.447}}},{"i":315,"$":{"0":{"v":"Health","n":1}}},{"i":316,"$":{"0":{"v":"Life Extension ","n":0.707},"1":{"v":"\n\n# Life Extension\n[Article From Martin](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7238909/)\nSummary:\nNMN, resveratrol и Metfermin са добавки които подобряват производството на NAD и активират процесите за поправка на ДНК и съответно забавят процеса на стареене.\n\nСъщо е добре от време на време да гладуваш и да си на студено.\n\n\n# Colitis, IBS and IBD\n\n\n# The Longevity Diet\n[The longevity diet by Walter Longo](https://www.amazon.com/Longevity-Diet-Discover-Activation-Regeneration/dp/0525534075)\n\nFrom [Valter Longo's site](https://www.valterlongo.com/daily-longevity-diet-for-adults/)\n\n* Eat mostly vegan, plus a little fish, limiting meals with fish to a maximum of two or three per week. Choose fish, crustaceans, and mollusks with a high omega-3, omega-6, and vitamin B12 content (salmon, anchovies, sardines, cod, sea bream, trout, clams, shrimp.  Pay attention to the quality of the fish, choosing those with low levels of mercury.\n* If you are below the age of 65, keep protein intake low (0.31 to 0.36 grams per pound of body weight). That comes to 40 to 47 grams of proteins per day for a person weighing 130 pounds, and 60 to 70 grams of protein per day for someone weighing 200 to 220 pounds. Over age 65, you should slightly increase protein intake but also increase consumption of fish, eggs, white meat, and products derived from goats and sheep to preserve muscle mass. Consume beans, chickpeas, green peas, and other legumes as your main source of protein.\n* Minimize saturated fats from animal and vegetable sources (meat, cheese) and sugar, and maximize good fats and complex carbs. Eat whole grains and high quantities of vegetables (tomatoes, broccoli, carrots, legumes, etc.) with generous amounts of olive oil (3 tablespoons per day) and nuts (1 ounce per day).\n* Follow a diet with high vitamin and mineral content, supplemented with a multivitamin buffer every three days.\n* Select ingredients among those discussed in this book that your ancestors would have eaten.\n* Based on your weight, age, and abdominal circumference, decide whether to have two or three meals per day. If you are overweight or tend to gain weight easily, consume two meals a day: breakfast and either lunch or dinner, plus two low-sugar (less than 5 grams) snacks with fewer than 100 calories each. If you are already at a normal weight, or if you tend to lose weight easily or are over 65 and of normal weight, eat three meals a day and one low-sugar (less than 3 to 5 grams) snack with fewer than 100 calories.\n* Confine all eating to within a twelve-hour period; for example, start after 8 a.m. and end before 8 p.m. Don’t eat anything within three to four hours of bedtime.\n\n# Rhonda Patrick \n[Podcast By Rhonda Patrick](https://www.foundmyfitness.com/about-dr-rhonda-patrick)\n# Finnish Sauna Study\n[From Harvard Health](https://www.health.harvard.edu/blog/sauna-use-linked-longer-life-fewer-fatal-heart-problems-201502257755)\n\nResearchers from the University of Eastern Finland tracked 2,300 middle-aged men for an average of 20 years. They categorized the men into three groups according to how often they used a sauna each week. The men spent an average of 14 minutes per visit baking in 175° F heat. Over the course of the study, __49% of men who went to a sauna once a week died, compared with 38% of those who went two to three times a week and just 31% of those who went four to seven times a week__.  But is it causal or just healthier ppl went to the sauna??\n\n\n","n":0.043}}},{"i":317,"$":{"0":{"v":"Gut Health","n":0.707},"1":{"v":"\n\n# [Coffee Article](https://leetcode.com/problems/index-pairs-of-a-string/)\n\n* Moderate coffee consumption 'does not' hurt\n* Increases good bacteria Bifidobacterium (found in probiotic drinks).\n* Improves gut motility\n* Decaf also effective.\n* \n","n":0.204}}},{"i":318,"$":{"0":{"v":"IBS","n":1}}},{"i":319,"$":{"0":{"v":"Diagnostics","n":1}}},{"i":320,"$":{"0":{"v":"Personalized Medicine","n":0.707},"1":{"v":"\n\n# InsideTracker\n\n#TODO check if there's EU pages\n","n":0.378}}},{"i":321,"$":{"0":{"v":"COVID","n":1},"1":{"v":"\n\n\n[Статия](https://www.dnevnik.bg/analizi/2022/03/17/4325288_bulgarinut_reshi_che_s_covid-19_e_prikljucheno_i/)","n":1}}},{"i":322,"$":{"0":{"v":"Testing","n":1},"1":{"v":"\n\n# [Rapid Test Efficacy](https://covid19-sciencetable.ca/sciencebrief/use-of-rapid-antigen-tests-during-the-omicron-wave/)\n\n![](/assets/images/2022-02-21-19-47-13.png)","n":0.5}}},{"i":323,"$":{"0":{"v":"CS","n":1},"1":{"v":"\n[[root.science.CS.Algorithms]]\n\nAlgorithms are important...\n\n\n","n":0.577}}},{"i":324,"$":{"0":{"v":"Languages","n":1},"1":{"v":"n\n","n":1}}},{"i":325,"$":{"0":{"v":"Python","n":1}}},{"i":326,"$":{"0":{"v":"Libraries","n":1}}},{"i":327,"$":{"0":{"v":"Flask","n":1}}},{"i":328,"$":{"0":{"v":"Jupyter","n":1},"1":{"v":"\n\n# Magic Commands\n\n1. %%capture - capture the output of stdout/stderr\n","n":0.316}}},{"i":329,"$":{"0":{"v":"Julia","n":1},"1":{"v":"\n\n## Pluto\n[[engineering.technologies.tooling.Pluto]]\n\n\n\n## Common packages to install\n\n```{julia}\n# in pkg mode\n] add Plots QuantEcon GLPK Pluto PlutoUI IJulia JuMP DifferentialEquations Turing Zygote ForwardDiff DiffEqBayes MCMCChains Distributions PyPlot PyCall RCall DataFramesMeta DataFrames Query Queryverse LanguageServer Flux StatsBase StatsPlots Revise PackageCompiler Gadfly Gen JuliaDB DSGE LightGraphs DiffEqFlux  Convex ModelingToolkit Interact Optim ApproxFun  Unitful CSV JSON \n\n\n] add Plots QuantEcon GLPK Pluto PlutoUI IJulia JuMP DifferentialEquations Turing Zygote ForwardDiff DiffEqBayes MCMCChains Distributions PyPlot DataFramesMeta DataFrames Query LanguageServer Flux StatsBase StatsPlots Revise JuliaDB LightGraphs DiffEqFlux  Convex ModelingToolkit Optim CSV JSON \n```\n\n\n","n":0.108}}},{"i":330,"$":{"0":{"v":"Theory","n":1}}},{"i":331,"$":{"0":{"v":"Functional Programming","n":0.707},"1":{"v":"\n\n\nOh yeah. I have heard that spreadsheets are purely functional programs with full referential transparency \nand also-also I think they re-implemented excel in F# in like a hackathon in Cambridge MS research\nand then this was expanded to a bigger project, where the F# code compiles to typescript and this then is MS excel 365\nwhereas b4 it would open a new VM on Azure and will be super slow\nmight be murky on the details, reference here:\nhttps://www.microsoft.com/en-us/research/podcast/advancing-excel-as-a-programming-language-with-andy-gordon-and-simon-peyton-jones/\n\n\n[[engineering.technologies.Spreadsheets]]\n\n[[science.CS.theory.Streams, Arrows, Reactive Programs]]","n":0.113}}},{"i":332,"$":{"0":{"v":"R","n":1}}},{"i":333,"$":{"0":{"v":"Mathematica","n":1}}},{"i":334,"$":{"0":{"v":"LaTeX","n":1}}},{"i":335,"$":{"0":{"v":"JavaScript","n":1}}},{"i":336,"$":{"0":{"v":"Interop","n":1},"1":{"v":"# Thrift\n\nCan use it to say define a service:\n```\nexception CustomException {\n  1: string message;\n}\n\nstruct AddResult {\n  1: i32 sum;\n}\n\nservice Calculator {\n  AddResult add(1:i32 a, 2:i32 b) throws (1:CustomException ex);\n}\n\n```\n\nthen generate fome python sclenecton:\n```\nthrift --getn py cancleator.thrift\n```\n\nThen the python snippet willbe like so:\n\n```python\nimport calculator.Calculator as Calculator\n\nclass CalculatorHandler:\n    def add(self, a, b):\n        if a < 0 or b < 0:\n            raise Calculator.CustomException(\"Both numbers must be non-negative\")\n        else:\n            return Calculator.AddResult(sum=a+b)\n\nhandler = CalculatorHandler()\nprocessor = Calculator.Processor(handler)\ntransport = TSocket.TServerSocket(port=9090)\nserver = TServer.TSimpleServer(processor, transport)\nserver.serve()\n\n```\n\nAnd the clinent as so:\n\n```cpp\n#include <iostream>\n#include <thrift/transport/TBufferTransports.h>\n#include <thrift/protocol/TBinaryProtocol.h>\n#include \"Calculator.h\"\n\nusing namespace apache::thrift;\nusing namespace apache::thrift::protocol;\nusing namespace apache::thrift::transport;\nusing namespace ::calculator;\n\nint main() {\n    std::shared_ptr<TTransport> socket(new TSocket(\"localhost\", 9090));\n    std::shared_ptr<TTransport> transport(new TBufferedTransport(socket));\n    std::shared_ptr<TProtocol> protocol(new TBinaryProtocol(transport));\n    CalculatorClient client(protocol);\n\n    try {\n        AddResult result = client.add(3, 4);\n        std::cout << \"3 + 4 = \" << result.sum << std::endl;\n\n        client.add(-1, 2);\n    } catch (CustomException& ex) {\n        std::cout << \"Caught custom exception: \" << ex.message << std::endl;\n    }\n\n    transport->close();\n    return 0;\n}\n\n```\n\nNote the port above in the cpp code.\nEvene if this doesn't work great, iit should be representing the relationships between the components well enough.","n":0.077}}},{"i":337,"$":{"0":{"v":"HTML","n":1},"1":{"v":"\nsome information from here used from: !()[https://bookdown.org/yihui/blogdown/css.html]\n\n# HTML\n\nbody and head\n\nValidate html code via:\n[w3 validatoro\n](https://validator.w3.org)\n\n\n6 possible header lavels `(h1, h2, h3, h4, h5, h6)`.\n\n\n\nCSS is language to describe the look and formatting of \ndocuments, written in HTML. CSS is respondible for the visual style of your site.\n\n\n[[engineering.technologies.Web Techologies.Hugo]] is a technology for web development.\n\n\nthis makes everything w/ id 'favorite' italic.\n\n```{html}\n<html>\n<style> \n#favorite {\n    font-style: italic;\n}\n</style>\n<ul id=\"tea-list\">\n  <li>Earl Grey</li>\n  <li>Darjeeling</li>\n  <li>Oolong</li>\n  <li>Chamomile</li>\n  <li id=\"favorite\">Chai</li>\n</ul>\n</html>\n```\n\nWhat goes inside the linked CSS document is essentially a list of rules (the same list could appear internally between the style tags, if you are using the second method). Each rule must include both a selector or group of selectors, and a declarations block within curly braces that contains one or more property: value; pairs. Here is the general structure for a rule:\n\n```{css}\n\nselectorlist {\n    property: value;\n    /* more property: value; pairs*/\n}\n```\n\n","n":0.084}}},{"i":338,"$":{"0":{"v":"CUDA","n":1}}},{"i":339,"$":{"0":{"v":"theory","n":1}}},{"i":340,"$":{"0":{"v":"coroutines","n":1},"1":{"v":"\n\n\n# Example of a coroutine for determinign market price of an asset,\nbased on number of people who bet 'buy'\n\n\n[[finance.various]]\n'''{python}\nCreated on Aug 23, 2012\n@author: Stefan1\nimport random\ndef suppDem(bids):\n    if(len(bids)==0):\n        return 0\n    return random.normalvariate(sum(bids),sum(bids))/len(bids)\ndef priceGenCoroutine(initialPrice=0,priceUpdateMechanism=suppDem):\n    currentPrice=initialPrice\n    while True:\n        currentPrice+=suppDem((yield currentPrice))\n    \ndef stochasticTrendFollow(prices):\n    if(len(prices)<2):\n        return random.normalvariate(0,0.5)\n    return random.normalvariate((prices[-1]-prices[-2]),0.5)\ndef AgentCoroutine(strategy=stochasticTrendFollow):\n    obsPrices=[]\n    currentBid=0\n    while True:\n        obsPrices.append((yield currentBid))\n        currentBid=strategy(obsPrices)\n        \nif __name__ == '__main__':\n    numAgents=10\n    market=priceGenCoroutine()\n    agents=[AgentCoroutine() for i in range(numAgents)]\n    for ag in agents:\n        next(ag)\n    numSteps=10\n    currPrice=next(market)\n    for i in range(numSteps):\n        bids=[]\n        print (currPrice)\n        for ag in agents:\n            bids.append(ag.send(currPrice))\n        currPrice=market.send(bids)\n\n\n```\n","n":0.11}}},{"i":341,"$":{"0":{"v":"Streams, Arrows, Reactive Programs","n":0.5},"1":{"v":"\n\nhttps://www.haskell.org/arrows/\n\n[[engineering.technologies.tooling.Pluto]]\n# Reactive Programmingh\n\n[[engineering.technologies.Spreadsheets]]","n":0.577}}},{"i":342,"$":{"0":{"v":"NP-complete Problems","n":0.707}}},{"i":343,"$":{"0":{"v":"NLP","n":1},"1":{"v":"\n\n\nFrom [this medium article](https://towardsdatascience.com/a-no-frills-guide-to-most-natural-language-processing-models-part-1-the-pre-lstm-ice-age-86055dd5d67c)\nPre- LSTM Dark Age\n\n```mermaid\ngraph LR;\na[NNLM-2003] --> b[word2Vec 2013]--> c[GloVe 2014]-->d[\"fastText(2016)\"]\n```\n\n\n\n\n\n# Seq2Seq ","n":0.267}}},{"i":344,"$":{"0":{"v":"Sequence To Sequence Modelling","n":0.5},"1":{"v":"\n\n# RNN- Driven\n\nThe standard first approach is to consider a recurrent model w/ state h:\n\n$h_n=f(h_{n-1},x_n)$ as the encoding engine. k\n\nThen the __key assumption__ is that the final encoding state $h_T$ contains enough information to carry out the decoding process:\n\n$y_t=g(h_t,y_{t-1},y_{T-2},...,y_0)$\n\nWhere $y_0$ is randomly initialized!!!\n\nWe can see it's a lot of burden on $h_T$.\n\n[[science.stats.Deep Neural Networks.Attention Mechanisms]]\n\n\n\n","n":0.135}}},{"i":345,"$":{"0":{"v":"Code Transformations","n":0.707}}},{"i":346,"$":{"0":{"v":"Differentiable and Probabalistic Programming","n":0.5},"1":{"v":"\n\n[[science.CS.theory.Code Transformations.Differentiable Programming.tensorflow]]\n[[science.CS.theory.Code Transformations.Differentiable Programming.pytorch]]\n[[science.cs.theory.Code Transformations.Differentiable Programming.turing]]\n[[science.CS.theory.Code Transformations.Differentiable Programming.Flux]]\n[[science.CS.theory.Code Transformations.Differentiable Programming.jax]]\n[[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming.gen]]\n\n\n### Kotlin Differentiable_programming Article\n[infoQ article](https://www.infoq.com/presentations/differentiable-framework-kotlin/)\n\n\n\n","n":0.229}}},{"i":347,"$":{"0":{"v":"stan","n":1},"1":{"v":"\n[Stan Reference Manual](https://mc-stan.org/docs/2_19/reference-manual/index.html)\n\n[[science.CS.theory.Code Transformations.Differentiable and Probabalistic Programming]]\n","n":0.378}}},{"i":348,"$":{"0":{"v":"pymc3","n":1}}},{"i":349,"$":{"0":{"v":"gen","n":1}}},{"i":350,"$":{"0":{"v":"Differentiable Programming","n":0.707},"1":{"v":"\n\nReferences: [Matlab site](https://www.mathworks.com/help/deeplearning/ug/deep-learning-with-automatic-differentiation-in-matlab.html).\n\n# Automatic Differentiation\n\n\n$x_1 exp(-\\frac{1}{2}(x_1^2+x_2^2)).$\n```mermaid\ngraph TB;\nx1[x1] --> u1[u2=x1^2];\nx2[x2] --> u2[u2=x2^2];\nu2[u2] --> u3[u3=u2+u1];\nu1[u1] --> u3[u3];\nu3 --> u4[u4=-1/2u3];\n```\n\n# Forward Mode Differentiation\n\n# Reverse Mode Differentiation\n","n":0.209}}},{"i":351,"$":{"0":{"v":"turing","n":1}}},{"i":352,"$":{"0":{"v":"tensorflow","n":1},"1":{"v":"[Website](https://www.tensorflow.org/)\n","n":1}}},{"i":353,"$":{"0":{"v":"dual_numbers_algebra","n":1},"1":{"v":"\n\n[Some tutorial from oxford](https://www.robots.ox.ac.uk/~tvg/publications/talks/autodiff.pdf)\n\n[[science.math.calculus]]\n\n[[science.CS.theory.Code Transformations]]\n\n\n","n":0.447}}},{"i":354,"$":{"0":{"v":"pytorch","n":1},"1":{"v":"[Website](https://pytorch.org/)\n\n\n# Multiple submodules\n\n## DataLoader\nIt's a iterator helper that would deal w/\n\n\n\n# Neural Nets, Forward and Backwards\n \n To create a neural net, make a class that inherits from `nn.Module`.\n It needs to implement `__init__` and `forward` methods.\n\n ```{python}\nclass DenseNet(nn.Module):\n    def __init__():\n        self.input = nn.Flatten()\n        self.linear_relu_stack=nn.Sequential(\n            nn.Linear(28*25, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n    def forward(self,x):\n        x = self.input(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\nmodel = DenseNet().to(device)# send the model to execute on the gpu/cpu\n\n\n ```\n\n So that's how we encode a a given computational tree.\n Probably there are various simplifications/specializations of the above. Is\n\n## Parameter fitting/optimization and backward pass\n\nAfter we have defined the 'evaluation' part, next we want to see how to fit parameters to the data.\n\nDefine 'optimizer' object and the loss funciton object\n__NB__ #NB optimizer needs to be supplied the model.parameters() as an argument in order to know what it's optimizing.\n\nIf you think about a function instead, the optimizer\nwould need to know the function + it's parameters, so it makes sense.\n```{python}\nloss_fn = nn.CrossEntropyLoss()\n!!!\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n```\n\n\n# Training loop\n\nWe have to define the training loop by ourselves.\n\nThe backpropagation is done via the following opaque at first look pattern:\n\n```{python}\noptimizer.zero_grad() # nullify previous gradient data\nloss.backward() #compute gradient (!!!)\noptimizer.step() #make step w/ the optimizer\n```\n\nOverall  Ifind the above pattern confusing, as there is quite a bit of state manipulation there. \nIn particular, the signatures of functions there don't tell you about what's happening.\n\n\n Nevertheless, it's short and only 'strange' part is\n\n` loss.backward() `. Why is this actinf on the model parameters? no idea.\n\nfrom [here](http://seba1511.net/tutorials/beginner/blitz/neural_networks_tutorial.html#:~:text=Loss%20Function,-A%20loss%20function&text=MSELoss%20which%20computes%20the%20mean,the%20input%20and%20the%20target.&text=So%2C%20when%20we%20call%20loss,Variable%20accumulated%20with%20the%20gradient.)\n\n\n**So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Variables in the graph will have their .grad Variable accumulated with the gradient.**\n\n Ok, so that makes sense. Every Variable has a .grad Variable, which is acted upon by `loss.backward()`.\n\n```\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    # I guess this tells the model that\n    # paramteres are free to update\n    \n    model.train()\n    # for each batch of samples\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation and parameter update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Occasional progress report (like callback)\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n```\n\n\n## [What Does model.train() do?](https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n\n\nIt sets the model so layers that behave differently during train and test set.\n\n`model.train()` and `model.eval()` basically only care about dropout and batch normalization layers atm.\n\n```{python}\ndata = [[1, 2],[3, 4]]\nx_data = torch.tensor(data)\n```\n\n# [loss.backward()](https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944)\n\n```\nloss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. In pseudo-code:\n```\n![](https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944/2)\n\n```{python}\nx.grad += dloss/dx\n\n```\n\nSo because of that we have to 0 the grad beforehand\n\n\n\n# Grad Mode\n(Enable grad)[https://pytorch.org/docs/stable/_modules/torch/autograd/grad_mode.html# enable_grad]\n\n\n## Torch.no_grad\n\nContext manager, disabling (thread-wise) grad calculations. Use when evaluating model.\n\n## a.item()\nif object is number/1 element tensor.\nuse a.tolist() otherwise.\n\n# Differentiable \nSome ops in torch are differentiable, some are not.\n\n# Tensors and differeentiataion\n\n['Autograd' is some engine,running in the background? Idk](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)\n\n\n# resources\n[Pytorch Internals Blog Post](http://blog.ezyang.com/2019/05/pytorch-internals/)\n","n":0.045}}},{"i":355,"$":{"0":{"v":"pymc3","n":1},"1":{"v":"\n\n[Bayesian Changepoint Detection w/ pymc3](https://cscherrer.github.io/post/bayesian-changepoint/)\n\n[[science.stats.Bayesian Framework]]\n","n":0.408}}},{"i":356,"$":{"0":{"v":"jax","n":1}}},{"i":357,"$":{"0":{"v":"Flux","n":1},"1":{"v":"\n[[science.cs.languages.julia]]\n[[science.CS.theory.Code Transformations.Differentiable Programming.tensorflow.dual_numbers_algebra]]\n\n\n","n":0.577}}},{"i":358,"$":{"0":{"v":"algos","n":1}}},{"i":359,"$":{"0":{"v":"mics","n":1},"1":{"v":"\n# 100 Prisoners Problems\n[](https://www.youtube.com/watch?v=_X_Q-_X_X_Q)\n\n[youtube](https://www.youtube.com/watch?v=C5-I0bAuEUE)\n[Evernote Link](https://www.evernote.com/shard/s101/nl/11122041/2b02fecb-f12e-46ad-a9d7-0a8bc96f3bfa?title=The%20100%20prisoners%20map%20-reduce%20probablistic%20%22analysis%22)\n (First,note that I haven't found a deterministic solution for the problem with \"stages buffering\", but trying to think of the ways to stochastically analyze the whole thing and how to get the optimum utility of time spend in jail/risk). The note is not very well structured ,if you have some questions (though it's completely useless problem, of course)  please call me.\n So, we assume that we can calculate the interarrival time, but we need a\nSo, the problem is:\n We are in a prison, and there is this warden ,who gives us the following game: We are prisoners;before the game starts, we can talk to each other, after it starts we can't talk any more.\n At random times ,the warden calls a random prisoner in a room with a light switch, which is initially off;.\n If at any point any of the prisoners announces that all the prisoners have visited the room, then all are free if he(she ?) 's correct.\n\n\n # [Linked List Cycle II](https://leetcode.com/problems/linked-list-cycle-ii/)\n\n Tortoise and hare algorithm to determine if present. Start from head, and ignore the equality of the 1st node.\n\n\nThen:\nif a nodes, then cycle of b:\nhare: $2*t$ \ntortoise:\n$t$\nthen:\n$t-a=2*t-a(mod b)$\n$t==0(mod b)$\nThus for the intersection node it's true that:\n$t-a==-a(mod b)$\n\nThus if we start from the head of the list, it's position is $1(mod b)$. If we advance $a$ times is $a+1(mod b )$ and in list.\nOn the other hand, if we start from the intersection node and also advance $a$ times it's position will also be $a+1(mod b)$.\nThus we can initialize 2nd pointer at the beginning, then move by one, until they meet, and that will be the first one.\n\n# [670. Maxiumum Swap](https://leetcode.com/problems/maximum-swap/)\n\nBookkeeping is a bit ugly, as well as the multiple num->string->list->string->num conversion chain; would be simpler to \nconvert directly to list of nums and operate on that.\n```{python}\ndef maximumSwap(num: int) -> int:\n    # let the digit representation be a1a2...\n    # we want to swap the earliest possible, for which we have a larger one after that, with the largest possible one \n    # after that. So we can start from the back and keep track of the max to right of current, and record last time it \n    # happened that current was not current maximum!\n    nm = str(num)\n    n = len(nm)\n    lastSwapPair=(float(\"inf\"),float(\"inf\"))\n    currMaxSeen = float(\"-inf\")\n    currMaxSeenIndex = float(\"inf\")\n    for i in range(n-1,-1,-1):\n        currDigit = int(nm[i])\n        # if swap candidate\n        if currDigit<currMaxSeen:\n            lastSwapPair = (i,currMaxSeenIndex)# simply update the maxSwapPair\n        elif currDigit==currMaxSeen:\n            continue\n        else:\n            currMaxSeen = currDigit\n            currMaxSeenIndex = i\n    #print(f\"{currMaxSeen=},{lastSwapPair=},{currMaxSeenIndex=}\")\n    nm = [c for c in nm]\n    #print(nm)\n    if lastSwapPair[0]<n:\n        tmp = nm[lastSwapPair[0]]\n        nm[lastSwapPair[0]] = nm[lastSwapPair[1]]\n        nm[lastSwapPair[1]] = tmp\n    #print(f\"{nm=}\")\n    return int(\"\".join(nm))\n            \n```\n\n# [1047. Remove All Adjacent Duplicates In String](https://leetcode.com/problems/remove-all-adjacent-duplicates-in-string/)\n\n```{python}\ndef popMultiple(q):\n    if q.qsize() <2:\n        return\n    else:\n        k,l = q.get(),q.get()\n        if k!=l:\n            q.put(l)\n            q.put(k)\n            return\n        else:\n            popMultiple(q)\n    \n    \nclass Solution:\n    def removeDuplicates(self, s: str) -> str:\n        # what we could do is to have\n        # 2 pointers- current left, current right\n        # 3 operations:\n        # if delete, \n        # just use a stack\n        from queue import LifoQueue\n        q = LifoQueue()\n        for c in s:\n            q.put(c)\n            popMultiple(q)\n        \n        return \"\".join(q.queue)\n\n```\n\n\n# [128. Longest Consecutive Sequence](https://leetcode.com/problems/longest-consecutive-sequence/)\n\nApproach: limited union-find. Namely, when we insert a new element, we have to check only if it connects to something to the left, then \ncheck if it connects to something to the right. No infinite cascading.\n\nSo, approach: \nkeep 2 dicts: for longest found sequence to the left, and to the right, at some points.\nWhen we insert something, we check if we're connecting, and if so, we lenght of the longest sequence to the left (and to the right).\n\nDo the same on the right-hand side, with the difference that if we're connecting the left and right-handside, we have to \ndelete the reference to the current element (forget about it)...\n```{python}\nclass Solution:\n    def longestConsecutive(self, nums: List[int]) -> int:\n\n        # Union-find?\n        seenElements = set()\n        if len(nums)<1:\n            return 0\n        # we keep track of 2 dicts:\n        # chain start and chain end\n        chainStart = {}\n        chainEnd = {}\n        for el in nums:\n            if el in seenElements:\n                continue\n            seenElements.add(el)\n            if el-1 in chainEnd:\n                oldLen = chainEnd[el-1]\n                beginning = el-1-oldLen+1\n                chainStart[beginning]+=1\n                del chainEnd[el-1]\n                chainEnd[el] = chainStart[beginning]\n            else:\n                chainStart[el] = 1\n                chainEnd[el] = 1\n            if el+1 in chainStart:\n                lenToRight  = chainStart[el+1]\n                elToRight = el+1+lenToRight-1 # new end to merge with\n                totalLen = lenToRight + chainEnd[el]\n                elToLeft = el - chainEnd[el]+1\n                del chainStart[el+1]\n                chainEnd[elToRight] = totalLen\n                chainStart[elToLeft] = totalLen\n                if elToLeft!=el:\n                    del chainEnd[el]\n                    if el in chainStart:\n                        del chainStart[el]\n        return max(chainStart[el] for el in chainStart)\n```\n\n# [886. Possible Bipartition](https://leetcode.com/problems/possible-bipartition/)\n #TODO write some notes about this.. see why it was slow...\n  An approach to detect a bipartite graph is to try to color it with 2 colors.\n    We can do this by using a color dict. Then we iterate through the graph (BFS sounds most natural for me in this case), and for each node, we assign it a color.\n    As usual, we use a 'seen' set to keep track of nodes we've seen. Now, as we're about to put a node in the queue, we first check if color doesn't exist or is compatible with the current node's color. If not, return false. If it has already been colored, we skip it. Else put it in the queue.\n    \n\n\n# https://leetcode.com/problems/number-of-islands/solution/\n#TODO see why slow\nSolution: dfs, counting components...\n\n\n\n# [Lowest common ancestor binary tree](https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree-iii/)\n\nkeep a dict, denoting how many of [p,q] we have found in the corresponding subtree.\nkeep a global state to know when we've found the answer...\n\n```{python}\n    def lowestCommonAncestor(self, p: 'Node', q: 'Node') -> 'Node':\n        # so what do we want to do here...\n        # no way of knowing \n        # idea: bubble up from both p and q; then bubble down from root\n        # return first thing that returns a 2\n        \n        from collections import defaultdict\n        numnodes = defaultdict(lambda :0)\n        while p is not None:\n            numnodes[p]+=1\n            pcurr = p\n            p=p.parent\n        root = pcurr\n        \n        #numnodes = defaultdict(lambda :0)\n        while q is not None:\n            numnodes[q]+=1\n            #pcurr = p\n            q=q.parent\n        # now explore in LRT order and return first thing that's a 2\n        found = None\n        def dfs(rt):\n            nonlocal found\n            if found is not None:\n                return \n            if rt.left:\n                dfs(rt.left)\n            if rt.right:\n                dfs(rt.right)\n            if found is None and numnodes[rt]==2:\n                found = rt\n            return\n        dfs(root)\n        return found\n\n```\n\n#[140. Word Break II](https://leetcode.com/problems/word-break-ii/)\n \n Backtracking solution\n```{python}\n    def wordBreak(self, s: str, wordDict: List[str]) -> List[str]:\n        # sounds like a backtracking thing\n        n = len(s)\n        res=[]\n        # current position, current partial sentence\n        partSent = []\n        def backtrack(cpos):\n            if cpos == n:\n                res.append(partSent.copy())\n                print(f\"{res=}\")\n                return\n            for candWord in wordDict:\n                if s[cpos:].startswith(candWord):\n                    partSent.append(candWord)\n                    backtrack(cpos+len(candWord))\n                    partSent.pop(-1)\n                #print(part)\n                #partSent.pop()\n                \n            return\n        backtrack(0)\n        return [\" \".join(sent) for sent in res]\n```\n\n#TODO - maybe look at the DP solutions in LC.\n\n[longest w/o rep chars](https://leetcode.com/explore/interview/card/facebook/5/array-and-strings/3008/)\n\nkeep a set, if new char in set, pop chars from correspondign indices.\n\n## Basic calculator\n\n(1+(4+5+2)-3)+(6+8)\n(10)\n\nidea:\nkeep:\ncurr Operand \ncurrent Operator (+ or -, so === sign)\ncurrent output\nstack of 'stuff for later FROM before' to remember the result when we enter a '('\n\nif digit- append to operand\n2 'stacks-'- a 'local' mini-stack, consisting of \n(output, operand, and operator ->eval() = output+operand*operator\n'global' stack, consisting of the list when we keep stuff for when we see a bracket. There we \ncan keep multiple (output, operand) pairs from before\nif + or -, evaluate current 'mini-stack',write to 'output',reset current, and write the new 'sign'\nif (, push to 'global' stack, reset output, operand and operator\nif ), finish current evaluation (res+sign*operand). Next thing in global stack wll be operator, so res*stack.pop().\nnext thing is the remembered value, so res+stack.pop() and that's the result. do we also reset sign?\n\n## [Minimum Number of opening/closings to add](https://leetcode.com/problems/remove-invalid-parentheses/solution/)\n\n### Remove Invalid Parentheses\n\nin each position, we consider adding.\n\nWe know how many left and how many right we should add to get the minimal correct number of brackets.\nwe backtrack and add expressions, in case in the end we have a valid state...\n\n## [k closest to origin](https://leetcode.com/problems/k-closest-points-to-origin/solution/)\n\nheap w/ keeping only the top k. O(nlogk) :). Sort is O(nlogn). \nbinary search wrt the distance to consider. O(n)\nIn this case, however, we can improve upon the time complexity of this modified binary search by eliminating one set of points at the end of each iteration. If the target distance yields fewer than kk closer points, then we know that each of those points belongs in our answer and can then be ignored in later iterations. If the target distance yields more than kk closer points, on the other hand, we know that we can discard the points that fell outside the target distance.\n\nBy roughly halving the remaining points in each iteration of the binary search, we reduce the total number of processes to $N + \\frac{N}{2} + \\frac{N}{4} + \\frac{N}{8} + ... + \\frac{N}{N} = 2N$\n This results in an average time complexity of $O(N)$.\n\n\n##[Minimal Rectangle](https://leetcode.com/problems/minimum-area-rectangle/)\n\n Idea- put points in set, consider each pair as a diagonal, check if it's a rectangle and it's area. $O(n^2)$ time, O(n) space.\n\n ## [Next Permutation](https://leetcode.com/problems/next-permutation/)\n \nVery similar to [Maximum Swap](https://leetcode.com/problems/maximum-swap/), but a bit more complicated.\nIn Maximum swap, we find the 'biggest' jump. Here, we want to find the 'smallest' jump+ fixup the stuff behind it.\nSo, we go backwards until we find a decreasing element in pos $i$. All nums in positions $j>i$ are sorted in decreasing order. We swap $i$ with the smallest number, larger than it, in $a[i+1...]$. \nNow, the numbers $a[i+1...]$ are still sorted in decreasing order. We __reverse the numbers in $a[i+1...]$ to get the smallest permutation__!!!\n\n## [Merge Intervals](https://leetcode.com/problems/merge-intervals/)\n\nSort and merge- straightforward.\n\n## [Valid Number](https://leetcode.com/problems/valid-number/)\nAnnoying.\nHere's the definition:\n```\nA valid number can be split up into these components (in order):\n\nA decimal number or an integer.\n(Optional) An 'e' or 'E', followed by an integer.\nA decimal number can be split up into these components (in order):\n\n(Optional) A sign character (either '+' or '-').\nOne of the following formats:\nOne or more digits, followed by a dot '.'.\nOne or more digits, followed by a dot '.', followed by one or more digits.\nA dot '.', followed by one or more digits.\nAn integer can be split up into these components (in order):\n\n(Optional) A sign character (either '+' or '-').\nOne or more digits.\n```\nJust implement it...\n\n\n## [Copy list with random pointer](https://leetcode.com/problems/copy-list-with-random-pointer/)\n\nKeep a hashmap w/ the copies and be careful of what's pointing to None and so on...\n\n## [Word Break II](https://leetcode.com/problems/word-break-ii/)\nBacktrack (or maybe use DP). state is current index, and a set of words we've collected so far.\nTo add a word, we check if s[ind:] starts with it, and call backtrack(ind+len(word), words+[word]))).\nWhen we reverse, we pop last word from partial solutions...\n\n\n## [Peak Element/ Local Maximum](https://leetcode.com/problems/find-peak-element/)\nFirst, check both ends. Check middle. If middle is peak, return. \nElse, check if they are ordered somehow. Check the slope as well...\n\n## [Simplify Path](https://leetcode.com/problems/simplify-path/)\n\nBasically we just keep a stack of the solution. We split the initial path by '/' and join it back. \nRules:\n* if we see \"..\", pop stack, as we're going up a directory.\n* if we see \".\" or \"\", do nothing.\n* else - append to stack.\nreturn \"/\"+\"/\".join(stack)\n\n```{python}\n    def simplifyPath(self, path: str) -> str:\n        m=path.split(\"/\")\n        # print(f\"{m=}\")\n        from queue import deque\n        res=deque()\n        for dr in m:\n            if dr==\"\" or dr==\".\":\n                continue\n            elif dr==\"..\":\n                if len(res)>0:\n                    res.pop()\n            else:\n                res.append(dr)\n        # print(f\"{res=}\")\n        return \"/\"+\"/\".join(res)\n```\n\n## [Binary Search Tree Iterator](https://leetcode.com/problems/binary-search-tree-iterator/)\n\nYou can serialize as an array, and then iterate through it.\n\n## [Binary Tree Right Side View](https://leetcode.com/problems/binary-tree-right-side-view/)\n Do BFS, keep track of the current depth, when it changes, add to res. Take care to add to res in the end as well (maybe there's a corner case).\n\n\n## [Kth Largest In Array](https://leetcode.com/problems/kth-largest-element-in-an-array/)\n\nSort $O(nlogn)$, heap with pops etc: $O(nlogk)$\n\n## [Basic Calculator II](https://leetcode.com/problems/basic-calculator-ii/)\n Multiply and divide, but no parentheses.\n Algorithm?\ncurrNum, currOp,stack = ...\nif digit- add to currNum\nif op:\n2 cases : \"+-\" vs \"*/\"\nops implicitly on the stack are '+' !!!\nWe have to delay the evaluation of \"+\" and \"-\" until the multiplications and divisions are \"done\".\n Conversely, if we see + or - we can 'evaluate' the stack so far by summing.\n If we see a * or /, if current op is -, then we put $-currentNumber$ to stack.\n if current op is \"+\", we put currentNumber to stack.\n if we see an op, and previous op was * or /, we evaluate op(stack.pop(),currentNumber) and add this to the currentNumber.\n ...\n\n finally add everything to the stack and that's the result...\n\n\n \n ## [Group Shifted Strings](https://leetcode.com/problems/group-shifted-strings/)\n\n Create the signature be the tuple of differences between the chars.\n Then, we can group strings by signature.\n Take care signatures are tuples os they're hashable as keys.\n If N-num strings,, K = max length of strings, then we have $O(N*K)$ time and $O(K*N)$ space.\n\n##  [Binary Tree Vertical Order](https://leetcode.com/problems/binary-tree-vertical-order-traversal/)\n* Do BFS, keep track of current depth AND current index. Then we sort in the end.\nMaybe we can use a hashmap to store the current depth and the string.\n\nO(nlogn)\nAnother option:\ndo BFS, put results in a hashmap.\nThen, we can sort the keys and iterate through them. Know the range of the keys.\nSee also\nhttps://leetcode.com/problems/vertical-order-traversal-of-a-binary-tree/solution/\nfor a slightly harde rversion.\n987. Vertical Order Traversal of a Binary Tree\n\n\n## Nested List Weighted Sum\n DFS\n```{python}\nclass Solution:\n    def depthSum(self, nestedList: List[NestedInteger]) -> int:\n        def dfs(nested_list,depth):            \n            total = 0\n            for nested in nested_list:\n                if nested.isInteger():\n                    total+=nested.getInteger()*depth\n                else:\n                    total+=dfs(nested.getList(),depth+1)\n            return total\n\n        return dfs(nestedList,1)\n\n\n```\n\n\n\n## [Maximum Subarry Sum](https://leetcode.com/problems/maximum-subarray/solution/)\n\nKadane $maxEndingHere[i] = max(maxEndingHere[i-1]+nums[i])$. Can optimize to not hold a whole array of maxEndingHere, but a single number,  in an obvious way obvious reasons (loop ).\n\n## [Top K frequent Elements](https://leetcode.com/problems/top-k-frequent-elements/)\n\nCounter + heap would yield O(n*log(k)) time and O(n) space. Counter + sort would be just O(nlog(n))\n\n__Quickselect__ would be O(n^2) worst case, O(n) average case.\n\n #TODO start top fb questions from 408- valid word abbreviation\n\n ##  (Range Sum of BST)[https://leetcode.com/problems/range-sum-of-bst/]\n  \n  Keep a global for the sum\n  Option 1: just traverse the whole tree (DFS) and check the value of the values.\n  Option 2:In the DFS code, add 2 parameters 'high' and 'low'. Depending on the passed  parameters, we can prune the tree and decide weather to go to left and/or right, changing the 'high' and 'low'. Values accordingly.\n\n\n\n# (Remove Duplicates from Sorted Array)[https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/]\n\n I think the best approach would be similar to the merge 2 arrays problem.\n So probabaly best way would be to first go forward and count the number of remaining elements $k$.\n Then, go from front, initializing 2 pointers- one we write FROM, and another we WRITE TO. We advance both of them in an obvious way. The \n __write from__ pointer will always be >= to __write to__ pointer.\n We can then never write to a place we haven't read from already.\n\n# [leetcode 525 Max Contignouse Array](https://leetcode.com/problems/contiguous-array/)\nGiven a binary array nums, return the maximum length of a contiguous subarray with an equal number of 0 and 1.\nlet's first build the prefix sums with 0 =-1,1=1. Then, we're looking for 'maximal size array with balance 0'. I think we can do this in O(n) time with a 2-pointer approach.\nFor example\n\n\n\n# [1065. Index Pairs of a string](https://leetcode.com/problems/index-pairs-of-a-string/)\n\n\napproach:\n\nBuild a set out of the words. Then check if each pair in there \n$O(n^2)$ time, $O(n*max(len(words)))$ space.\n\nAnother approach?\n\nVariation of KMP?\n\nTrie? This will be like $O(n*log(n))$\n\n\n# [1060. Missing Element in Sorted Array](https://leetcode.com/problems/missing-element-in-sorted-array/)\n\nNotice that if the array $a$ is sorted, then the number of missing elements up to \nindex $i$ is $f(i)= a[i]-a[0]-i$!!\n\nNow, use binary search to find $i$, such that\n$f(i)<=k<f(i+1)$\nTake care of corner cases $i=n-1$.\nNow we can return $a[i]+(k-f(i))$.\n\n# [Find Peak Element 2D](https://leetcode.com/problems/find-a-peak-element-ii/)\n**No two adjanced cells are equal !!**\n\nA peak element is one that's strictly greater than its neighbors to left, right,\ntop, and bottom.\n\nApproach:\n1. There is a maximal element.\n2. a. There is a maximal element in the leftmost column, on the \nrightmost column, or in the middle column\nCheck them\n\n2. Take the max element in the middle column. Check numbers in the same row on both sides. Now, if we're increasing in one of these directions, we must have \nat least 1 local maximum in that direction... Thus recurse there\nWhy? Starting from the max in the middle, we can build up an increasing chain of values.\nThis chain won't cross to the other half, cause by design we took the max element of the boundary.\n\n\n\n\n# [1231. Divide Chocolate](https://leetcode.com/problems/divide-chocolate/)\n\nApproach: \nmaximin of consequtive chunks...\nLet sweetness be $s$.\nMin we can possibly get is $min(s)$. Max is $floor(sum(s)/k)$.\nStepsize is maybe min(s).\nCan we do efficient binary search in this interval?\n\nForm the cumsum array.\n\nChecking for feasibility:\nWe can do k bisect calls for a given number and see if it works.\nComplexity: $k*log(n)$.\nTotal Complexity:\nO(log(sum(s))-min(s)*log(n)*k)\n\nAnother solution:\n\nsame binary search, but linear check.\nComplexity O(n*log(sum()/min(s)))\n\n\n\n# [Shortest Distance To Target Color](https://leetcode.com/problems/shortest-distance-to-target-color/)\n\nWe're given a 1-d array of colors. \nThen we have a bunch of queries, asking the shortest distance from a given point \nto a given color.\n\nWe can prep some stuff that makes queries fast.\n\nIdea:\nFor each color, keep 2 Arrays:\n```\n{'color':[start_index,end_index]} \n```\n\nof the intervals in question. Then do binary search on both intervals.\nIf you get 'same' interval, which would correspond to bisect_right returning \nsay $k+1$ on the start and $k$ on the end, return 0.\n\nElse return min(abs(pos-dat[col][0][k]) # start to the right\n,abs(pos-dat[col][1][k-1])# end to the left\n)\n\nBe careful about the indices!!! Above might have off-by-1 error. \n\n\n\n# [1229 Meeting Scheduler](https://leetcode.com/problems/meeting-scheduler/)\n\nGiven availability time intervals for 2 people and a meeting duration of __duration__, return the earliest time they can meet.\n\nIdea:\n sort ALL time slots. then go trough them;\n if there is an overlap as we go, they can't be for the same person!\n\n\n\n\n# [287. Find the Duplicate Number](https://leetcode.com/problems/find-the-duplicate-number/)\n\nUse only constant extra space.\nDon't modify the array nums.\n\nsol1:\nSort, then go.\nIdea 2 : negative marking.\nIdea 3: Tortoise and hare.\n  1. step 1: detect cycle\n  2. Step 2: start from there, do single steps to find the 'entrance' of the cycle.\n    Can do some modular arithmetics to prove it...\n\n\n# [42. Trapping Rain Water](https://leetcode.com/problems/trapping-rain-water/)\n\nFor each cell, what we're trapping is:\n\n\n $trapped_i = max(maxToLeft_i,maxToRight_i)-height_i$\n So can do it in $O(n)$ time and $O(n)$ extra memory.\n\n # [1868. Product of Two Run-Length Encoded Arrays\n](https://leetcode.com/problems/product-of-two-run-length-encoded-arrays/)\n\nJust take care of the bookkeepign quite carefully...\n\n# [340. Longest Substring with at most k distinct characters](https://leetcode.com/problems/longest-substring-with-at-most-k-distinct-characters/)\n\n\nGiven a string s and an integer k, return the length of the longest substring of s that contains at most k distinct characters.\n\nSliding window + hashmap.\nIn the hashmap, map character-> it's rightmost position.\nWhen The hashmap gets full, get the character with minimal rightmost position. Delete this, new start is this+1.\n\n#\n#  [1004. Max Consecutive Ones III](https://leetcode.com/problems/max-consecutive-ones-iii/)\n\nGive an array of binary numbers, return the maximum number of consecutive 1s if you're allowed to flip at most $k$ 0's.\n\nIdea:\nTry to calculate 'maximum number to flip if 1'seq' ends\nat a given index...\n\nSay we build a cumsum of 0's. \n\nThen $maxUntil_i = i-min(j| cumsum_1(j)>=i-k)$\n\nthis can be found w/ binary search.\n\n# [1886. Determine Whether Matrix Can Be Obtained By Rotation](https://leetcode.com/problems/determine-whether-matrix-can-be-obtained-by-rotation/)\n\nNote the clockwise rotations of $R^{m*m}$ matrix transforms the coordinates as follows:\n\n\n$(i,j)\\rightarrow (j,m-i) \\rightarrow (m-i,m-j) \\rightarrow (m-j,i) \\rightarrow (i,j)$\n\nand with the 0-based indexing:\n\n$(i,j)\\rightarrow (j,m-i-1) \\rightarrow (m-i-1,m-j-1) \\rightarrow (m-j-1,i) \\rightarrow (i,j)$\n\nWe can use this directly to check if the matrix is a rotation of the original matrix.\n\n![[science.math.Linear Algebra.Rotation Matrices#2D]]\n\n\n\n# [739. Daily Temperatures](https://leetcode.com/problems/daily-temperatures/)\n\n Use monotonously decresing stack of temperatures (temp,ind) starting from the back.\n\n# [48. Rotate Image](https://leetcode.com/problems/rotate-image/)\n\n![](/assets/images/2022-04-01-12-31-37.png)\nSo iterate over the right-top indices and do the swap w/ some intermediate variables.\nTake care of the 0-indexing and of the ranges.\n\nSecond option:\nNote that:\n\n$\\mathbf{R}(\\pi/2) = \\left[\\begin{array}\n{rrr}\n0 & -1  \\\\\n1 & 0  \\\\\n\\end{array}\\right] = \\left[\\begin{array}\n{rrr}\n0 & 1  \\\\\n1 & 0  \\\\\n\\end{array}\\right]*\\left[\\begin{array}\n{rrr}\n1 & 0  \\\\\n0 & -1  \\\\\n\\end{array}\\right]\n$\n\nthe first part is the 'transpose', so simply $(i,j)->(j,i)$\nThe second part is a left-to-right flip.\n\n\n# [54. Spiral Matrix](https://leetcode.com/problems/spiral-matrix/)\n\nLet the matrix be $m*n$.\nAlgorithm:\n1.Initialize the top, right, bottom, and left boundaries as up, right, down, and left.\n2. Traverse from left boundary to right boundary (direction (0,1)). Update right boundary\n3. Go from bottom to top (direction(1,0)). update top. \n... etc\nwhen traversing right-to-left or top-to-bottom, check if we're already at the bottom or left, respectively (to check if we have to finish).\n\n\n\n\n\n```\n\n\n\n\n\n\n\n  ","n":0.018}}},{"i":360,"$":{"0":{"v":"mics problems","n":0.707},"1":{"v":"\n\n# Least Common Ancestor\n\n#TODO \n\n[Read this and rephrase solution](https://leetcode.com/problems/lowest-common-ancestor-of-a-binary-tree/solution/)\n\n\n# Leetcode 507. Perfect Number\n\nA perfect number is a number that is equal to the sum of its positive divisors, excluding the number itself.\nlet $x$ is a number.\nLet's think about $n=kl$ then sm(kl)=sm(k)*sm(l)+k+l (?).\nExample:\n$sm(4) = sm(2)*sm(2)+2$\n\n\n\n# [Exclusive time of Functions](https://leetcode.com/problems/exclusive-time-of-functions/)\n\n* Process logs in order and put them in a stack\n* 'start' log is opening bracket\n*  we keep 'time wasted' variable, initialized at 0. It is always re-initializied at 0 whenever the stack is empty. So the 'slate is clean'\n* 'end' log is closing bracket. If we get an end log, then the previous one is it's 'start' counterpart. Record time $time(end)+1-time(start)-timeWasted$ for this process in the array. \nReason for the timeWasted is this time was actually used up by other processes and accounted for already. Reason for +1 is just the way the problem does the bookkeeping, i.e. start 1 means 'start at BEGINNING of period 1', while end 2 means 'end at END of period 2'.\n We then re-initialize timeWasted as simply $time(end)-time(start)+1$ is stack is non-empty ans $0$ is stack is empty.\n * O(n) time, O(n) space\n \n\n[Custom Sort String](https://leetcode.com/problems/custom-sort-string/)\n\nWe're given 2 strings, 1 of the order and 1 of the actual string. have to re-sort the actual string like the order is sorted.\n```\nInput: order = \"cba\", s = \"abcd\"\nOutput: \"cbad\"\n\n```\n\nUse a Counter to represent the actual string and re-build from scratch in an obvious way. \nneed also a $set$ to hold the chars in the string, but not\nin the order.\n\n[Toposort solution also possible, check it out.](https://leetcode.com/problems/custom-sort-string/discuss/1704409/Python-3-solutions-(hashmap-lambda-in-sort-and-Topological-sort))\n\n\n#TODO \n\n[Balance a Binary Search Tree](https://leetcode.com/problems/balance-a-binary-search-tree/)\n\nAlgorithm:\n* Build a sorted array via in-order (left,top,right) traversal of the tree.\n* Re-build a new tree from the array.\n```{python}\n# Definition for a binary tree node.\n# class TreeNode:\n#     def __init__(self, val=0, left=None, right=None):\n#         self.val = val\n#         self.left = left\n#         self.right = right\nclass Solution:\n    def balanceBST(self, root: TreeNode) -> TreeNode:\n        # step 1: build arr via in-order traversal\n        arr = []\n        \n        def dfs(nd):\n            if not nd:\n                return\n            dfs(nd.left) #left\n            arr.append(nd.val)# root \n            dfs(nd.right)# right\n        dfs(root)\n        print(f\"{arr=}\")# check\n        assert sorted(arr) == arr # check\n\n        # step 2: re-build tree recursively from arr\n        n= len(arr)\n        # take care for off-by-one errors\n        def build(lo=0,hi= n):\n            if lo>=hi:\n                return None\n            else:\n                mid = (lo+hi)//2\n                curr = TreeNode(arr[mid])\n                curr.left = build(lo=lo,hi=mid)\n                curr.right = build(lo=mid+1,hi=hi)\n                \n                return curr\n        return build()\n            \n```\n\n[Shortest Path in Binary Matrix](https://leetcode.com/problems/shortest-path-in-binary-matrix/submissions/).\n\nSimple BFS. Maybe can use A* to be fast but idk.\n\n\n```{python}\nclass Solution:\n    def shortestPathBinaryMatrix(self, grid: List[List[int]]) -> int:\n        # idea:\n        # use bfs\n        m = len(grid)\n        n = len(grid[0])\n        def getNeighbors(cell): #O(1)\n            i,j = cell[0],cell[1]\n            return [(i+k,j+l) for k in range(-1,2) for l in range(-1,2) if \n                   abs(k)+abs(l)>=1 and 0<=k+i<m and 0<=j+l<n \n                    and grid[i+k][j+l]==0\n                   ]\n        if (grid[0][0]!=0) or (grid[m-1][n-1]!=0):\n            #print(f\"no end or beginning,{grid[0][0]=},{grid[m-1][n-1]=}\")\n            return -1\n        # note: when we see a cell, we never need to update the distance to it!!\n        from queue import deque\n        q = deque()\n        seen = dict()\n        q.append(((0,0),1))\n        while q:\n            cell,dist = q.popleft()\n            if cell in seen:\n                continue\n            else:\n                seen[cell]=dist\n            potentialNeighbors=getNeighbors(cell)\n           # print(f\"{cell=},{potentialNeighbors=}\")\n            for nb in potentialNeighbors:\n                if nb==(n-1,m-1):\n                    return dist+1\n                if nb not in seen:\n                    q.append((nb,dist+1))\n                \n            \n            \n        if (m-1,n-1) in seen:\n            return seen[(m-1,n-1)]\n        else:\n            return -1\n```\n\n[Employee Free Time](https://leetcode.com/problems/employee-free-time/)\n\n\nEmployee free time problem:\n\nWe are given a list schedule of employees, which represents the working time for each employee.\n\nEach employee has a list of non-overlapping Intervals, and these intervals are in sorted order.\n\nReturn the list of finite intervals representing common, positive-length free time for all employees, also in sorted order.\n\nSolution:\nstart w/ free interval $(-\\infty,\\infty)$. Make a priority queue of intervals from teh emp schedule list.\nRepeadedly choose the employee schedule item w/ the earliest start time..\nThen:\n* if the end time of the current interval is less than the start time of the current free interval, do nothing \n\n* if the end time of the current free interval is smaller than the start tiem of employe interval, add current to solution, re-initialize new to point to end time of employee\n* if overlap with emp.start< current.start, then update current.start to emp.end. If needed, update current.end as well\n\n* if overlap with emp.start>current.start, can add\n(current.start,emp.start)  to solution and update current to start at emp.end. The end $\\infty$ if emp.end> current.end, else current.end.\n\n[Skyline](https://leetcode.com/problems/the-skyline-problem/)\n\nApproach - put all buildings in a priority queue, sorted by start time. Bellow instructions skip some corner cases, as they are very verbose (but are in code).\n\n* Initialize 'current' as $-\\infty,\\infty,0$ (the default building), sky(result) to empty list.\n* Pop the queue. Call this proc. If current.end < proc.start,\nadd current to skyline. if $current.start < proc.start<=current.end$, then :\n * if current.height > proc.height, update start of proc to be $current.end$, and add back to queue.\n * if $current.height<proc.height$ , add current to skyline, check if need to add $proc.end,current,start,current.height$ to queue.\n * in the end add the last one if needed.\n\n Be careful with corner cases, e.g. when 2 heights are the same, with deleting the first dummy building, and adding the last building if needed. \n\n ```{python}\n from heapq import heappop, heappush\nclass Solution:\n    def getSkyline(self, buildings: List[List[int]]) -> List[List[int]]:\n        # make a priority q w/ all buildings. We\n        q = []\n        for b in buildings:\n            heappush(q,b)\n        res = []\n        # start, end, height\n        current = [float(\"-inf\"),float(\"inf\"),0]\n        while q:\n            proc = heappop(q)\n            s,e,h = proc[0],proc[1],proc[2]\n            if s>current[1]:\n                \n                res.append([current[0],current[2]])# finalize a 'current'\n                current = [s,e,h]\n            if s==current[1]:\n                # case 1:\n                # if heights are different:\n                if h!=current[2]:\n                    res.append([current[0],current[2]])# finalize a 'current'\n                    current = [s,e,h]\n                else:\n                    current[1] = e\n                    continue\n                    \n            else:\n                # the new one is higher:\n                if current[2]<h:\n                    if  current[0]<s:\n                        res.append([current[0],current[2]])\n                    \n                    if current[1]>e:# if old one continues after current one, add it back to queue\n                        heappush(q,[e,current[1],current[2]])\n                    else:# do nothing, it will be swallowed\n                        pass\n                    current = [s,e,h]\n                    \n                # same height\n                elif current[2]==h:# update end time of current\n                    current[1] = max(e,current[1])\n                else:# old one is higher\n                    if e>current[1]:\n                        heappush(q,[current[1],e,h])\n        # notice we only add stuff after finishing the processing, so we'll be left\n        # with somethign to add in the end\n        if current[0]>res[-1][0]:\n            res.append([current[0],current[2]])\n        res2 = []\n        for r in res[1:]:\n            if not res2 or r[1]!=res2[-1][1]:\n                res2.append(r)\n        return res2\n                    \n                    \n                \n            \n        \n ```\n\n\n#todo check tree and stuff \n\n\n[Longest Increasing Path in Matrix](https://leetcode.com/problems/longest-increasing-path-in-a-matrix/)\n\nApproach:\nfirst do topo-sort in order to 'linearize' the graph.\nThen do a DFS from each node, and keep track of the max path length, memoizing the DP calls.\n\n```{python}\nfrom functools import lru_cache\n\nclass Solution:\n    def longestIncreasingPath(self, matrix: List[List[int]]) -> int:\n        # first step-topological sort to find potential roots\n        st = []\n        m = len(matrix)\n        n = len(matrix[0])\n        def getNeighbors(cell):\n            i,j = cell[0], cell[1]\n            return [(i+k,j+l) for k in range(-1,2) for l in range(-1,2)\n                   if 0<=i+k<m and 0<=j+l<n and abs(k)+abs(l) ==1 \n                    and matrix[i][j]<matrix[i+k][j+l]\n                   \n                   ]\n        st = []\n        seen = set()\n        #totBest = 0\n        from collections import defaultdict\n        bestWalk = defaultdict( lambda :1)\n        \n        def walk(nd):\n           # print(f\"walking {nd=}\")\n            if nd in seen:\n                return\n            seen.add(nd)\n            for nb in getNeighbors(nd):\n                #print(f\"{nd=},{nb=}\")\n                walk(nb)\n            st.append(nd)\n            return\n        \n        #print(st)\n        for i in range(m):\n            for j in range(n):\n                walk((i,j))\n        #print(st)\n        \n        @lru_cache(maxsize = None)\n        def dpwalk(node):\n            #curr = 1\n            best = 1\n            for nb in getNeighbors(node):\n               # print(f\"{node=},{nb=}\")\n                k= dpwalk(nb)\n                best = max(best,k+1)\n            return best\n        \n        bestFound = 1\n        for el in st[-1::-1]:\n            bestFromHere = dpwalk(el)\n            #print(f\"{el=},{bestFromHere=}\")\n            bestFound= max(bestFound,bestFromHere)\n            \n        \n        return bestFound\n```\n\n # Problem 1041: Robot Bounded in Circle\n  On an infinite plane, a robot initially stands at (0, 0) and faces north. The robot can receive one of three instructions:\n* \"G\": go straight 1 unit;\n* \"L\": turn 90 degrees to the left;\n* \"R\": turn 90 degrees to the right.\n\n\nThe robot performs the instructions given in order, and repeats them forever.\n\nReturn true if and only if there exists a circle in the plane such that the robot never leaves the circle.\n\nLet $v$ be the vector we move the robot in one instruction set, and $d$ be the direction in radians, relative to the initial direction of the robot.\n\nSolution/ answer:\nAfter 1 instruction set we're either at the origin, or we're __not__ facing north.\n\n### Proof\nExercise for reader.\n\n\n# Problem 1463. Cherry Pickup II\nYou are given a rows x cols matrix grid representing a field of cherries where $grid[i][j]$\n represents the number of cherries that you can collect from the $(i, j)$ cell.\n\nYou have two robots that can collect cherries for you:\n\nRobot #1 is located at the top-left corner (0, 0), and\nRobot #2 is located at the top-right corner (0, cols - 1).\nReturn the maximum number of cherries collection using both robots by following the rules below:\n\nFrom a cell (i, j), robots can move to cell $(i + 1, j - 1), (i + 1, j), \\text{or }  (i + 1, j + 1)$.\nWhen any robot passes through a cell, It picks up all cherries, and the cell becomes an empty cell.\nWhen both robots stay in the same cell, only one takes the cherries.\nBoth robots cannot move outside of the grid at any moment.\nBoth robots should reach the bottom row in grid.\n\n### Solution:\nLet D(col1,col2,row) be the maximum number of cherries that can be collected if the robots are at\n$(row,col1),(row,col2)$.\nThen:\n\n\n\n$$\nD(c_1,c_2,r) = \\max_{cn_1 \\in [c_1-1,c_1,c_1+1],cn_2\\in {c_2-1,c_2,c_2+1}} D(cn_1,cn_2,r+1) +\\begin{cases}\ngrid[c_1,r]+grid[c_2,r] \\text{ if } c_1!=c_2\\\\\ngrid[c_1,r] \\text{ else }\n\\end{cases}\n$$\nThe solution is then $D(0,n-1,0)$\n \n\nWith the obvious boundary conditions. We use memoization table to store the results .A small optimization we could use is to make sure $c_1<=c_2$ troughout the execution of the algorithm.\n\n\n## 1094. Car Pooling\n\n\nThere is a car with capacity empty seats. The vehicle only drives east (i.e., it cannot turn around and drive west).\n\nYou are given the integer capacity and an array trips where trip[i] = [numPassengersi, fromi, toi] indicates that the ith trip has numPassengersi passengers and the locations to pick them up and drop them off are fromi and toi respectively. The locations are given as the number of kilometers due east from the car's initial location.\n\nReturn true if it is possible to pick up and drop off all passengers for all the given trips, or false otherwise.\n\n \n\nExample 1:\n\n```\nInput: trips = [[2,1,5],[3,3,7]], capacity = 4\nOutput: false\n```\nExample 2:\n```\nInput: trips = [[2,1,5],[3,3,7]], capacity = 5\nOutput: true\n```\n\nSolution:\nwe simply merge all intervals and keep track if the capacity is enough.\n\n```{python}\nclass Solution:\n    def carPooling(self, trips: List[List[int]], capacity: int) -> bool:\n        from collections import defaultdict\n        # aggregate pickups and dropoffs at any time something happens'\n        pickups = defaultdict(lambda :0)\n        dropoffs = defaultdict(lambda :0)\n        for t in trips:\n            pickups[t[1]]+=t[0]\n            dropoffs[t[2]]+=t[0]\n        # sort !! NB- this step is important, BUT if we have limited numbers\n        # we can use bucket sort for linear time!!!\n        pickupsAndDropoffs = sorted(\n            list(\n                set(\n                    [t[1] for t in trips]+[t[2] for t in trips]\n                )\n            ))\n        currOcc = 0\n        for t in pickupsAndDropoffs:\n            if t in pickups:\n                currOcc+=pickups[t]\n            if t in dropoffs:\n                currOcc-=dropoffs[t]\n            assert currOcc>=0\n            if currOcc>capacity:\n                return False\n        return True\n                                    \n```\n\n### Approach 2: Bucket Sort\n##### Intuition\n\nNote that in the problem there is a interesting constraint:\n\n$0 <= trips[i][1] < trips[i][2] <= 1000$\nWhat pops into the mind is Bucket Sort, which is a sorting algorithm in $\\mathcal{O}(N)$ time but requires some prior knowledge for the range of the data.\n\nWe can use it instead of the normal sorting in this method.\n\nWhat we do is initial 1001 buckets, and put the number of passengers changed in corresponding buckets, and collect the buckets one by one.\n\nAlgorithm\n\nWe will initial 1001 buckets, iterate trip, and save the number of passengers changed at i mile in the i-th bucket.\n\n## \n\n\n## 131. Palindrome Partitioning\n_Given a string s, partition s such that every substring of the partition is a palindrome. Return all possible palindrome partitioning of s._\n\n \n```\nExample 1:\n\nInput: s = \"aab\"\nOutput: [[\"a\",\"a\",\"b\"],[\"aa\",\"b\"]]\nExample 2:\n\nInput: s = \"a\"\nOutput: [[\"a\"]]\n \n\nConstraints:\n\n1 <= s.length <= 16\ns contains only lowercase English letters.\n```\n\n#### Solution\n\nGiven that we're being asked to return everything, we can use backtracking to solve this problem. We also note the maximum possible length of the string is 16, \nwhich is small enough to do a brute force search.\n\n```{python}\ndef isPalindrome(a):\n    return a==a[-1::-1]\ndef findPossiblePalindromesStartingFromBeginning(s):\n    res = []\n    if len(s)==0:\n        return res\n    for i in range(0,len(s)):\n        if isPalindrome(s[:i+1]):\n            res.append(s[:i+1])\n    return res\n        \n            \n            \n    \nclass Solution:\n    def partition(self, s: str) -> List[List[str]]:\n        res = []\n        n = len(s)\n        \n        def backtrack(partialResult,currInd):\n            #print(f\"{partialResult=},{currInd=}\")\n            if currInd >n:\n            #    pass\n                return\n            elif currInd == n:\n                print(\"adding\")\n                res.append(partialResult.copy())\n                return\n            else:\n                possibleContinuations = [(len(c),c) for c in findPossiblePalindromesStartingFromBeginning(s[currInd:])]\n                print(possibleContinuations)\n                for ind,c in possibleContinuations:\n                    # partialResult.append(c)\n                    backtrack(partialResult+[c],currInd+ind)\n                    \n            #partialResult.pop(-1)\n            return res\n        return backtrack([],0)\n            \n                \n```\n\n\n## 1762. Buildings With an Ocean View\n\nThere are n buildings in a line. You are given an integer array heights of size n that represents the heights of the buildings in the line.\n\nThe ocean is to the right of the buildings. A building has an ocean view if the building can see the ocean without obstructions. Formally, a building has an ocean view if all the buildings to its right have a smaller height.\n\nReturn a list of indices (0-indexed) of buildings that have an ocean view, sorted in increasing order.\n\n \n\nExample 1:\n```\nInput: heights = [4,2,3,1]\nOutput: [0,2,3]\n```\nExplanation: Building 1 (0-indexed) does not have an ocean view because building 2 is taller.\nExample 2:\n\nInput: heights = [4,3,2,1]\nOutput: [0,1,2,3]\nExplanation: All the buildings have an ocean view.\nExample 3:\n\nInput: heights = [1,3,2,4]\nOutput: [3]\nExplanation: Only building 3 has an ocean view.\n \n\nConstraints:\n\n1 <= heights.length <= 105\n1 <= heights[i] <= 109\n\nit's a bit slow cause of the appending, but can be fixed by instead starting from the the beginning\nand maintaining a monotonously decreasing sequence- every time we add an element,\nit deletes all elements already in the stack that have smaller height already (we keep the index in the stack and check heights dynamically) .\nFinally return the stack.\n```\nclass Solution:\n    def findBuildings(self, heights: List[int]) -> List[int]:\n        maxToRight = float(\"-inf\")\n        n = len(heights)\n        res = []\n        for i in range(n-1,-1,-1):\n            if heights[i]>maxToRight:\n                res.append(i)\n                maxToRight = heights[i]\n        return res[-1::-1]\n```\n\n\n## 1891. Cutting Ribbons\n\nYou are given an integer array ribbons, where ribbons[i] represents the length of the ith ribbon, and an integer k. You may cut any of the ribbons into any number of segments of positive integer lengths, or perform no cuts at all.\n\nFor example, if you have a ribbon of length 4, you can:\nKeep the ribbon of length 4,\nCut it into one ribbon of length 3 and one ribbon of length 1,\nCut it into two ribbons of length 2,\nCut it into one ribbon of length 2 and two ribbons of length 1, or\nCut it into four ribbons of length 1.\nYour goal is to obtain k ribbons of all the same positive integer length. You are allowed to throw away any excess ribbon as a result of cutting.\n\nReturn the maximum possible positive integer length that you can obtain k ribbons of, or 0 if you cannot obtain k ribbons of the same length.\n\n \n```\nExample 1:\n\nInput: ribbons = [9,7,5], k = 3\nOutput: 5\nExplanation:\n- Cut the first ribbon to two ribbons, one of length 5 and one of length 4.\n- Cut the second ribbon to two ribbons, one of length 5 and one of length 2.\n- Keep the third ribbon as it is.\n```\n\nNow you have 3 ribbons of length 5.\n\n\n# Lc 4 Median of Two Sorted Arrays\n\n\nProbably have to do it quickly...\nlet's try 'binary search' approach.\nThe median is the 50th pctile...\n\n```python\n\ndef get_order_statistic(arr1,arr2,k):\n    m = len(arr1)\n    n = len(arr2)\n    # corner cases- m or n =0, k = 0, \n    # k = m,k = n\n    # then\n    a1 = arr1[k//2-1]\n    a2 = arr2[k//2-1]\n    #then make 2 cuts as follows:\n    \n```\n\n\n# LC 1071. GCD of strings\n\nstring 'division with reminder?'\n\n is it 'just take the common prefix'?\n no, actually the solution is quite fun:\n```{python}\n# note that thegdc is non-empty iff a+b = b+a\n# so we can just check if a+b = b+a\n# and take the a[gdc(len(a),len(b)):] as the answer\n\nreturn a[gdc[len(a),len(b)]:] if a+b == b+a else \"\"\n```\n\n# verify alien dictionary\nlearend about itertools zip_longest.\n\n\n","n":0.02}}},{"i":361,"$":{"0":{"v":"Matrix Chain Multiplication Algorithm","n":0.5},"1":{"v":"### A little bit of a tricky problem insofar as dynamic programming goes.\n\n[[science.CS.algos.dynamicProgramming]]\n\n2 matrices $M\\in \\mathcal{R}^{n,m}$ , and $N\\in \\mathcal{R}^{m,p}$ are multiplied. \nThe result has dimensions $n\\times p$. Naive multiplication will be O(n*m*p) time. Reason is that \nwe have to do $np$ scalar products, of $m$ elements each.\n\nNow, with [[science.CS.algos.StrassenAlgorithm]], we can reduce the problem to $O(n^{log_2 7})$ time.\n\nSo, if we have a chain of matrices to multiply, how do we find the optimal order of multiplication?\n\nNotice we can do bottom up dynamic programming. First say $i$ is such a matrix __last__ matrix in the \nchain in the sense that all other matrices have already participated in a multiplication.\n\nIn that case, we know the sizes of the matrices left:\nnamely they are $n_1,n_i$ and $m_i,m_L$ so nrow of first, ncol of last, and the middle one.\n\nLet \n$$C(i,j)= \\text{minimum cost of multiplying } A_i\\times A_{i+1}\\times A_S{i+2} \\times...\\times A{j}$$ \n\n![](/assets/images/2022-01-10-15-39-33.png)\n\n We're done.\n\n\n\n\n\n\n\n","n":0.082}}},{"i":362,"$":{"0":{"v":"dynamicProgramming","n":1},"1":{"v":"\n# Dynamic programming \n## Shortest path problem in DAGs\n\n$G={V,E}$\n<!-- $dist[v] = min(dist[u] + l(u,v) | u,v \\in e})$ -->\n\nas the dag is linearizeable, the above will never go back to the same node.\n\n\n$dist[v] = min(dist[u] + l(u,v) | (u,v) \\in e)$\n\n\n## Knapsack problem with DP\n* Input: capacity C, items {(w,v),...}\n* Output: max value V\n\nSolve the problem by dynamic programming. Let $f{i,w}$ be the max value, achieved by using the first i items and at most w weight.\n\n* $f(i,w) = max{f(i-1,w), f(i-1,w-w_i) + v_i}$\n* if i==0 or w==0, f(i,w)=0\n* if w<0, f(i,w)=$-\\infty$\n* V=f(n,C)\n \n Memoize\n\n ### Longest Increasing Contignous Subsequence\n * Input: array A\n    * Output: length of the longest increasing subsequence\n* Let $f(i)$ be the length of the longest increasing subsequence ending at A[i].\n$f(1) = 1$\n$f(i)=1+f(i-1)*(A[i]>=A[i-1] ? 1:0)$\n\nIf noncontiguous\n\n$f(i)=1+max_{j\\in [1,i-1]}(f(j)|A[j]<=A[i])$\n\n# Edit Distance\n\nFirst operation is either:\n* Insert S2[1] at first position of S1 (equivalent to delete S2[1])\n* Insert S1[1] at first position of S2 (equivalent to delete S1[1])\n* Replace S1[1] with S2[1] \n* S[1] match S2[1] so we continue\n\nLet $E(i,j)$ be the edit distance between S1[i..] and S2[j..].\n$E(i,j)=1+min(E(i,j+1),E(i+1,j),E(i+1,j+1) - (1  S1[i]==S2[j]))$\n$$\n\\begin{equation}\nx = \\begin{cases}\n        1 & \\text{if } x = y \\\\\n        2 & \\text{if } x \\neq y \\\\\n        \\end{cases}\n\\end{equation}\n$$\n\n\n### 67. Add Binary\n\n__Given two binary strings a and b, return their sum as a binary string.__\n\n \n\nExample 1:\n```\nInput: a = \"11\", b = \"1\"\nOutput: \"100\"\nExample 2:\n\nInput: a = \"1010\", b = \"1011\"\nOutput: \"10101\"\n```\nConstraints:\n\n1 <= a.length, b.length <= 104\na and b consist only of '0' or '1' characters.\nEach string does not contain leading zeros except for the zero itself.\n\nGrade school addition- first reverse the strings, then use carry etc.\n\n### 312. Burst Balloons\n\n\nYou are given n balloons, indexed from $0$ to $n - 1$. Each balloon is painted with a number on it represented by an array nums. You are asked to burst all the balloons.\n\nIf you burst the ith balloon, you will get $nums[i - 1] * nums[i] * nums[i + 1]$ coins. If $i - 1$ or $i + 1$ goes out of bounds of the array, then treat it as if there is a balloon with a 1 painted on it.\n\nReturn the maximum coins you can collect by bursting the balloons wisely.\n\n#### Solution \n\n\n*NB (Nota Bene)*\n\nIn the exposition intervals are 1- indexed, while in code they are 0 -based. \nIdea:\nlet $i$ be the index of the __LAST__ balloon to burst in the interval [left,right].\nThen when we burst $i$ we gain $nums[left-1]*nums[i]*nums[right+1]$ coins.\nWhy don't we need to make sure that $left-1$ and $right+1$ are still in play?\nBecause in the recursive calls to our subroutine (say $dp$) we have the $left-1$ and $right+1$ elements of the array as elements assumed to be burst __after__ all baloons in the interval\n$[left,right]$ are gone.\nWe prepend and append $1$ to the array to handle the special case when we have $left-1$ or $right+1$ out of bounds and adjust the loop accordingly.\n\n\n\n\n\n```\nfrom functools import lru_cache\n\nclass Solution:\n    def maxCoins(self, nums: List[int]) -> int:\n        if len(nums) > 1 and len(set(nums)) == 1:\n            return (nums[0] ** 3) * (len(nums) - 2) + nums[0] ** 2 + nums[0]\n        \n        n = len(nums)\n        nums = [1]+nums+[1]\n        \n        @lru_cache(None)\n        def dp(lind,rind):\n            if lind>rind:\n                return 0\n\n            best = float(\"-inf\")\n\n            for i in range(lind,rind+1):\n                gain = nums[i]*nums[lind-1]*nums[rind+1]\n                rest = dp(lind,i-1)+dp(i+1,rind)\n                best = max(best,gain+rest)\n                \n            return best\n                        \n                    \n        \n        \n        \n        return dp(1,len(nums)-2)\n```\n[[science.CS.algos.matrixChainMultiplication]]\n\n##  https://leetcode.com/problems/minimum-score-triangulation-of-polygon/\n\n[1039. Minimum Score Triangulation of Polygon](https://leetcode.com/problems/minimum-score-triangulation-of-polygon/)\n\nou have a convex n-sided polygon where each vertex has an integer value. You are given an integer array values where values[i] is the value of the ith vertex (i.e., clockwise order).\n\nYou will triangulate the polygon into n - 2 triangles. For each triangle, the value of that triangle is the product of the values of its vertices, and the total score of the triangulation is the sum of these values over all n - 2 triangles in the triangulation.\n\nReturn the smallest possible total score that you can achieve with some triangulation of the polygon.\n\n \n\nExample 1:\n![](/assets/images/2022-01-10-15-42-44.png)\n\nInput: values = [1,2,3]\nOutput: 6\nExplanation: The polygon is already triangulated, and the score of the only triangle is 6.\n\n```{python}\n```\n\n\n\n\n# Vazirani Chapter on Dynamic Programming\n#dynamic_programming\n*Algorithms Vazirani*\n[Vazirani Intro Book](http://algorithmics.lsi.upc.edu/docs/Dasgupta-Papadimitriou-Vazirani.pdf)\n\n### Dynamic Programming Chapter\n\n------------\nDist in dag- algo\n```\n1. linearize nodes in graph\n2. for each v in V, in linearized order:\n    dist(v) = min_{u,v in E}(dist(u,v)+l(u,v))\n```\n\nlinearize by topo-sort\ntopo-sort is dfs with looking at completion time\n\n-------------\nlinearization of collection of sybproblems, solving after solving previous (and caching result).\n\n-------\n\nlongest inc subsequence:\n\n\nSolve as follows\na(i)->len of longest increasing ending here\nInput: $nums$\n$a(i) = 1+max(a(j)|j<i,nums[i]>nums[j])$\n\n---------------\n\ndp- problmes are a bit smaller, not times smaller like divide and conquer...\n\n--------------\n","n":0.037}}},{"i":363,"$":{"0":{"v":"String hashing","n":0.707},"1":{"v":"\n\n# Rolling Polynomial string hashing\nPick a prime p and a large number m, not a multiple of p.\nthen it's obvious\n\n![](/assets/images/2022-07-29-17-04-15.png)\n\n\nWe can also quickly calsulate the hashes of substrings.\n\nIdk if we can also quickly check for partial matches (i.e. given a string and a potential partial string, check if really is partial).\nI suppose it's not difficult...\n#todo think about this and read more from [the cp algorithms page](https://cp-algorithms.com/string/string-hashing.html#search-for-duplicate-strings-in-an-array-of-strings)\n\n\n# Rabin-Karp for string matching...s\n\nGiven a string $s$ and a text (alsostring) $t$ find if thereare matches of $s$ in $t$ and if so, enumerate them\n\nAlgorithm - calculate the hash of $s$ and the hashes of all $len(s)$ substrings of $t$, and compare them...\n\ndetails for exercise...\n\n# KMP, DP and preprocessing...\n\n\nwe make a partial match table, which allows us to see where the next possible match starts from, and start matching only from there...\n\n\n","n":0.085}}},{"i":364,"$":{"0":{"v":"StrassenAlgorithm","n":1},"1":{"v":"Strassen's algorithm is a divide-and-conquer algorithm for matrix multiplication.\nIt works by noting that the product of two matrices of size $n\\times n$ can be expressed as follows:\n\n$$ \nXY = \\begin{bmatrix}\nA & B \\\\\nC & D\n\\end{bmatrix}*\\begin{bmatrix}\nE & F \\\\\nG & H\\\\\n\\end{bmatrix}=\\begin{bmatrix}\nAE+BG & AF+BH \\\\\nCE+DG & CF+DH \\\\\n\\end{bmatrix}\n$$\n\n![](/assets/images/2022-01-10-15-29-26.png)\n\nThe running time will be then:\n$T(N ) = 7T(\\frac{n}{2})+O(N^2)$ \nwhere the $O(N^2)$ part comes from the fact that we have a bunch of $N/2*N/2$ matrices to sum (in order to combine).\n\n\n\n","n":0.115}}},{"i":365,"$":{"0":{"v":"Run Length Encoding","n":0.577}}},{"i":366,"$":{"0":{"v":"Network Flows","n":0.707},"1":{"v":"\n# Max Flow\n## Linear-Programming Formulation\n### Edge Formulation\n### Path Formulation\n## Ford-Fulkerson \n## Push-Relabel\n\n## Network Simples\n\n# Multicommodity Flow\n[Multicommodity Flow in Julia](https://drive.google.com/open?id=12OlkSvm7qVNrrdlbXIJhps2gR4j7b0lk&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n[[science.cs.languages.julia]]\n[[science.math.Optimization.JuMP]]\n\n## Path-based formulation \n[Luca Trevisan's lecture](https://www.cs.stanford.edu/~trevisan/cs261/lecture16.pdf)\n\n\n## Fixed Cost Min-Cost Flows\n\n\n\n## Distributed Max Flow\n[Distributed Max Flow Algorithm](http://www.lifl.fr/ispdc2005/presentations/ispdc-maxflow-PHAM.pdf).\n\n\n[[science.math.Optimization.Linear Programming]]\n[[science.CS.algos.Combinatorial Optimization]]\n","n":0.167}}},{"i":367,"$":{"0":{"v":"MiniMax","n":1},"1":{"v":"\nThere are various types of minimax algos.\nHere we mostly refer to ones, dealing with 2- player games.\n\n[Link with introduction](https://www.geeksforgeeks.org/minimax-algorithm-in-game-theory-set-1-introduction/)\n\n\n[[science.math.Game Theory]]\n\n### Summary\n\n__Setting__: 2-player alternating turn game\n","n":0.2}}},{"i":368,"$":{"0":{"v":"Master Theorem of Algorithmic Complexity","n":0.447}}},{"i":369,"$":{"0":{"v":"Greedy Algorithms","n":0.707},"1":{"v":"[[science.math.theory.Algebra.Matroids]]\n\n\n# Huffman Coding:\n\nMinimizes Entropy:\n\n$min E(p(symb)*len(enc(symbol))) = E(-log_2 p*p)$ \n$len(symbol)= depth$\n\ncan solve by greedy:\nbuild up tree bottom-up\nevery time join symbols w/ minimum prob/freq (and make another symbol for the join).\nrecover tree in the end\nuse priority queue to pop smallest frequency every time.\n\nhuffman coding also minimizes entropy.\n\n\n-----------\ngreedy algo\n\n------------\n## Dijkstra:\n\n\n\n## \nnegative edges:\ncombine op on edges\nrepeat |V|-1 times\nif wanna detect negative CYCLEs repeat once more and obs is fixed point changes.\ndijkstra wants prio queue\n\n## Minimum Spanning Tree:\n\ninvariant: add minimal edge that doesn't add a cycle\n\nkruskal- do that, need prio queue and union find to keep track of partial forests\n-----------\n\n## Prim Algorithm\n\nkeep track of tree only; then use priority queue (similar to dijkstra then, almost same.\n\n\nVazirani algos:\n\n## Horn clauses\n\n\n Implications, whose left-hand side is an AND of anynumber of positive literals and whose\nright-hand side is a single positive literal. These express statements of the form “if the\nconditions on the left hold, then the one on the right must also be true.” For instance,\n(z ∧ w) => u\nmight mean “if the colonel was asleep at 8 pm and the murder took place at 8 pm then\nthe colonel is innocent.” A degenerate type of implication is the singleton “⇒ x,” meaning\nsimply that x is true: “the murder definitely occurred in the kitchen.”\n2. Pure negative clauses, consisting of an OR of any number of negative literals, as in\n(!u ∨ !v ∨ !y)\n(“they can’t all be innocent”).\nGiven a set of clauses of these two types, the goal is to determine whether there is a consis-\ntent explanation: an assignment of true/false values to the variables that satisfies all the\nclauses. This is also called a satisfying assignment.\n\nSo SAT is in general np-hard\nbut if instead set of horn clauses, greedy efficient\nhttps://tryalgo.org/en/satisfiability/2016/12/04/horn-sat/\nlinear time algo for horn clauses (horn-sat, instead of SAT).\nAnother mention here:\nhttps://people.eecs.berkeley.edu/~sseshia/219c/lectures/SATSolving.pdf\n\n2-sat\n\nSpecial Cases of 3-SAT that are\npolynomial-time solvable\n• 2-SAT\n– T. Larrabee observed that many clauses in\nATPG tend to be 2-CNF\n• Horn-SAT\n– A clause is a Horn clause if at most one literal\nis positive\n– If all clauses are Horn, then problem is HornSAT\n– E.g. Application:- Checking that one finitestate system refines (implements) anoth\n\nhttps://www.geeksforgeeks.org/2-satisfiability-2-sat-problem/\nso horn-sat and 2-sat\nTo understand this better, first let us see what is Conjunctive Normal Form (CNF) or also known as Product of Sums (POS). \nCNF : CNF is a conjunction (AND) of clauses, where every clause is a disjunction (OR).\nNow, 2-SAT limits the problem of SAT to only those Boolean formula which are expressed as a CNF with every clause having only 2 terms(also called 2-CNF).\n-------\nso 2-sat is if we can make cnf w/ 2 clauses everywhere...\n\n------\n\n\nThe two kinds of clauses pull us in different directions. The implications tell us to set\nsome of the variables to true, while the negative clauses encourage us to make them false.\nOur strategy for solving a Horn formula is this: We start with all variables false. We then\nproceed to set some of them to true, one by one, but very reluctantly, and only if we absolutely\nhave to because an implication would otherwise be violated. Once we are done with this phase\nand all implications are satisfied, only then do we turn to the negative clauses and make sure\nthey are all satisfied\n\n------\nthis scheme is linear-time and 'greedy' in the negative sense (we want many literals to be false cuase of the negative clauses.\n\n--------\nhorn clause thing:\n2 types of clauses:\nPositive Implicative:\nrhs is single positive\nlhs is any number of positive :\n(a and b)=>c\n=>c\n.. etc\n(a and b and c)=>d\npure negative:\nOR with negatives:\n------------------\n\n'greedy' :start with all false, then only make true is some implication is broken.\nwhen all implications are ok, check all pure negatives.'\n\n--------------------------------\n\n\n5.4. Set cover greedy approximation:\n\n--------\nPick the set w/ largest number of uncovered elements has ln(n) approximation ratio.\n\n----------\n\nShortest paths in dags are easy\n\n----------\ndag-> can linearize\n\n\n'\n\n\n\n","n":0.041}}},{"i":370,"$":{"0":{"v":"Graph Traversal","n":0.707},"1":{"v":"\n\n# \n\n\n# Basic Tree Traversals\n## DFS\n\nT-top(or root)\nL=left\nR=right\n\n\n[Tree traversals](https://www.geeksforgeeks.org/tree-traversals-inorder-preorder-and-postorder/)\n### Pre-order\nT, L , R \n### In-order\nL, T, R\n### Post-order :\nL R T\n\n## BFS \n### Iteratively deepening BFS\n\n\n## Heuristic Search\n### A*\n consisten heuristic\n\n\n# DFS Notes\n\nExploring w/ dfs\n```{python}\n\nseen = set()\ndef explore(V:List[Int],E:Dict[Int,Set[int]],v):\n    if v in seen:  #optionally!!!\n        return\n    seen.add(v)\n    previsit(v) # optionally! use if need to detect cycles, other stuff \n    for w in E[v]:\n        explore(V,E,w)\n    postvisit(v) # optionally! useful to keep track of cycles and other stuff\n\n```\n\nIntuition:\n Explore labyrinth: need some __rope__ (stack) and __piece of chalk__(visited set). Go along the __rightmost path without chalk marks__ (dfs ordering), and return when \n you reach a dead end.\n\n ### Previsit and connected components\n\n ```{python}\n #...\n cc=dict()\n def previsit(v,cc):\n    ccnum[v] = cc\n ```\n\n\n\n\n\n\n  \n   \n\n","n":0.092}}},{"i":371,"$":{"0":{"v":"Data Structures","n":0.707},"1":{"v":"# Arrays\n\n# Linked Lists\n\n# Stacks, queues, Bidirectional Queues\n\n# Trees\n\n# HashMaps\n\n# Disjoin Set/ Union-Find\n\n# Heaps and Priority Queues\n\n# Segment Trees\n\n# Graphs\n\n\n\n","n":0.224}}},{"i":372,"$":{"0":{"v":"Trie (Prefix Tree)","n":0.577},"1":{"v":"\n#TODO\n\n\n\nOperation | Complexity |\n---------|-------------\n lookup | O(n) in key length | \n insert | O(m) | \n\n\n","n":0.243}}},{"i":373,"$":{"0":{"v":"Sqrt Decomposition","n":0.707},"1":{"v":"\nif we split an array of size N into $~\\sqrt{N}$ \nof size $~\\sqrt{N}$, then we can do the sum in O(sqrt) time, and the updates as well.\nThat's the basic way, but we can do better.\nhow?\n\nfirst, extend the class of problems - first of all, interval updates are as fast as element updates.\n\n","n":0.139}}},{"i":374,"$":{"0":{"v":"Segment Tree","n":0.707},"1":{"v":"\n\n Also known as interval tree, make a data structure, holding the sum/min ect of the whole array, then as children divide in half, and write down that sum, etc... the tree has size O(n) (actually 2n), and then the function we call is recursive with asymptotic call time O(log n). \n\n[segment tree data structures](https://cp-algorithms.com/data_structures/segment_tree.html)","n":0.135}}},{"i":375,"$":{"0":{"v":"Quad Tree","n":0.707},"1":{"v":"\n\nUse a 'geographical quad-tree' to store all the locations of all the __things of interest__. The quad-tree is a tree where each node is a rectangle of size 2x2. Each node (except terminal ones) represents a location, and it's children split it into a southeast, northeast, northwest, and southwest quadrant.\n\n\nSo then a quad-tree is like a 2d version of the binary tree.\n\n# Parent Nodes links or Sibling Linked list connections\nSo we can more easily expand the search area: search up, then do DFS/BFS from there.\nWith the sibling linked list- also clear what to do.\n","n":0.103}}},{"i":376,"$":{"0":{"v":"Fenwick Tree","n":0.707},"1":{"v":"\n\n\nNotes from [here](https://cp-algorithms.com/data_structures/fenwick.html#overview) ^4t3mq78xcqdo\n\n# Fenwick Tree\nthis is an array of size N, which contains pre-aggregated information about another array of size N.\n\nCan use to answer queries like 'interval sum', 'interval max', other folds of associative functions across intervals.\n\n# Algorithm\n\n\n\nInput;\narray A,$len(A)=n$\nfunction $g(i)$.\nop (by default sum) - the binary group operation we're aggregating on\n\npre-compute the array $T(N)$.\nAlso, I think $T(i) = op(A[g(i),i])$ # this is probabLy not quite right though though.\nto get the interval sum for $0,i$:\n```\nS=0\nr=i\nwhile i>=0:\n  S+=A[i]\n  i= g(i-1)\n```\n    Update is similar,but in a waythe opposite (check out the algorithm)\n\n\n## Examples for $g(i)$\n\n### Identity\n1. $g(i)=i$ sum is slow, update is fast\n2. $g(i)=0 $ - this is prefix sum, sum is fast, update is slow \n3. construct g(i) as follows: \n take all the trailing 1's of g, and flip them.\n this gives both update and sum of $O(log(n))$ \n\n$g(j) = j&(j+1)$\n\n\ns\n\n \n\n\n\n","n":0.084}}},{"i":377,"$":{"0":{"v":"Bloom Filters","n":0.707},"1":{"v":"\n\nUsed to test for set membership.\nE.g. check if usernames have been used already. It's probabalistic, meaning that it'll return either __definitely not in set__ or __possibly in set__. There's therefore a __false positive rate__ $\\epsilon$ involved.\n\n# Algorithm:\nchoose a number $m$, which is the number of bits in the filter. Choose $k$ hash functions $h_1, h_2, ..., h_k: S->Z_m$, so they return numbers from $1 to  m$. Normally $k$ is small, depending on $\\epsilon$ and $m$ depends on $k$ and number of items to be added (how?idk). \n\n0. Initialize bit-array of size $m$ with 0s.\n1. __Operations__: __add(x)__,__contains(x)__.\n2. __add(x)__ calculates the $k$ hashes, and gets some numbers $h_1(x),...$. Set the bits $h_1(x),...$ to 1.\n3. __query(x)__ calculates the $k$ hashes, and gets some numbers $h_1(x),...$. Check if the bits $h_1(x),...$ are 1. If all are, return True (possibly in set). Else, return False (definitely not in set).\n\n\nCan choose $m$ and $k$ so that it's quite reliable, but still use it for non-critical applications.\nSee (wikipedia)[\"https://en.wikipedia.org/wiki/Bloom_filter\\#Probability_of_false_positives\"].\n\n\n### Use in Recommendation Systems ^recsys\n\nWe can use bloom filters to check if we have already presented a given product to a given user.\nWe can have a bloom filter for each user then and quickly filter if we should consider that for a given user.\n","n":0.07}}},{"i":378,"$":{"0":{"v":"Control in Networks","n":0.577},"1":{"v":"\n Compilation of old notes, taken in Evernote, concering [this book](https://books.google.at/books/about/Control_Techniques_for_Complex_Networks.html?id=0OdSX2BZ4WIC&redir_esc=y) by Sean Meyn.\n\n\n [[science.math.modelling.Operations Research]]\n [[science.math.modelling.Operations Research.Queuing Theory]]\n\n # Queuing Theory\n\n#evernote_link\n#queuing_theory\n The idea of queueing theory is to design a system that can be used to model the behavior of a queue.\n Controlling it means that under certain conditions, the queue size will be limited (I think).\n\n[Evernote Notes](https://www.evernote.com/client/web?referralSpecifier=mktgrepack_en_oo_web_hpg_V03&rememberMe=true&login=true#?b=79a34c9e-0c72-48bd-8a04-f229f21cc7b3&n=99b2089f-38b9-4c67-9052-82c52afe080c&)\n \n## Chapter 2 is talking about the \nsingle-server queue: M/M/1: memoryless in both arrivals and serving times,single server.\n\n\n\n\n\n\n \n\n","n":0.113}}},{"i":379,"$":{"0":{"v":"Combinatorial Optimization","n":0.707},"1":{"v":"## Books\n\n\n[Luca Trevisan](http://theory.stanford.edu/~trevisan/books/cs261.pdf)\n\n","n":0.577}}},{"i":380,"$":{"0":{"v":"Catalan Numbers","n":0.707},"1":{"v":"\nNumber of valid parentheses strings with n opening brackets and n closing brackets.\n# Recursive Expression\n\n# Analytical Solution\n\nIt's q beautiful bijection- \nWe know the number of catalan numbers are all monotonic paths in a grid (nxn), which don't cross the main diagonal.\nHence the 'bad paths' are the ones that do cross it.\nNow, how many bad paths are there?\nWell, all the bad paths do cross the main diagonal.\n\nFor each bad path, if we find the first point at which it does cross it, we can mark that\nThen we can **reflect the rest of the path** with respect of the main diagonal?\n\nThen this one will end at (n+1,n-1). \nWe can prove that this is in fact a bijection.\n\nThen the total number of catalan numbers is:\n$C(n,k) = \\binom{2n}{n}-\\binom{2n}{n-1}$\ns\n\n\n\n\n\n\n\n","n":0.09}}},{"i":381,"$":{"0":{"v":"algo","n":1}}},{"i":382,"$":{"0":{"v":"Memory Operation Costs","n":0.577},"1":{"v":"\n![Low-Level Memory Model ](https://cdn.hackernoon.com/hn-images/1*nT3RAGnOAWmKmvOBnizNtw.png)\n\n\n![this classic chart](http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/)\n\nMinimizing cache misses w/ numerical algorithms:\nrow-major and column-major optimization.\n\n# Heap, Stack, etc\n![Virtual Memory](https://bayanbox.ir/view/581244719208138556/virtual-memory.jpg)\n\n![Stacka and heap 2](https://camo.githubusercontent.com/ca96d70d09ce694363e44b93fd975bb3033898c1/687474703a2f2f7475746f7269616c732e6a656e6b6f762e636f6d2f696d616765732f6a6176612d636f6e63757272656e63792f6a6176612d6d656d6f72792d6d6f64656c2d352e706e67)\n\n\n\n# Type Stability\nWhy is the inference algorithm able to infer all of the types of g? It's because it knows the types coming out of f at compile time. Given an Int and a Float64, f will always output a Float64, and thus it can continue with inference knowing that c, d, and eventually the output is Float64. Thus in order for this to occur, we need that the type of the output on our function is directly inferred from the type of the input. This property is known as type-stability.\n\nAn example of breaking it is as follows:\n```{julia}\nfunction h(x,y)\n  out = x + y\n  rand() < 0.5 ? out : Float64(out)\nend\n```\n\nHere, on an integer input the output's type is randomly either Int or Float64, and thus the output is unknown:","n":0.082}}},{"i":383,"$":{"0":{"v":"GIS","n":1},"1":{"v":"\n\n# Mics\n\n\n\n[Visualization of Every ship in the sea](https://www.visualcapitalist.com/visualizing-every-ship-real-time/?fbclid=IwAR0siK8NBpaD0lG6hT7xCc1QIGtzaXot0w7bO64xs0ApWVTa8N7yPnP9ygs)\n\nWhat technology is used to trace the ship?\n\nThere is one system called AIS (Automatic Identification System), which requires tracked ships to be equipped by a device emitting signal with information about the ship, its size, destination, etc etc. The type of ships mandated to equip such devices is described in SOLAS (Safety Of Life At Sea) convention. Advanced systems, such as X-band marine radars, are required to track other targets not equipping AIS transmitters.\n\n\n","n":0.111}}},{"i":384,"$":{"0":{"v":"Cryptography","n":1},"1":{"v":"## Private-key schemes (one-time pad, AES, etc)\n\n#TODO\n\n## RSA Cryptography\n\nBob:\n\n* Pick at random 2 large ($n$-bit) primes\n* Pick $e$- relatively prime to $(p-1)(q-1)$. Public key is $(N,e)$, $N=pq$.\n* Secret key is $d=e^{-1}(mod (p-1)(q-1))$, computed via extended Euclid algorithm (!!!). This step he can do, cause he knows $p$ and $q$.\n\nAlice, sending message $x$ to bob:\n\n* Looks up public key $(N,e)$, and sends him $y=(x^e mod\\text{ }N)$\n* $(y^d mod \\text{ }N) = ((x^e)^d mod\\text{ } N) = (x^(e*d) \\text{ }mod N) = (x^1 \\text{ }modN) = x$  \nSo Bob computes $y^d mod\\text{ }N$, and gets back $x$.\n\nThe above relies on the fact that factoring $N=pq$ is hard, and thus an eavesdropper can't get $(p-1)(q-1)$ and thus the secret key $d$.","n":0.092}}},{"i":385,"$":{"0":{"v":"BioInformatics","n":1}}},{"i":386,"$":{"0":{"v":"Brilliant Course Notes","n":0.577},"1":{"v":"\n\n\n\nAdenine\n\nThymine - in RNA replaced by u-uracil\n\ncysteine\n\nGuanine\n\n----\n\n```mermaid\ngraph LR;\nDNA-.RNA polymerase?.-> RNA-.\"ribosomes(?)\".->proteins;\n```\n\n\nSize of folded DNA grows as $O(\\sqrt{N})$ of the length of the sequence. Random walk argument. If angles are random, that would be the expected length\n\n*Disulfide bridges* - bonds between 2 strands of DNA that are not complimentary.\n2 C AA would come together to staple the protein anf fold it together..\n\n\nNative folds- one configuration occurs very often. Stable configurations...\n\n\n\nThermodynamic hypothesis - not onlythe C proteins, but all AA's in the protein together determine it's native fold...\n\nWhy was alcohol interfering witht the thing finding it's correct fold,though??![](/assets/images/2022-07-30-21-23-18.png)\n\nLike heat, alcohol breaks protein fold...\n\n\nDifferent bonds hold different amount of energy, so counting bonds is not an acceptable way to estimate energy...\n\n\n\n# PCR, Genome reading, etc\n\n\n## PCR is doubleing a piDNA","n":0.089}}},{"i":387,"$":{"0":{"v":"Algorithms","n":1},"1":{"v":"\n## Leetcode Problems\n\n### [1. Two Sum](https://leetcode.com/problems/two-sum/)\n\n```mermaid\n\ngraph TD;\na-->b;\n\n```\n\n$x$\n$$\n\\begin{align}\n    x=2\n\\end{align}\n$$\n\n# [Max Distance to closest person](https://leetcode.com/problems/maximize-distance-to-closest-person/)\nSolved w/ O(n) space...\n#TODO\nCheck this solution:\n\n2: Two Pointer [Accepted]\nIntuition\n\nAs we iterate through seats, we'll update the closest person sitting to our left, and closest person sitting to our right.\n\nAlgorithm\n\nKeep track of prev, the filled seat at or to the left of i, and future, the filled seat at or to the right of i.\n\nThen at seat i, the closest person is min(i - prev, future - i), with one exception. i - prev should be considered infinite if there is no person to the left of seat i, and similarly future - i is infinite if there is no one to the right of seat i.\n\n# [Word Pattern](https://leetcode.com/problems/word-pattern/)\n\nVery stupid, solved w/ the 2 hash map approach\n\n# 783. Minimum Distance Between BST Nodes\n\nSolution- can walk over the tree, record thing \nin a array, sort it, return smallest diff.\nsimplest approach:\nwalk, push, heapsort while doing it, then walk.\nTAP_DANCE_ENABLE = yes\nQMK_SETTINGS = yes\nLTO_ENABLE = yes\n\nVIA_ENABLE = yes\nVIAL_ENABLE = yes\n\nin-order traversal, but the best one can be\n'rightmost' on one side,vs 'leftmost' on the other...\n\nSo it's wrong... \nlets'a analyse a solution.\nuse in-order traversal, and while doing it,\nkeep track of the current and next, \nand update the best distance accordingly:\n\n```python\nclass Solution:\n    def minDiffInBST(self, root: Optional[TreeNode]) -> int:\n        \n        self.cur = None \n        self.minimum = float('inf')\n        def inorder(node):\n            if node:\n                inorder(node.left)\n                if self.cur:\n                    self.minimum = min(self.minimum,node.val-self.cur.val)\n                self.cur = node\n                res.append(node.val)\n                inorder(node.right)\n        inorder(root)\n        return self.minimum\n```","n":0.065}}},{"i":388,"$":{"0":{"v":"Resources","n":1}}},{"i":389,"$":{"0":{"v":"Online","n":1},"1":{"v":"\n\n# Other Online Acccounts I use\n\n# OneNote\n\n# Google Docs\n\n# Dropbox\n\n# Evernote\n\n[Some PDE Stuff](https://www.evernote.com/shard/s101/nl/11122041/965ed68d-3b67-40a1-a8bb-4e9157b15bf4?title=SDE)\n\n#DifferentialEquations\n\n[[science.math.modelling.Differential Equations]]\n\n\n\n#archive\n[Combo Bets With Mathematica](https://drive.google.com/open?id=0B-C_0LZtyGcNOGhXQmt3blNTcVk&resourcekey=0-GpsyMO-2b3GhUfDuF-n0yQ&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n\n\n\n\n","n":0.243}}},{"i":390,"$":{"0":{"v":"Old Job Application Resources","n":0.5},"1":{"v":"[Austrian Consultancy](https://drive.google.com/open?id=1-YCS2g4PGODRUJ1RJsjqIvmnXeOd_xLs&authuser=stefanvpetrov%40gmail.com&usp=drive_fs)\n\n\n[Soccer Event Defintion data](https://drive.google.com/drive/folders/1CtPSA9LbGy97vQqguhl2VnVbumEx9vfz?usp=sharing).","n":0.447}}},{"i":391,"$":{"0":{"v":"Random","n":1},"1":{"v":"\n\nDesign Local Search\n \nTL;DR:\nThe interview itself was good IMO, but I had a lot more to show and the drawing part was poor,\nso I'm not sure how I feel. Also at one point I got a bit confused about a specific thing\n(building a global user-similarity model, rather than learning it's embedding within an already-made\nlocation model).\nI don't have a very certain opinion how it went (well or poorly). I couldn't say all of the things prepared, and drawings were bad, but they were also stopping me to focus on some specific things, and \nseemed engaged enough in the discussion. But idk.\n\n\n------------\n\nIt’s a variation of the ‘design local search’ question, so I first explained briefly the\nquadtree algorithm and then explained I'll accept the search as black BOX except one of the \n3 types of entities to consider will interact w/ the search engine. The search \n\n They wanted mostly to see how data would flow, but I don't think I drew that well. \n However, the conversation was going relatively smoothly and the discussion did not stall.\n However, I didn't manage to have a nice flow of the story end-to-end.\n\n\nThen I said we have 3 types of entities to consider that we want to make an embedding off:\n* Locations/ Places\n* Users\n* Queries (interacts w/ the search engine)\n\nMentioned content-based vs collaborative filtering and decided a nice 'primary' model would \nstart w/ content-based entity embedding, as 'entities' are kind of independent of the user.\n(same for queries)\n\nThen I mentioned probably we can do a 'secondary' model w/ user-location embedding, using \nregularization to 'shrink' towards the basic entity model.\n\nMentioned how the query model would work, there was a bit of forecasting and how recommendations\nwould depend on time-of-day, working times, holidays, event list at the venue etc. and\n\nOverall I focused a bit more on the featurization, as the questions were more in this direction;\nI spoke about sequence of models, cold starts (new locations/ new users).\n\nSpoke about how to incorporate user friend list in the models. \nMentioned fairness.\n\nHowever overall I didn't draw very much and maybe it was a bit scattered. The interviewer was\nstopping me here and there to focus on specific aspects on what data to use, how to combine the models, etc.\n\nAt one point I got a bit lost in the sens of building an overall user embedding model, rather than one that uses the __place__ embedding, and the interviewer pulled me back.\n\nI missed the 'number of visits time series' feature in the place embedding, but I think it's a good idea to include it. I put it in the whiteboard after the interview ended (with a note it's after). We touched on a very closely related point of how queries depend on time features.\n I spoke quite a bit about target, mentioned offline vs online measurements.\n\n They mentioned A/B testing and then asked what my KPI's would be.\n I discussed the different tiers of signals I would use (most important, but sparse one, would be \"conditional expectation of rating\", then prob to click, prob to visit w/o rating, probability \n they use the service every time they travel).\n  Mentioned Mean Absolute precision (mean of cummeans of 'relevances' of thigns in the presented list) as possible measure of the models.\n\n For negative signals I mentioned leaving bad rating, not clicking, searching right after that w/\n a different phrases, etc.\n\n Didn't speak enough about the 'model tiers' - candidate generation, scoring, and re-sccoring and ordering.  It felt a bit unnatural in the flow, as I though the search would kind of take care of that in the sense of returning relatively few results. \n The use case stated was posed as 'I'm on the train, wanna see where I can go during my business trip', so it was implied the num results wouldn't be in the billions, thus reducing need for so many filtering layers. \n\n This might not be true, but it wasn't immediately obvious for me, so I didn't talk about it.\n\n\n\n\n\nDesign scoreboard for a game\nEvery 50 ms, show:\n1. your current position, 10 players above and bellow you\n2. Ranking of your friendlist \n3. Top 10 board\n\ntl;dr \nI hadn't seen this one. Issue is scoreboard has 10^8 users and needs to be re-calculated 20 times a second. we have about 200 games/second.\nI proposed when someone plays a game, we figure out their new place in the scoreboard (O(logn)), lock the\npositions between current and new position, make the update.\nWe keep track of currently locked positions w/ some kind of interval tree and if we can't make an update right now, as the interval is locked, we go into a queue for this specific interval.\nI think the interval tree locking business is also O(logn) and it's probably workable under normal operations. We discussed this approach quite a bit and the guy was quite skeptical and asking lots of questions. Also he had VERY difficult accent (for me) so we lost maybe 2-3 minutes out of the interview repeating things and stuff.\n\n Essentially we got stuck on the distributed update/sorting approach for long time and didn't have time to do much else.\n\n He asked me how I would make the scoreboard efficient for reading as well;\n  I did mention how to partition the scoreboard into intervals (which lead me to realize bucketsort is way more elegant). So I mentioned that in the end of the interview.\n\nThere were a couple of more requirements we didn't end up doing, like the friend list (a variation of the hybrid fan-out and fan-in approach w/ the celebrity problem maybe?).\n\nI put those into an e-mail to the reqruiter, as I was quite mad at not seing the bucket sort solution faster, as the remaining part of the design flows very naturally from there and 15 minutes after the interview I had a paragraph with the outline.  \n Reqruiter said maybe he'll show it during the debrief if needed.\n\n\nI didn't get to the optimal design, but mentioned it in the end for 10 seconds while we were doing the chit-chat, as I realized it. So ,I think optimal design is to have the global leaderboard bucket-ized as rankings, when you play a game an update your rating, you write there, if needed move in another bucket, then every 0.05 seconds you re-sort the buckets (can decide how to re-sort based on number of new ops in bucket, i.e. if very few operations operations do insertion sort).\n\n\nBehavioral\n\nI think it went fine, I said my stories and she was like 'fine'. Asked maybe 4-5 questions, only one\nnot on the story list was somethign like 'what kind of people don't you work well with'. I said ones that take credit for other people's work, overpromise stuff they're not licensed to, and ones who don't have the customer's best interests in mind. ","n":0.03}}},{"i":392,"$":{"0":{"v":"Math","n":1}}},{"i":393,"$":{"0":{"v":"Theory","n":1}}},{"i":394,"$":{"0":{"v":"Information Theory","n":0.707},"1":{"v":"# Entropy\n\n$$\n\\Sigma_{e\\in\\mathcal{S}} - p_e log(p_e)\n\n$$\n\n# Mutual Information\n\n\n# KL Divergence\n\n\n# Cross- Entropy\n[[science.probability.Distributions.bernoulli]]\n\n\n# Huffman Coding\n[[science.CS.algos.Greedy Algorithms]]\n\n\n\n","n":0.267}}},{"i":395,"$":{"0":{"v":"Information (statistics)","n":0.707},"1":{"v":"\nIf we have observed the i.i.d. sequence $X_1, X_2, \\ldots, X_n$ with $n$ observations,  $L(\\theta) = f(x;\\theta)$ is the corresponding [[science.stats.Likelyhood Function]] and $l(\\theta)$ is the log-likelihood, then the __observed information__ is:\n\n $J(\\theta) = - \\frac{d^2l(\\theta)}{d\\theta^2}$\n\nSo it's the negative hessian of the log-likelihood function. \nIt's important, as it's intimitely related to asymptotic distribution of parameters.\n\n[[science.stats.Maximum Likelyhood Estimator (MLE)]]\n\n\nThe __expected__ or __Fisher__ information is instead:\n    \n$I(\\theta) = - E_{X}[\\frac{d^2l(\\theta)}{d\\theta^2}]$\n\nWhere the expectation is taken over the data distribution $X$.\n\n\n\n\n","n":0.114}}},{"i":396,"$":{"0":{"v":"Study Tips","n":0.707},"1":{"v":"\n# How to write a proof-paper","n":0.408}}},{"i":397,"$":{"0":{"v":"Optimization","n":1}}},{"i":398,"$":{"0":{"v":"Lagrangian","n":1}}},{"i":399,"$":{"0":{"v":"Learning","n":1},"1":{"v":"## How to Read a Paper\n3 pass approach:\n1. Skim\n2. Read Carefully\n3. Re-implement (effectively)\n\n[Evernote Link](https://www.evernote.com/shard/s101/nl/11122041/e863c6af-c733-42b5-a676-b45d1edeb724?title=How%20to%20read%20a%20paper)\n\n\n#","n":0.267}}},{"i":400,"$":{"0":{"v":"Free Recall","n":0.707},"1":{"v":"# how to learn more from audiobooks and podcasts\n1. Before listening, write down what you already know about the topic (priming, get into the mood).\n2. split into chunks if quite long.\n3. do free recall, fill gaps (by maybe listening again), write down open questions.\n4. listen to the next chunk\n. after listening to the whole thing, do free recall again.\n6. try to find something to listen to from a different perscpective, maybe a different source.\n\nexample - history of vikings, after that maybe listen to something about france in that age, something about england, then you get a comprehensve picture and make the 'relational diagram' hairier/denser.","n":0.098}}},{"i":401,"$":{"0":{"v":"elasticsearchInDendron","n":1},"1":{"v":"[Notes](https://wiki.dendron.so/notes/401c5889-20ae-4b3a-8468-269def4b4865/#analyze-notes-using-elasticsearch)\n","n":1}}},{"i":402,"$":{"0":{"v":"Briefing","n":1},"1":{"v":"\n\n# Briefing\n\n\n# Scheduling\nSchedule bigger blocks, 'until done' or until some milestone is reached. Overestimate time needed. Overestimation is much\nsmaller problem than underestimation.\nunderpromise and overdeliver...\n\n## Sleep\n8-9 hours a night is crucial, otherwise you're poking a whole in the middle of the bucket you're filling with water.\nyou can't consolidate memories.\n\n## Bloom's Hierarchy of competence,\nunconcious Incompetence\nconcious incompetence, \nconcious competence, lots of effort\nunconcious competence\n\n\n## Colb Experimental Learning Cycle\n```mermaid\nexperience\nreflection/obsercation\nabstraction\nexperimentation\n```\n\nNeed to follow logically from each other...\n\n## cognitive load\n\nnegative corelation between preceived difficulty and perceived metacognitice self9(?)- assessment...\nmodelated by goal-setting \nExample - if you choose words to study and you just go by the amount, you'll\n'feel better' and assess the easier things as having better outcomes.\nIf you instead prepare your cyllabus to be like in the exam and you study the words that would be on the exam, you won't \nperceive the more difficult words with being associated  wiTh lower self-assessment score (???)\nsometing like tis. Desired difficultY...\n\n\n## Tips and tricks-\nonly 10%.\n\n\n## Pitfalls\n\n### Death spirals- when you need to invest more and more time to uphold certain learning paradigm...\n\n## Bandwagon Effect\nDo it cause others are doing it.\n\n## Inappropriate use of a technique\ne.g. flashcards are not so good for abstrac concpets or for 'what if' questions...\n\n## Pre-study\n\nVery very important...\npre-study from textbook is efficient\n\n## Revision strategy\na week and then a month after learning in-depth (??)\nSee the schedule...\n\n## Focus\n\nRemove distractions, rather than 'trying harder' or otherwise relying on willpower.\n\n## Techniques in school\n\n## Asking questions, trying to play with the concet in your mind, having lots of questions and trying to answer.\n\n\n\n## Collecting and processing...\n\nClearly separate times when you collect information and when you process it. \nCollecting information coult be [[Knowledge Management]] and processing is the learning part.\n\n# Focus \n\n\n\n","n":0.06}}},{"i":403,"$":{"0":{"v":"Understanable Input Approach (Language Learning)","n":0.447},"1":{"v":"\n[Classical Krashen Lecture](https://www.youtube.com/watch?time_continue=2&v=NiTsduRreug&feature=emb_logo)\n[Authenatic German Learning](https://www.authenticgermanlearning.com/german-podcast/)\n\n\n[Some other article](https://www.leonardoenglish.com/blog/comprehensible-input)","n":0.378}}},{"i":404,"$":{"0":{"v":"Speed Reading","n":0.707},"1":{"v":"\n\nMakes some things faster, \nSome of the techniques (maybe a majority) works by turning off subvocalization,\n\nbut for learning dense material you **want to** sub-vocalize to understand better, think about it etc.\n\n","n":0.18}}},{"i":405,"$":{"0":{"v":"Spaced Repetition","n":0.707},"1":{"v":"\n[Anki](https://ankiweb.net/)\n","n":1}}},{"i":406,"$":{"0":{"v":"Priming","n":1},"1":{"v":"\nWays to read a paper first pass\n\nVideo by sung- build skeleton first;\netc.\nSo go quickly trough the table of contents and try to gleam what the topic is and what are it's subtopics.\n\nUseful for math ? Maybe not\n\n**Main headings, start, end of paragraph, figures.**\n\nHow many concepts, what are the concepts, how dense.\n\n\nRead ToC first.\n\n\n**Try to ask deep questions as you go, even if you don't know the wods. Try to guess possible answers/ideas.**\n\n\nFocus on the conceptual understanding, ignoring the stuff that makes no sense.\n\nGo back and forth between pages.\n\nAs long as you feel like you're learning, should feel pretty happy with that by itself.\n\n\nGo trough the pages briefly to finish the priming...\n\nDoesn't really work with math (?)\n\n","n":0.093}}},{"i":407,"$":{"0":{"v":"Notetaking apps","n":0.707},"1":{"v":"\n# Obsidian\n# Google Keep\n# Roam\n# Dendron\n# OneNote\n# Notion\n# Word\n\n# Recommended for handtaken notes ^hnd\n\n## Leonardo\n\n## Concepts (iPad)\n\n## Squid (Android)","n":0.229}}},{"i":408,"$":{"0":{"v":"Misinterpreted Effort Hypothesis","n":0.577},"1":{"v":"\n[Some article about it](https://www.msrlab.pitt.edu/wp-content/uploads/2021/08/Kirk-Johnson-et-al-2019_Perceiving-effort-as-poor-learning.pdf)\n\n\nPeople use strategies that work less well during learning. \nReason is if they feel greater effort,they attribute this to sucking at the task. Thus they feel like\nthe strategy is bad.\n\nBut this interpretation could be wrong, as the greater effort could be related to growth.\n\nSimilar to [[Health And Personal Development.Progressive Overload]]. What's the difference, since everyone likes progressive overload? **Measurement is noisy and not instant, maybe?**\n\nSo if it feels hard, people think they suck at it. If it feels easy, they think they are good at it. But this is clearly wrong\n\n\nEffort avoidance hypothesis.\n\n[[Philosophy.Cognitive Biases]]\n\n\n```\nAcross these first three studies, a consistent pattern emerged: The more learners perceived a study strategy as mentally effortful,\nthe less they judged it to be effective for learning; this, in turn, predicted their choice of study strategies such that the more effective\nthat participants thought a strategy was for learning, the more likely they were to choose it for future study. That is, we observed an\nindirect effect of perceived effort on study strategy choices, mediated by perceived learning. This pattern held across differences in\nstudy strategies (the choice between blocked vs. interleaved schedules and the choice between restudy vs. retrieval practice), to-belearned materials (learning to classify category exemplars and learning of science texts), subject populations (students and the\ngeneral adult population), and locations (the Web or a laboratory). This indirect effect also always held across both participants’\nmeasures of immediate perceptions of each strategy and retrospective comparisons of the two strategies. It also held even when\ncontrolling for participants’ objective performance during study.\n```\n\n\n![](/assets/images/2022-08-06-12-52-28.png)\n\n\nSo basically it's supported, though in the previous paragraph it feels like it isn't...\n\nProbably how to think about how the analysis works exactly...s","n":0.06}}},{"i":409,"$":{"0":{"v":"Mindmaps","n":1},"1":{"v":"\n\nIt's dendron:)\n\n# Non-linearity in storytelling ^nonlinear ","n":0.408}}},{"i":410,"$":{"0":{"v":"Learning and Practicing Mathematics","n":0.5},"1":{"v":"\n\n[Learning math](https://www.maa.org/external_archive/devlin/devlin_03_06.html)\n\nSymbolic roles: \nnot the goal\n\n\nConceptual understanding comes **after** a considerable amout of **procedurial practice**.\n\n\nSo this is similar to the [[learning.Understanable Input Approach (Language Learning)]] to language learning, probably (?)\n\nLoosely related also to the algorithmic questions in interviews...\n\nCheck if the practice is there first. Hard to fake...\n\n\nThis guy thinks practice comes before conceptual understanding.\n\nKind of opposite to [[learning.Bloom's Taxonomy]].\n\nIdea here is that the brain is wired to do procedures, and not for abstract thoughts...\n\n\n\n\nLife in today's society requires that we acquire many skills without associated understanding - driving a car, operating a computer, using a VCR, etc. Becoming a better driver, computer user, etc. often requires understanding the technology (and perhaps also the science behind it). But from society's perspective (and in many cases the perspective of the individual), the most important thing is the **initial mastery of use**.","n":0.085}}},{"i":411,"$":{"0":{"v":"Learing Techniques","n":0.707},"1":{"v":"\n\n# Some Notes from Justin Sung\n\n\nSome notes from [this reddit](https://www.reddit.com/r/GetStudying/comments/qggnu5/icanstudy_by_dr_justin_sung/)\n\nCognitive change/transformation.\n\n\n\n[Study Live stream](https://www.youtube.com/watch?v=5JJnBuTQahs&ab_channel=JustinSung)\n\n\n\n\nTimestamps for when he speaks:\n\n* 00:30 - Have your study stuff with you\n\n **Optimize Environment, make it you don't get up. All resources in front.**\n Foods for study- almonds/fruit (no sugar crash).\n Lon-linear notes [[learning.Mindmaps#^nonlinear]]\n* 02:13 - Preparing is a legit step + apps he uses for notetaking\n!![[learning.Notetaking apps#^hnd]]\n* 05:13 - Recommended snacks + explanation on notetaking\n\nMost of study happens inside the head.\nSpend as little time of notetaking as possible.\nOnce done the learning, document that.\n\n**Thinking a lot, playing with ideas**, less time spent on notetaking (?).\n\nAlways handwritten, always non-written if possible (?).\n\n\n\n\n* 06:23 - More explanation on notetaking and learning\n* 07:52 - Handwritten notes vs typed notes\n* 09:41 - Priming Step\n[[learning.Priming]]\n* 12:10 - Sensory Distraction or Sensory Deprivation \nKeep your focus on reading, maybe rythim. Play pen/etc. \n\n* 13:25 - What he is reading atm for priming\nWhen you read a sentence during priming, even if you don't know the words, play with it, think what it could mean,etc.\n* 14:03 - Learning in your head is slow\n* 16:52 - Finished reading contents + how to avoid passive reading + concentration tip + explanation on what he's thinking\n**Be clear on why you're reading something. Both in terms of the inidial goal, and where he's at at a given timepoint**.\n* 19:10 - Explanation on reading the preface (speed reading)\n**Preface is skimmed.** Skim trough about what that's talking about... It's okay to skip if you don't need to learn it ...\n* 21:21 - Quick note on the mental model\nMental model - no words, but images. Turn words into images. Re-express it as a mental image... Image is easier to hold than 10 different words across a flowchart.\n* 22:53 - How he developed this method\n**1000s of hours of reading research, 10000s of hours of self-experimentation**.\n\n* 23:34 - Drawing out what he is imagining\nSo the point is just to try to right away connect stuff, enrich the image and as you go correct it if needed.\n* 25:30 - Embracing the confusion\n\n**Go back and forth with things.**\n[[Health And Personal Development.Progressive Overload]]\n\n\nTry to keep as many things in your mind as long as comfortable, then keep in mind a bit longer [[Health And Personal Development.Progressive Overload]].\n* 28:37 - Page 1 + Priming + If I don't remember something, how do I overcome it\nSo it's quite different than the second brain stuff in many ways...\n* 31:21 - Priming through the pages\nhe thinks that his initial framework was accurate. Having a visual aid might be good.\n* 33:57 - Finished priming\n* 35:04 - Do you listen to study music?\nmaybe/probably not...\n* 35:55 - Going through from the beginning being curious and inquisitive (why am I reading this, for what purpose, how can I apply it and how can I simplify it) - Blooms Taxonomy\n* 37:42 - Are you reading backwards?\n* 38:40 - A relaxing process; a well-oiled habit\nGo back and forth with the things you're reading. Be quite active with it in your mind. If using kindle or something,\nfigure out how to quickly go back and forth w/ the reading...\n* 41:00 - How can I apply it?\n**Always think \"how would I apply this\"?  Why is this useful to create other stuff...**\n* 42:40 - Loosing any detail when skimming\nLosing detail is fine. Don't care.\n* 46:06 - Annotating while reading - is it valid?\n* 47:32 - Is this the only study technique that you use?\n* 49:24 - Bullet Points - Memorizing specifics\n* 53:01 - Change on his mental model (Hypercorrection effect)\n* 54:11 - Read his mind + course ad + guarantee\n* 59:04 - Threshhold concept breached - \"Lightbulb moment\"\n* 1:04:05 - The best time to take breaks\n* 1:05:29 - He's confused - Apply+Simplify\n* 1:06:09 - Trying to make an analogy to simplify\n* 1:10:44 - Creating focus\n* 1:15:15 - Remembers another framework thus speeding up the process of learning\n* 1:16:53 - Skips to another part of the book to learn more about a topic\n* 1:18:16 - Back to where he was\n* 1:23:48 - Study sessions vary\n* 1:26:42 - Exponential increase + special information + good book\n* 1:30:35 - Hour and a half of stream (40min study - page 33)\n* 1:31:04 - Notes after priming? prioritize learning istead of note taking + showing mindmap\n* 1:35:40 - Reading details and it makes sense because he knows the logic behind all of it\n* 1:38:55 - Satisfaction of learning\n* 1:44:54 - Quick technique - analogy and representing on the mindmap\n* 1:46:42 - Are there any more websites to find out more about learning? + thoughts on study tips and non scientifical sources\n* 1:49:13 - Thomas Frank\n1:53:41 - 50 pages + What do you mean by studying fast? + What is a successful study session? + ending\n\n\n\n# Write Down Challenging Questions for yourself to Answer \n\nIn a bit of time, either as a prompt or work towards it. Either way, it's a problem solving thing.\n\n\n# Learn on hour, spend 5 minutes writing notes\n\nSounds difficult...\n\nrelies on you being able to remember quite a bit...\n\n\n# Live session with Justing Sung\n\nTalkign about Interleaveing...\n\nDeclarative vs Procedural...\n\nSpacing and Interleaving effects.\nResearch on Interleaving is quite large.\n\n\n## Interleaving - Varying up your practice, looking at somethign from multiple angles...\n\nOrders of learning:\n\n1. repeat\n2. understand and can apply basics to familiar concept, and remember.\nThis is kind of isolated...\n3. Can Apply\n4. Can apply to varying contexts, how it relates to other things\n...\n7. Can produce new things.\n\n-----\n\n\nHigher order learning - learn how to use the concept in a highly creative concept...\n\n\nInterleaving 'Table'\n\nBest things to do are: \n\nfor declarative:\n\nBrain dump, generated isolated questions, isolated teaching, , teachingw/ relations, chunkmaps, peer/groupd discussion.\n\n**So basically studying with people is the best...***\n\n\n# Good Techniques\n\n3C- cover-copy, check - ow level\n\nPractice questions- extended method. - solve a problem sheet, then for everything you're unsure, re-solve while looking at the material. Then compare answers vs original answers and book answers...\n\nREBIM -(Repetitive execution Beyond Initial Mastery).\n\n\nBrain Dump (MindMap) - just make a mind map/excalidraw of everything you know...\n\nGenerated Questions (Isolated, Broad).\n\nTeaching (Isolated, simple relational)...\n\n## Feynman Technique\n\nThere are four key steps to the Feynman Technique:\n\n\n1. Choose a concept you want to learn about\n2. Explain it to a 12 year old\n3. Reflect, Refine, and Simplify\n4. Organize and Review\n\n\n\nCreating an answer sheet by itself can consolidate learning...\n\nRetrieved execution (applied).\n\n\n\nChallenges with the topic...\n\nLater mastery levels basically is 'How to be a good researcher...'a\n\n\n\nSolution - \nwhile reading some tutorials, add some variation, but on the variables of interest.\n\nSo for example, if there is \n\n\n\n\n\n\n","n":0.031}}},{"i":412,"$":{"0":{"v":"Inquiry Based Learning","n":0.577}}},{"i":413,"$":{"0":{"v":"Hierarchy Of Competence","n":0.577},"1":{"v":"\n\n# Hierarchy Of Competence\n\n## Unconscious Incompetence\nWrong Intuition- don't know what you don't know\n\n## Conscious Incompetence\n\nYou're doing some wrong analysis and can understand why you're wrong.\n\n## Conscious Competence\n\nCan do the right analysis\n\n## Unconscious Competence\n\nRight intuition...\n\n\n```mermaid\ngraph LR\n    A[Concrete Experience] --diverging--> B[Reflective Observation]\n    B[Reflective Observation] --accomodating--> C[Abstract Conceptualization]\n    C[Abstract Conceptualization] --Assimilating--> D[Active Experimentation]\n    D[Abstract Experimentation] --converging--> A[Abstract Experimentation]\n```","n":0.135}}},{"i":414,"$":{"0":{"v":"GrowthPhas","n":1},"1":{"v":"\n\n# Right and Wrong way to practice\n\n\n# Kolb's  experiential learning cycle\n\n## Concrete Experience\n\nThis is \n\n## Reflective Observation\n\n## Abstract Conceptualization\n\n## Active Experimentation","n":0.218}}},{"i":415,"$":{"0":{"v":"Course Notes","n":0.707},"1":{"v":"\n# Rapid Fire Techniques\n\n# Meta-plan\n## Watch video and take notes\n### Burn Bridges\nNo brides to burn here\n### Schedule \ndo it now\n### Environment\nVs code and dendron are open, ready to open up excalidraw\n### Distraction Cheat Sheet\n\nHave it\n\n\n# Catalyst Session Notes\n\n## Community Rules\n[How to ask good questions](https://stackoverflow.com/help/how-to-ask)\n\n* Show your work\n* minimally reproducible example (of what didn't work)\n* Show what didn't work, journey trough \n* Many ways to be wrong.\n* So narrow down the problem as much as you can so people can help you\n\n\nCause there are many ways for something not to work, try stuff out...\n\n\n[[Health And Personal Development.Progressive Overload]]\n\n\n\n## [[Health And Personal Development.Procrastination]]\n\n\n\n## This course is not a spectator sport\n\n\n[Mathematics is not a Spectator sport](https://www.maa.org/press/maa-reviews/mathematics-is-not-a-spectator-sport)\nYou have to cosntantly practice it...\n\nHave to practice.\n\n\n\n## Skill Acquisition is more complicated than just theory, practice is important too\n\n\n## Claiming they are ahead of research\n\n\n\n\n#TODO Why research trickles down slowly into practice\n\nCommon sharlatan claim?\n\nSpecific claims about learning- learner focused, rather than policy-focused.\n \n Research is policy focused (focused on what teachers should do...)\n\n Very doubious claims on this...\n\n\n### Research practice gap\n![](/assets/images/2022-08-06-11-48-23.png)\n\n[ACM article](https://interactions.acm.org/archive/view/july-august-2010/the-research-practice-gap1)\n#TODO check if this is real or not...s\n\nThe picture has soem problems:\n1. What if the problem can be identified from first principles and on small scale studies?\n## Deviation from the couRse\nThey claim it's super optimized and gaps will appear and bottleneck you later.\n\n### Selective learning\n### Lack of practice (spectator sport)\n### Rushing\n\n\n\n## Encoding vs PKM\n\nThe course focuses on learning how to learn and encode/understand things better, rahter than  \\\\\n#TODO think about the difference a bit, even though there are huge overlaps I would say...\n\n\ns\n\n\n\n## Funcamentals vs Growth Stages\n\nFirst it'sthe high yield stage, where we reap rewards from the fundamentals...\n\n### How do you know you've mastered a technique?\n\nBe able to apply it and feel it's kind of working. E.g. not looking at notes way too much...\n\n70-80% only checking notes sometimes.\n\nA bit more consolidations/practice.\n\nAlmost second nature to it.\n\n[[Health And Personal Development.Unconcious Competence]]\n\n\n I **Higher Ground Series** is about modifying fundamentals for special contexts, like professional or ADHD, etc.\n\n\n## The learning is path, dependent...\n\n![](/assets/images/2022-08-06-12-13-53.png)\nso small perturbations/errors propagate...\n**So they don't recommend deviating from the course at all, cause they think it's optimized and the path dependency is strong.**\n\n\n## How to take notes, when to take the notes, etc...s\n\n\n### Peer feedback on Discord is nice already\n\n### Office hours- group call - doctor consultation. Basically 1-on-1 with the instructor.\n\n### Spot the issues\nLibrary of worked examples\n\n### Live clinics\n\n2 hour group call..\n\n\n## With the fundamentals- experiment\n\nIf you feel confused whenapplying some of the techniques.\n\nMisinterpreted Effort Hypothesis\n[[Health And Personal Development.Progressive Overload]]\n[[learning.Misinterpreted Effort Hypothesis]]\n\n\nFailure is Success...\n\n\nTry many things...\n\n\n\n## Mind Maps and Spatial organization is more important\n\nOne needs Very big mind maps, so then you need infinite canvas.\n\nMore processing of the information is better/more important...s\n\nDigital mind-mapping is not as good, as you're consitriced by the options of thr pgoram.\nbut much more legible, otherwise I'm consitricted in the retrieval by mydexterity.\n\nAlso much harder to edit/ correct later.\n\nSo excalidraw is nice...s\n\n\n## What do you do when you have holidays so techniques don't get too rusty...\n\n\n\n### Differentiate between actual cognitive Load and one sucking/catastrophising\n\n\nHow do you know if it's cognitive load or if it's just too much.\nExpert recycle. Try to do some measurements, gather feedback, etc.\ns\n## Pure Math\nthere is a help article...\nprocedural plus declarative knowledge components...\n\n\n\n# Rapid Fire Modules Summary\n\n### Urgency Trapping and Eisenhower Matrix\n\nHave to make time for the important, but not urgent stuff.\n\nHuman biological tendencies are to do the urgent stuff, as it's difficult to find joules...\n\nPrioritize important stuff, instead of urgent.\n\n\n\n### Theory VS Practice Times\n\nIt should be a ratio of 1:5 for simpler things, and 1:30-1:40 for more complex topics...\n\nSo it's very very important to practice skills.\n\n**Doing too much theory without practice can lead to cognitive overload and be worse than just doing nothing**\n\n\nSummary:\n\nProblem: \n\nWe have day to day urges and distractions (like hw) that don’t translate to long term successes like doing well on tests.\n\nCause: \n\nWe don’t prioritize more “important” tasks like proper studying over urgent tasks like “hw” or maybe even personal urges like loneliness or addiction.\n\n\nSolution: \n\nWe must recognize the tasks on the Eisenhower Matrix and reorganize our time to include the theory:practice ratio. We must organize by importance instead of urgency.\n\n\n\n\n\n\n\n\n","n":0.038}}},{"i":416,"$":{"0":{"v":"Book Summari Websites","n":0.577},"1":{"v":"\n\n# [Reddit Thread](https://www.reddit.com/r/books/comments/obwqs8/i_started_comparing_book_summary_websites_heres/)\n\n\n* Nat Eliason https://www.nateliason.com/ - good high-level thoughts\n\n* Four Minute Books https://fourminutebooks.com/\n Many summaries, but short (<=1200 words). Lots of ideas are out\n They don’t actually read the books they write summaries for. They read the summaries on Blinkist and then write summaries of summaries.\n\n* Blinkist https://www.blinkist.com/ big and paid\n* Shortform paid, but very high quality\n* Growthabit https://growthabit.com/\nThey have a detailed structure of every summary\n* Derek Sivers https://sive.rs/\nOne-centencs summary of books\n\n* The Ripening http://www.theripening.com/\n\n* Graham Mann https://www.grahammann.net/\n\nPros:\n* Alex J. Hughes https://www.alexjhughes.com/\n\n* Unearned Wisdom https://unearnedwisdom.com/\n\n","n":0.108}}},{"i":417,"$":{"0":{"v":"Bloom's Taxonomy","n":0.707},"1":{"v":"\n\n\nWhere are we:\n\n```mermaid\ngraph TD;\nR[Remember];\nU[Understand];\nA[Apply];\nAn[\"Analyse(graw connections between ideas)\"];\nE[\"Evaluate (also trade-offs, etc)\"];\nC[\"Create Produce new or original work\"];\n\nR-->U-->A-->An-->E-->C;\n\n```","n":0.258}}},{"i":418,"$":{"0":{"v":"Finance","n":1}}},{"i":419,"$":{"0":{"v":"Various","n":1}}},{"i":420,"$":{"0":{"v":"Resilience to Contagion","n":0.577},"1":{"v":"\n[Evernote Note Link](https://www.evernote.com/shard/s101/nl/11122041/771e97cd-88e2-4c8e-9f9e-5d8f2d20612a?title=Resilience%20to%20contagion%20in%20financial%20networks)\n\n\n# Futures Risk Premium Vs Maturity\n[Some Old Project about nord pools I did](https://drive.google.com/open?id=0B-C_0LZtyGcNV2dIYlBqS2xtbUk&resourcekey=0-KVGK_LR4zKNx4NiQ1jUHvg&authuser=stefanvpetrov%40gmail.com&usp=drive_fs).\n\n\n","n":0.258}}},{"i":421,"$":{"0":{"v":"Engineering","n":1}}},{"i":422,"$":{"0":{"v":"Making","n":1}}},{"i":423,"$":{"0":{"v":"3dprinting","n":1},"1":{"v":"\n\n# fdm\n\n\nextrusion, like a hot glue gun, layer by layer, like a building, needs supports\n\n\n## Slicer\nturns a 3d model file into executable instructions for the printer, mostly gcode, most of which containst instructions for moving the print head, extruding plastic, and turning the bed on and off.\n\n\n## Materials\n\n### PLA\npoLyactyc acid\n180-220C printing temp\ndoestn smell too bad\ndoesnt require very hot bed\n\n### ABS\nstinier, more toxic, requires a heated bed, higher printin temperature, main advantage is temperature resistance, and i think uv resistance, also some chemical resistance\n\n\n\n\n## Printers and buying recommendations\nlook at these, sorted by budget and types:\n\nbambulab p1s, qidi 3x pro, creality k1c\n\npcoming core xy from twotrees,\nhttps://www.twotrees3dofficial.com/products/sk1-corexy-3d-printer-twotrees?variant=44354496135388\npromises more than the other \n\n\nsovol 6 or 7, or anycubic cobra 2 pro or max\n\n\n\n### core xy\n\nthere are mainly s types of constructions i know of, which are about what parts move how and how the construction is done. atm corexy is the hotness, as there the bed moves only up and down, which makes you not have to move the bed, which is fast. \nthere is delta, which i dont know much about, but the bed there is a circle, not rectangle\n\n\n\n### bambulab p1s with ams\n1000ish , ams is the multicolor/material stuff, very usefu especially for support removal as discussed\nbambulab was the big winner in the end of 2022, many companies are cloning their systems and trying to beat them on speed, like\nenclosed, building volume 256^3. without the ams same price as the bellow ones.\n\nvery integrated ecosystem, which is nice to begin with but many downsides, mods are not as common...\n\n## Creality k1c or qidi 3x pro\n\ni think 600 or 700, a bit bigger and better specs, and more established companies, but no working multimaterial system yet.   \n\nabout hte ams, it adds a lot of convenience in general, as it can serve as dry box, it can help with the supports as mentioned, and it can also be used to just not swap rolls all the time...\n\n\n# for resin, google best resin printers, and watch thhese 2\nhttps://www.youtube.com/watch?v=UU6tWhV010\n\nhttps://www.youtube.com/watch?v=sen7PO6HSoU\n","n":0.055}}},{"i":424,"$":{"0":{"v":"Technologies","n":1}}},{"i":425,"$":{"0":{"v":"Web Techologies","n":0.707}}},{"i":426,"$":{"0":{"v":"React","n":1},"1":{"v":"\n# Notes\n\n\n## Index.html is non-descriptive\nSort of a template.\n\n\n```\n <link rel=\"apple-touch-icon\" href=\"%PUBLIC_URL%/logo192.png\" /> \n      <link rel=\"manifest\" href=\"%PUBLIC_URL%/manifest.json\" /> \n\n```\n\n```\n<body>\n<div id=\"root>\n<!-- index.js will dynamically write here -->\n\n</div>\n\n</body>\n\n```\n\n\n## Index.js \n The application will dynamically re-write the empty div.\n\n\n## The true 'entry point' is App.js\n\n\n\n# React Components\n\nThey inherit the __Component__ class.\n\nThey can be class or funciton based, etc.\n\nThen have a __render__ method that interprets them to an actual DOM element.\n\n\n\n\n\n\n\n","n":0.123}}},{"i":427,"$":{"0":{"v":"Hugo","n":1}}},{"i":428,"$":{"0":{"v":"Educative Course","n":0.707},"1":{"v":"\nUsing [[science.cs.languages.python.libraries.Flask]], [[engineering.system_design.SQL Databases#^postgres]] and [[engineering.technologies.Web Techologies.React]].\n\n# Synchronous vs. Asynchronous Communication\n\n\nSynchronous| Asyncronous \n---------|----------\n Phone Call | Email\n\n\n# Single vs Multipage applications\n\n## **Multi-page applications** : server sends a new page every time the user does something\n## **Single-page applications**: servers sends only the relevant data, client updates itself\n\n# RESTful API\n\n\nServer doesn't know the state, but client can keep track of the state as much as you like.\n\nI.e. **stateless** is like [[science.cs.languages.Theory.Functional Programming]], rather than OOP (at least from the server's perspective).\n\n\n\n\n\n\n\n\n\n\n\n\n","n":0.113}}},{"i":429,"$":{"0":{"v":"Tooling","n":1},"1":{"v":"\n#TODO \n\nSetup colab to work with local VSCode.\n\nhttps://colab.research.google.com/drive/1kmZcXYL0lxt5R3rSBRSd9zZC_HsGrs2p#scrollTo=ihdRjHetUxmR\n\n[[engineering.technologies.NGROK]]\n","n":0.354}}},{"i":430,"$":{"0":{"v":"Pluto","n":1},"1":{"v":"\n\n[[science.cs.languages.julia]]\n\n\npluto is this interactive notebook (makes a DAG of the cells and re-runs what's needed when you change one-like a spreadsheet- so you it figures out the cell order for you)\nand it has notebook-specific package manager, so when you open one nb, it installs the packages for you\nInteresting. I'll check it out!\nit's very cute:D spreadysheets are 40 years ahead of everyone\nthey used it for https://computationalthinking.mit.edu/Spring21/\nOh yeah. I have heard that spreadsheets are purely functional programs with full referential transparency 🙂","n":0.112}}},{"i":431,"$":{"0":{"v":"Spreadsheets","n":1},"1":{"v":"\n\nSpreadsheets are purely functional programs with full referential transparency.\n\n[[science.cs.languages.Theory.Functional Programming]]","n":0.316}}},{"i":432,"$":{"0":{"v":"Security-Related","n":1},"1":{"v":"\n[[engineering.technologies.Security-Related.GitHub Secrets Manager]]\n\n\n[[science.CS.Cryptography]]\n","n":0.577}}},{"i":433,"$":{"0":{"v":"OAuth","n":1},"1":{"v":"\n For-my-own purposes summary from [Apigee's OAuth Pamphlet](https://cloud.google.com/files/apigee/apigee-oauth-the-big-picture-ebook.pdf).\n\n# Major point: \nOAuth allows an app to use the API of a platform (say Twitter) on your behalf without ever seeing your Twitter password.\n\n# Businesses as Platforms\n\nMarkets have intermediaries, who connect buyers and sellers by knowing what both want and create convenient ways to transact.\nApps are the new intermediaries.\n\n# API's are way for machines to talk to each other\n\n\nAPI's require trust. Innovation require openness. Trust and openness are at odds.\n\nAn innovative app could want to use your Twitter/Facebook/Google/etc data for a specific purpose.\nIt uses that by calling some API's Twitter/Facebook/Google provide.\n\nBut, you can't trust the app with your google password, as you have everything in there. If the password leaks, you're boned\n\nOAuth is a way to get around this. \n\n# Vallet Key\n\nA vallet key for a car is a __limited privilige key__ you can use to operate the car, but not access the car's glove box or trunc.\n\n OAuth tries to simulate this by having it's own __vallet key: token__ giving a single app/API access to particular API's/services on a __service provider (e.g. Twitter)__ on behalf of the user .\n\n ![](/assets/images/2022-01-25-12-06-54.png)\n\n# Flow: Miko, stefApp, and Twitter\n\n1. Miko uses stefApp on phone, which uses Twitter API for something.Miko already has logins for\nstefApp and twitter.\n2. Behind the scenes, stefApp starts the process of getting access from Twitter.\n3. A browser opens, asking Miko to log into with twitter.\n4. A page apprears, asking if Miko gives permission to stefApp to do specific things \nand not do other things w/ Miko's Twitter account.\n5. If Miko agrees, then a token is sent back and stored on Miko's phone.\n\nThis can be sharded to make it harder for a thief to get access to your Twitter account.\nstefApp never sees Miko's password.\n\nKey/token permissions cna be gracefully upgraded/downgraded/ stopped if needed.\n","n":0.058}}},{"i":434,"$":{"0":{"v":"GitHub Secrets Manager","n":0.577}}},{"i":435,"$":{"0":{"v":"Proxy and Reverse Proxy","n":0.5},"1":{"v":"\n\n# Proxy and Reverse Proxy\n## Forward Proxy\n \n A proxy server sits in front of some client machines (e.g. you IPS may be a proxy?) and intercepts web requests.\n\n It then redirects the request to the internet and can do some processing on the response and the request.\n\n ### Example  usecase:\n\n Thus it can help w/ security and generally augment both the request and the response.\n\n\n\n ## Reverse Proxy \n\n A reverse proxy is a proxy server that sits in front of some server and intercepts web requests.\n\n Example use case:\n\n 1. Load balancing\n [[engineering.system_design.load balancer]]\n 2. Caching\n\n\n\n\n\n","n":0.101}}},{"i":436,"$":{"0":{"v":"Object Relational Mapping","n":0.577},"1":{"v":" When connecting to a relational database, we can get the results, convert to object instances\n\n\n#  Django\n\n# Java Spring\n# .NET Entity Framework\n\n\n\n\n\n#TODO write some stuff here\n","n":0.2}}},{"i":437,"$":{"0":{"v":"Networks","n":1}}},{"i":438,"$":{"0":{"v":"Gateway","n":1},"1":{"v":"\n\nFrom:\n\n\nFrom [Tutorials Point](https://www.tutorialspoint.com/what-are-gateways-in-computer-network)\n\nA gateway is a network node that forms a passage between two networks operating with different transmission protocols.\n\n# Features:\n* located at the boundary; manages all data that inflows or outflows from that network.\n\n* Form passage between two different networks with different transmission protocols.\n\n* Protocol converter \n\n\n[Cisco page](https://www.cisco.com/c/en/us/products/routers/what-is-a-network-gateway.html)\n\n\nA network gateway is a device or node that connects disparate networks by translating communications from one protocol to another.\n\nSo it's some 'medium' that makes different networks to talk to each other...\n\n\n\n\n","n":0.112}}},{"i":439,"$":{"0":{"v":"NGROK","n":1},"1":{"v":"\n\n Headline:\n Spend more time programming. One command for an instant, secure URL to your localhost server trough any NAT or firewall.\n\n With the above you can 'hack' google colab, or run a server from your local machine (temporarly) in order to share stuff w/ client.\n","n":0.147}}},{"i":440,"$":{"0":{"v":"Message Queues","n":0.707},"1":{"v":"\n\n\nM3\n\n\n\n# Message Queues\n## Data Streams and logs\n#TODO add link to onenote about logs...\n\n\n# [Google PubSub](https://cloud.google.com/pubsub/)\n\n## Some notes from old project\n## Google Pubsub Emulator\nMake mock pubsub thing locally.\ngcloud beta emulators pubsub start --project = my_awesome-project_local\nPUBSUB_PROJECT_ID [options]\n\nCreate a simple pubsub app with pub/sub.\nPubsub: message queue;\nThere is a topic name;\nThen there are things, subscribed to that topic name\n\n# Note About Logs\n[Artilcle About Logs-Not application logs, logs like a stream data structure](https://onedrive.live.com/view.aspx?resid=A6A13EED7FFACAB8%215824&id=documents&wd=target%28System%20Design%20Stuff.one%7CC47AA9EC-5641-4E28-9386-48260F2E0A52%2FSystem%20design%20and%20logs%7CAD5C2B0C-35FD-4427-940A-C9469EE005A5%2F%29)\n\n\n[[engineering.system_design]]\n\n","n":0.121}}},{"i":441,"$":{"0":{"v":"MacroBase","n":1},"1":{"v":"\n\nStanford MacroBase\n\n[MacroBase Website](https://macrobase.stanford.edu/)\n\n\nWhat is MacroBase? A New Kind of Analytics Engine\nMacroBase is a new analytic monitoring engine designed to prioritize human attention in large-scale datasets and data streams. Unlike a traditional analytics engine, MacroBase is specialized for one task: finding and explaining unusual or interesting trends in data.\n\n\nHe was an assistent professor in Stanford, with many co-advisees with Matei Zaharia\n","n":0.129}}},{"i":442,"$":{"0":{"v":"ML","n":1}}},{"i":443,"$":{"0":{"v":"Spark","n":1}}},{"i":444,"$":{"0":{"v":"Libraries","n":1}}},{"i":445,"$":{"0":{"v":"SymPy","n":1}}},{"i":446,"$":{"0":{"v":"Incremental Learning","n":0.707},"1":{"v":"\n(Incremental Learning Algorithms)[https://datascience.stackexchange.com/questions/75198/which-model-is-better-for-incremental-learning]\n\nKeras - freeze some layers, train last few\nhttps://gokhang1327.medium.com/how-to-create-a-text-classifier-online-incremental-learning-with-creme-ml-6aac9d869e5c\n[Creme](https://pypi.org/project/creme/)\n\n\nFrom [datascience stack exchange ](https://datascience.stackexchange.com/questions/75198/which-model-is-better-for-incremental-learning)\n```\nI will say, it's an either Or situation\n\nYou can pick one of \"Incremental/Online\" training Or \"addition of new class\".\n\nYou may do a fine-tuning approach with a Neural network by adjusting the o/p layer and training the last few layers. But this approach expects the new data to be quite similar to the training set.\nKNN - Can do the online stuff but it doesn't do training. It simply calculates all the distances at the time of prediction. So, no reduction in computing. But you might have to compromise on accuracy if it is not the best\nScikit-Learn SGD Classifier can help with online training but can't support new classes\n\nFor classification, a somewhat important thing to note is that although a stateless feature extraction routine may be able to cope with new/unseen attributes, the incremental learner itself may be unable to cope with new/unseen targets classes.\nSGDClassifier\n\nOther models e.g. SVM/DT doesn't support incremental learning naturally. Though there are suggested approaches on the internet. But may not be simple. See these references.\njournalofbigdata A Good SE read\n\nI am not sure how will you figure it out if it is a new Class unless you have a separate arrangement because the model will predict it an existing Class anyway. Assuming you have a setup for that. We may try below approach -\nTill the time, the prediction is within \"known class\" - do an Online training.\nWhen the data is for a \"New Class\", do a full-data training.\nWith this approach, you can reduce the frequency of full-data training.\n\nA simple Neural network can be a good candidate for both purposes. You can also get class probability with it.\n```\n\n","n":0.06}}},{"i":447,"$":{"0":{"v":"Data Freshness","n":0.707},"1":{"v":"\nCan use [[science.CS.algos.Data Structures.Bloom Filters]] in order to not show same item to users that we've already shown...\n\n\n","n":0.236}}},{"i":448,"$":{"0":{"v":"Cold Start Problem","n":0.577},"1":{"v":"\n[[science.stats.Imputation and Missing Data#^conditional_sampling]]\n","n":0.5}}},{"i":449,"$":{"0":{"v":"Linux","n":1},"1":{"v":"\n\n\n# [Migrating Linux to another drive](https://askubuntu.com/questions/741723/moving-entire-linux-installation-to-another-drive)\n","n":0.408}}},{"i":450,"$":{"0":{"v":"Internet Of Things","n":0.577}}},{"i":451,"$":{"0":{"v":"DevOps","n":1},"1":{"v":"\n\nIf you don't use containers, Ops needs to handle everything.\n\n\n\n[[science.engineering.technologies.MLOps]]\n\n``` mermaid\ngraph LR;\nA[Continous Feedback];\nB[Continous Plan];\nC[Build];\nD[Deploy];\n    A-->B;\n    B-->C;\n    C-->D;\n    D-->A;\n\n```\n\n\n# International Commerce, Containers, and Docker\n\n\nBefore containers in ports, loading and unloading the ship was very stressfull.\n\nNow containers are standartized like Lego...\n\n\n\n","n":0.16}}},{"i":452,"$":{"0":{"v":"Github Actions","n":0.707},"1":{"v":"\n[[engineering.technologies.Security-Related.GitHub Secrets Manager]]\n","n":0.577}}},{"i":453,"$":{"0":{"v":"Docker","n":1},"1":{"v":"\n\nThese are rough notes from the Educative Tools\n\n# Why Docker\n\nProblem:\ndependency, environment managementm\n\nScaling \n\nUpdates\n\n\n\n# Basics\n\n* Container- isolated instance of a running VM.\n* Image 'recipe' for building a container. \n* Registry - Repository for imates.\n\n\nCan run containers from existing images.\nCan craete new images.\nCan upload images to registries\n\n\n# Orchestrator and updates\n\n\n## Scale-up\n\n\n```mermaid\ngraph LR;\nR[\"Registry(app v1.0.0,app v1.0.1)\"];\nRP[Reverse Proxy];\nO[Orchestrator];\nS1[\"Server 1, app v1.0.1\"];\nS2[\"Server 2, app v1.0.1\"];\nS3[\"Server 3, app v1.0.1\"];\nS4[\"Server 4, app v1.0.1\"];\n\n\nR-->O\nO-->RP\nO-->S1\nO-->S2\nO-->S3\nO-->S4\nRP-->S1\nRP-->S2\nRP-->S3\nRP-->S4\n```\n\n[[engineering.technologies.Proxy and Reverse Proxy]]\n\n#TODO Question: does the reverse proxy talk to the orchestrator??\n\n\n\n## Updates\n\nAn orchestrator is something that sits in front of a bunch of containers of the same type and:\n1. Redirects traffic to the correct container.\n2. Runs more or deletes containers\n3. Updates containers by a schedule (?)...\n\nSo probably docker allows \"seamless\" updates via it's orchestrator..\n\n\n**Solves  dependency conflicts- every container is 'born' to run tightly coupled set of applications/services.**. Most of the time it will be a single application.\n\n\n\n","n":0.084}}},{"i":454,"$":{"0":{"v":"Docker Compose","n":0.707},"1":{"v":"\n\n# Docker Compose\n\n\nTool to combine and run multiple related containers with single command and define their dependencies reasonably...\n\nSyntax:\n\n```\nservices:\n service 1:\n    image: image1\n    ports:\n     - \"80:80\"\n     - \"443:443\"\n    volumes:\n     - /var/www/html:/var/www/html\n    links:\n     - service 2\n     - service 3\nservice 2:\n    build: . # path to dockerfile\n    ports:\n     - \"80:81\"\n     - \"443:444\"\n    links:\n     - service 1\n\n```\n\n## Clauses\n\n### Build or Image\n -- path to the dockerfile, or image name (from the repository, I guess), respectfully.\n\n### Ports\n -- Mapping of container ports to host ports.\n -- Creates a tunnel\n -- Same as using the -p 5000:5001 flag in `docker run`.\n\n###  Volumes\n same as the -v option in `docker run`. Used to mount disks.\n\n\n### Links\n\n Link in the ![[engineering.technologies.DevOps.Bridge Network]]\n \n\n\n\n\n```\n\n\n# Docker Swarm\n\n\n\n# Docker Security and Nginx","n":0.091}}},{"i":455,"$":{"0":{"v":"Bridge Network","n":0.707},"1":{"v":"\n\nBy default, all cockers run \nin the 'Docker network' (?). Maybe.\n\n\n\nQuote from educative:\n\n\n\"By default, **all** containers **run** in the **default network space of Docker**. Hence, **every container can communicate** with others. We can create network isolation if it is needed.\"\n\n\n\n![Docker Network View](/assets/images/2022-07-14-15-15-32.png)\n\n\n# Default Docker Networks\nBy default, 3 networks are created:\n\n# host network\nDocker Internal- nevermind\n# None Network\n\nDocker Internal- nevermind\n# Bridge network\n\nnamed Docker0; it automatically creates IP subnet and gateway.\n\n\n **Containers within the docker network can talk to each other via IP addressing**. They are in the **same subnet**.\n\n","n":0.107}}},{"i":456,"$":{"0":{"v":"Compilers and Interpreters","n":0.577},"1":{"v":"\n[Writing Lisp Interpreter in Python](https://docs.google.com/document/d/12R6ASF58YjORtTSxNhMx6A71zjrP3lum0vMJUtGz3_o/edit?usp=sharing)\n\n\n\n\n[Haskell Version](https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours)\n\n\nThis is related also to [[science.CS.theory.Code Transformations.Differentiable Programming]]\n\n\n","n":0.277}}},{"i":457,"$":{"0":{"v":"BOTO3","n":1},"1":{"v":"\n\nYou use the **AWS SDK for Python (Boto3)** to create, configure, and manage **AWS services**, such as Amazon Elastic Compute Cloud (**Amazon EC2**) and Amazon Simple Storage Service (**Amazon S3**). The SDK provides an **object-oriented API** as well as low-level access to **AWS services**.\n\nDocumentation and developers tend to **refer to the AWS SDK for Python as \"Boto3,\"** and this documentation often does so as well.\n\n\nSDK Pattern\n\n![[engineering.Cloud.AWS.Simple Storage Service (S3)]]\n\n```{python}\n\ns3 = boto3.resource(\"s3\")\nobj = s3.Object(bucket,filename).get()['Body'].read() # gets the file object\nfrom pickle import loads# above is a handle to file w/ pickled data\nmod = loads(obj)\n```\n","n":0.104}}},{"i":458,"$":{"0":{"v":"AutoEDA","n":1},"1":{"v":"\n\n[State of AutoEDA in R Article](https://journal.r-project.org/archive/2019/RJ-2019-033/RJ-2019-033.pdf)\n\nPackages:\n\n* DataExplorer\n* DataMaid\n\n#dlookr\narsenal\n","n":0.354}}},{"i":459,"$":{"0":{"v":"System Design","n":0.707},"1":{"v":"\n\n# TL;DR Path For Interview\n\n\nRead and practice from either [this system design Interview book](https://www.amazon.de/-/en/Frank-Kane/dp/B09M172JQK/ref=sr_1_1?crid=24YZRAKE14LBZ&keywords=mastersystem+design+vorstellungsgespr%C3%A4ch&qid=1647079294&sprefix=sennheiser+450bt+battery%2Caps%2C92&sr=8-1)\n\nor the grokking course\nhttps://www.educative.io/courses/grokking-the-system-design-interview\nIf using the course, maybe jump between the case studies and the concepts towards the back.\nfrom here or the system design interview book, read the concepts first, then go trough the use cases one by one and when you don't understand something, google around.\nAfter reading through 3-4 of the design use cases, try to replicate by doing them in the drawing tool for the interview. Rinse and repeat.\n\n\n[Designing Data-Intensive Applications](https://dataintensive.net/) is also great, but maybe a bit of a longer-term read, deepening on your background and time.\n\n\n# My Study Path\n\n0. Watch some youtube videos to get a feel of goal.\nThese are good ones:\n[Design Messenger](https://www.youtube.com/watch?v=uzeJb7ZjoQ4&ab_channel=Exponent)\n[Design Build System](https://www.youtube.com/watch?v=q0KGYwNbf-0&ab_channel=Cl%C3%A9mentMihailescu)\n\n1. Join a discussion group. \n2. [Grokking is pretty classic](https://www.educative.io/courses/grokking-the-machine-learning-interview).\nCan do the free trial and or get the pdf for free\n Read trough it. I [this system design Interview book](https://www.amazon.de/-/en/Frank-Kane/dp/B09M172JQK/ref=sr_1_1?crid=24YZRAKE14LBZ&keywords=mastersystem+design+vorstellungsgespr%C3%A4ch&qid=1647079294&sprefix=sennheiser+450bt+battery%2Caps%2C92&sr=8-1) was a bit better, but maybe it was ergonomic issue(reading on kindle).\n\n3. When I would hit a point I don't understand re: performance and choice of DB, I would go around to google stuff about sql/nosql/ usage patterns of different DB's.\nSome notes here:\n[[engineering.system_design.nosql databases]]\nSome nice Quora Discussions/blogs I've found:\n\n[RDBMS-over-nosql](https://www.quora.com/What-are-some-reasons-to-use-traditional-RDBMS-over-NoSQL>)\n[Relational-Disadvantages](https://www.quora.com/What-are-disadvantages-of-relational-databases)\n[Time Complexity of Joins](https://www.quora.com/What-is-time-complexity-of-Join-algorithm-in-Database?share=1)\n[Logs and Real Time Data](https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)\n[Shopify Data Store Blog](https://shopify.engineering/five-common-data-stores-usage)\n\nPapers:\n[Google Big Table Paper](https://static.googleusercontent.com/media/research.google.com/en//archive/bigtable-osdi06.pdf)\n\n\n3. Practice the drawing tool you'll use during the interview. Do a bunch of drawings/designs with it.\n\n\n\n4. Rememeber to mention [[engineering.system_design.CAP and PACELC Theorems]].\n\n5. Remember to mention that if scalability is required and you turn out to need joins, you can always outsource the joins etc to the application logic.\n\nThink about if you need very fast reads and writes, and how this trades off against correctness\n\n\nNotes and references here:\n\n[log based workflow](\nhttps://onedrive.live.com/redir?resid=A6A13EED7FFACAB8%212256&page=Edit&wd=target%28Quick%20Notes.one%7Cb7e7d858-e5f0-4801-9d21-c506078b696a%2FSystem%20design%20and%20logs%7C468f4191-cdbc-7440-b035-e8581ff8b933%2F%29)\n\nhttps://onedrive.live.com/redir?resid=A6A13EED7FFACAB8%212256&page=Edit&wd=target%28Transmetrics%20Clieant%20Projects%2FNew%20Section%208.one%7Cc346bbda-ef84-4637-8db7-5b2328e31011%2FManage%20massive%20writes%20with%20HA%5C%2FDR.%20-%20A%20%7C65627e1e-3a4b-4e06-a3df-7d4a7968a69f%2F%29\n\n\n\n\n\n# Basics\n\n## Single- Server Design \n\n```mermaid\ngraph LR;\na[Clients]--network-->b[\"Server(compute and DB)\"];\nc[Single point of failure]-->b\n```\n\n Single point of failure is bad\n\n```mermaid\ngraph LR;\na[Clients]--network-->b[\"Server(compute and DB)\"] <--> f[DB];\nc[Single point of failure]-->b\nc[Single point of failure]-->f\n\n```\n\nnot any better\n\nVertical Scaling - buy bigger server, has limits.\n\nHorizontal Scaling - buy more servers, larger limits.\n\n\nGeo-disitrubtion of servers.\n\n *Any individual server cannot assume that that server is the same one that served previous requests to a given user. That's what I mean by stateless.*\n\nDifferent Data centers (availability zones in AWS).\n\n\n# DB Replication\n\n## Cold Standby \n\n\n```mermaid\ngraph TD;\na[Clients]--network-->b[\"Server(compute and DB)\"] <--> f[DB];\nc[\"DB Replica\"]\nc--periodic backup-->f\n```\nDowntime; backup files to restore with, data since last backup is lost.\n\n## Warm Standby\n\n```mermaid\ngraph TD;\na[Clients]--network-->b[\"Server(compute and DB)\"] <--> f[DB];\nc[\"DB Replica\"]\nc--\"replication (copy-on-write-constantly)\"-->f\n```\nMost Database systems have their own replication mechanisms.\n__Replication__ is a process of copying data from one database to another. For most practical cases, \nit's just a switch you turn on...\n\n\n##  Hot Standby\n\n\n```mermaid\ngraph TD;\na[Clients]--network-->b[\"Server(compute and DB)\"] <--> f[DB];\n\nc[\"DB Replica\"]\nc--\"replication (copy-on-write-constantly)\"-->f\nb-.if primary fails.->c\n```\n\n\n\n```mermaid\ngraph TD;\na[Clients]\nb[\"Server\"];\nc[\"DB\"];\nd[\"DB Replica\"];\ne[\"Load Balancer\"]\na--network-->b-->e-.->c\ne-.->d\n```\n\n\n\n## horizontal \n\n\n\n\n\n\n\n\n\n\n\n\n","n":0.048}}},{"i":460,"$":{"0":{"v":"Nosql","n":1},"1":{"v":"\nThis is just something...\n","n":0.5}}},{"i":461,"$":{"0":{"v":"Amazon Kinesis","n":0.707},"1":{"v":"\n#streaming\n\nHandles streaming data.\n","n":0.577}}},{"i":462,"$":{"0":{"v":"Amazon Athena","n":0.707}}},{"i":463,"$":{"0":{"v":"Nosql Databases","n":0.707},"1":{"v":"\n\n__Note - these are my personal notes from barely studying these things and trying to understand them__. They might be completely off.\n# MongoDB\n\nDocument database. 'Best' use-case scenario: not sure what our data model is exactly, need to integrate many different data sources. Can just put them in Mongo and have the application deal with\nit later.\n\n## Use Cases:\n\nWhen you are expecting a lot of reads and write operations from your application but you do not care much about some of the data being lost in the server crash \n\nUp to application logic to handle joins/etc!!! \n\n# Key- Value stores\n##  DynamoDB\nAmazon DynamoDB supports keys, partition keys, sort keys, and secondary indices.\n(DynamoDB keys)[https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/bp-sort-keys.html].\n\nSo it can probably support fast range queries.\n\n## Cassandra and Hbase. \n\nWhen your use case requires more writing operations than reading ones ---  \n\nIn situations where you need more availability than consistency. For example, you can use it for social network websites but cannot use it for banking purposes \n\nYou require less number of joins and aggregations in your queries to the database \n\nHealth trackers, weather data, tracking of orders, and time series data are some good use cases where you can use Cassandra databases \n\n# Wide Column Stores\n BigTable\n\n\n# Graph Databases (Neo4j)\n\nUse case is clear- want recursive joins and long-range relationships.\nIt's kind of clear when we want it...\n\n# Column Oriented Databases:\nSupport fast appends, use [[science.CS.algos.Run Length Encoding]] to compress data. Great for massive time series (e.g. sensor data, [[engineering.technologies.Internet Of Things]]).\n\n\n# List Of popular NoSQL databases w/ some notes... \n\nhttps://onedrive.live.com/view.aspx?resid=A6A13EED7FFACAB8%215824&id=documents&wd=target%28System%20Design%20Stuff.one%7CC47AA9EC-5641-4E28-9386-48260F2E0A52%2FNoSQL%20databases%20list%7CB0AF0C61-E8DA-4D46-8CCE-4F24A23D4698%2F%29\n\n# Database Replication\n* Cold Standby \n\n```{mermaid}\ngraph LR;\na[a]-->b[b]\n\n```\n\n# Time Series\n\nHave some common properties with [[#column-oriented-databases]]\n\n[[engineering.system_design.InfluxDB]]\n\n\n\n\n","n":0.062}}},{"i":464,"$":{"0":{"v":"BigTable","n":1}}},{"i":465,"$":{"0":{"v":"Load Balancer","n":0.707},"1":{"v":"\n\n# Load Balancing Algorithms\n\n[[science.math.modelling.Operations Research.Scheduling.Load Balancing]]\n","n":0.408}}},{"i":466,"$":{"0":{"v":"Streaming","n":1},"1":{"v":"\n[[engineering.system_design.nosql.Amazon Kinesis]]\n","n":0.707}}},{"i":467,"$":{"0":{"v":"Software Design exercises","n":0.577},"1":{"v":"\n\nFrom [here](https://etutorials.org/Programming/Software+engineering+and+computer+games/Part+I+Software+Engineering+and+Computer+Games/Chapter+5.+Software+design+patterns/Exercises/)\n\n\n\n# Exercise 5.1: Strategy Pattern and sales chart display\n\nSuppose that you have a cSalesData object with a drawGraph() method. Draw a UML including a few lines of code to show how you could use a Strategy Pattern to select at runtime between drawing a bar graph or a pie graph of the data.\n\n\ntype A<C> = \n    object a: C\n    function b: C->1\nend\n\nA<C>(a::C,b::C->1) = new A(a,b)\nA<C>(a::C) = new A(a,x->{})\n\nexecute(a::A) =a.b(a.a)\n\n\ncSalesData = A(salesData)\ncSalesData.b = {...\n\ndrawBar\n..\n} \n\n\n\nExercise 5.2:\nTemplate Method patterna dn opening diverse file types\n\nTemplate methd pattern and opening \n\n\n","n":0.107}}},{"i":468,"$":{"0":{"v":"Search","n":1},"1":{"v":"Three basic stages of search : \n__crawling__ – where  discover pages; \n__indexing__ - normalize text from pages and make it easier to search\n__retrieval -get a list of relevant search results.\n\n# Crawling\n\nScan sites, get links, put in queue(#BFS), get content, images, etc, store in database. \nMaybe cache a copy of page\n\n\n# Indexing\n\n# Retrieval/Searching\n\n Ranking algorithm is trade secret, but we know about pagerank, etc.","n":0.126}}},{"i":469,"$":{"0":{"v":"Scoreboard","n":1},"1":{"v":"\n\n\nWe can:\n1. For each user, keep bucket_id, and score. \n2. For each bucket, keep bucket_id, user_id, lower_bound,upper_bound, score, next and previous bucket pointers. \n3. The ranking table is split into buckets.\n4. When the user score is updates, we:\n * update the user score\n * check if we're still in the same bucket, else delete user from bucket, go up or down bucket pointers, and add user to new bucket. Alternatively, we can first consult a the bucket table above, and we can figure out the appropriate new bucket .\n * evern 100 ms, sort each bucket in parallel, using insertion sort. If we detect some buckets have too many inversions,\n can switch them to merge sort (too many games in a given bracket).\n* if sorting time for any bucket becomes too large (>e.g. 50ms), then split the bucket into two, \nmove upper part of the user range to new bucket.\n* We retrieve 10 above and bellow you in the same bucket. For edge cases where  you're the top/bottom 9 person in bucket- have 2 parallel 'bucket' sequences: e.g. percentiles 0,2,...,98,100, and percentiles 0,1,3,5,...,99,100, search for user in both sequences. At least  1 of them will contain the -10-user_rank;10 +user_rank interval completely (or can use the bucket pointers, mentioned before)\n\n* For sorting the friend list: \n1. If friend list is undirected, maintain these equivalence relations sort and retrieve them\nThen we use similar sorting mechanisms for each friend list.\nFriend lists are equivalence relationships, every time a user plays a game, update their score, use a procedure as above.\n\n2. If friend list is directed\nMaintain list to show to each user.\n\nFor players with not many incoming friends (ppl who follow them):\nEvery such player is a pub-sub topic, to which ppl who follow them subscribe.\nThen when game happens, the user publishes to the topic, and the topic publishes to all the users who follow it,\nupdating their 'friend' scoreboard w/ insertion sort.\n\nFor players with many incoming friends (ppl who follow them) :\nCelebrity problem\nDon't update follower scoreboard directly, but for each user, maintain a special list of celebrities they follow, and at\nrequest- time, if there was update, insertion-sort them into the existing 'friend' scoreboards. \n\n\n  ","n":0.053}}},{"i":470,"$":{"0":{"v":"SQL Databases","n":0.707},"1":{"v":"\n# SQL Databases\n\n\n# Vendors\n\n## Postgres ^postgres \n\n\n\n\n\n","n":0.378}}},{"i":471,"$":{"0":{"v":"Object Storages","n":0.707},"1":{"v":"# Distributed File Systems\n\n## HDFS\n\n## S3 \n### Amazon S3 storage types and durability guarantees\n\n","n":0.267}}},{"i":472,"$":{"0":{"v":"ML System Design","n":0.577},"1":{"v":"\n# ML System Design Interview Structure\n\nSignals they're looking for\n* Theoretical knowledge of ML\n* Methods/ algorithms \n* How it's done in the industry/ state of the art solutions\n* Practical Experience \n* Implementation: development and model serving \n* Technical leadership\n* Product leadership: \n\n \n\n People ask about recommendation systems, as it:\n 1. Huge impact/ big part.\n 2. Many approaches, very creative methods, could go in different directions.\n 3. Non-trivial model serving.\n 4. Tricky product stuff.\n\n\nExamples:\n 1. Recommend new trips to take.\n 2. Recomend restaurants on Google Maps.\n\n# Design Process\n\n# Clarify Objectives And Constraints (requirements)\n\n\n[[seed.Product Management.Product School Book#^companygoals]]\n1. What are we optimizing?\n Engagement+ revenue are common ones.\n2. Timing SLA (batch or real-time)?\n3. Scale (whole product/all users, is it decomposeable,etc)?\n4. Multiple languages? \n5. Recency of content to show?\n\n\n__Look for buy in...__\n\n# User Feed/recommendations\n\n```mermaid\ngraph LR;\na[Universe of possible items] -->b[Candidate Generations]-->c[Ranking, scoring, re-ranking]\n```\n\n\n# Inputs and Features\n\nSources:\n* User profile\n* Item profiles (e.g. videos)\n * User-item interactions.\n * The search query\n\nFeatures:\n* Session information (length, number of viewed items)\n* Item profiles (e.g. videos): NumViews, weighted number of views, description, features from the video, text, data2vec, etc\n* User demographics info - age, gender, nationality, location\n* Post History/ action history\n* Friends and following -  info from the graph\n\n\n\n\n# Some Videos to Watch\n[OneNote Links](https://onedrive.live.com/view.aspx?resid=A6A13EED7FFACAB8%215824&id=documents&wd=target%28meta%20notes.one%7C5A0AC04E-9E8E-4CFF-A157-0BCC01CE8AC7%2F%29\nonenote:https://d.docs.live.net/a6a13eed7ffacab8/Документи/Leetcode%20Problems/meta%20notes.one#section-id={5A0AC04E-9E8E-4CFF-A157-0BCC01CE8AC7}&end)\n\nhttps://www.youtube.com/watch?v=7VFoLDN3apI&ab_channel=DataScienceJay\nhttps://www.youtube.com/watch?v=sEZsIUBIhNk&list=PLmGsNPZGeM5D8fgr2scwe8wZih4SYB7Vt&ab_channel=InfoQ\n\nhttps://www.youtube.com/watch?v=4mG7morAasw&ab_channel=DataScienceJay\nhttps://www.youtube.com/watch?v=sEZsIUBIhNk&list=PLmGsNPZGeM5D8fgr2scwe8wZih4SYB7Vt&ab_channel=InfoQ\nhttps://www.youtube.com/watch?v=HREeLryOh4Q&list=PLmGsNPZGeM5D8fgr2scwe8wZih4SYB7Vt&index=3&ab_channel=ArtificialIntelligence-AllinOne","n":0.07}}},{"i":473,"$":{"0":{"v":"Youyube Video Recommendation","n":0.577},"1":{"v":"\n[[engineering.system_design.ML System Design.Recommender Systems]]\n\n# Several Layer Process\nUse fast search in the embedding space to generate candidates.\n\n# After that simply try to predict probability to click...","n":0.2}}},{"i":474,"$":{"0":{"v":"Search Ranking","n":0.707},"1":{"v":"\n\n# Problem Statement\n\nGeneral Query, return results\n\n## Scale \n\n## Personalization\n\n## Internationalization\n\n\n# Metrics\n\n\n## Online Metrics\n\n### End To End Metrics\n ### User engagement\n [[seed.Product Management.Product Metrics.User Based Metrics (Digital Products)]]\n [[seed.Product Management.Product Metrics.User Based Metrics (Digital Products)#^ctr]]\n ### Query Succcess\n Dwell time, not re-doing search after short time.\n\n [[seed.Product Management.Product Metrics.User Based Metrics (Digital Products)#^task_success]]\n\n\n # Offline Metrics\n Classification metrics\n [[science.stats.Regression.Classification.Metrics]]\n AUC, precision, recall, etc.\n Ranking Metrics: \n ![[science.stats.Regression.Loss Functions#^ranking-NDCG]],\n ![[science.stats.Regression.Loss Functions#^ranking-map]],\n\n\n # Architectural Components\n\n Draw the usual Picture - think about multiple models etc.\n\n\n# Document Selection Algorithm\n We can give multiple semi-independent scores of different aspects of the user-query-document match.\n 1. Intent-document match\n 2. Document Pagerank\n 3. Keyword Match\n 4. User-Document Topic Match\n 5. Location Match \n\n We will have independent models, estimating all these scores, and combine them w/ some function to estimate the best score.\n\n# ML Architectural Parts\n\n## Query Rewriting\n### Spell Checking\n### Query Expansion \nAdd synonyms and nearby phrases.\n#### Query Relaxation\nRemove redundant words (e.g. __good italian restaurants__ --> __italian restaurant__).\n\n### Query \n## Query Understanding \n\n### Intent Understanding\n Embed query?\nCreate an 'intent' embedding for the query- 'earthquake' is 'news-y', 'food' is 'local', etc.\nCan see the intent dataset by manual labelling and then proceed.\n\n## Inverted Index Lookup\n\n\n##\n\n \n\n\n# Relevance Scoring Scheme\n\nCreate different models for relevance for:\n1. Terms match\n2. Document popularity\n3. Query intent match\n4. Personalization match\n\nAnd maybe do a function on that to decide what to show\n\n\n# Feature Engineering\n\nThe 'agent types' in this system are:\n1. Searcher\n2. Query\n4. Documents\n5. 'Context' (includes session length, current intent, etc)\n\nIn addition, we can think about \n* Searcher-Document Interactions\n* Query-Document Interactions\n\n\n## Searcher Features\nDemographic data. Historical intents. Interests.\n\n## Query Features \n[[seed.Product Management.Product School Book#^companygoals]]\nKeywords, query embedding. Temporal features (time of day).\nQuery historical engagement.\n\n## Document Features\nDocument Embedding. Pagerank/popularity measures.\n\n\n\n","n":0.06}}},{"i":475,"$":{"0":{"v":"Recommender Systems","n":0.707},"1":{"v":"\n\n# Why Recsys?\n\nItem space, user space.\nVery high value to customer and commercial.\nItems can be other users too, i.e. tinder.\n\n# References\n[Matrix Factorization Report](https://pdfs.semanticscholar.org/b474/56864177f79b0ef1b00ac923527aac256ffc.pdf).\n\n\n# Requirements\n## Functional\n Enjoyable content\n Increasing Revenue\n Fairness (across demographic strata)\n Fairness (across items)\n Diversity of content (serendipity)\n\n## Non-functional\n* Availability\n* Low latency\n\n\n# System Overview\n\n## Scalability Concern 1\n\n```mermaid\ngraph LR;\na[\"Corpus(10^9s)\"];\nb[\"Candidates(100's)\"]\nc[\"Top Candidates(10's)\"]\nd[\"Top Recommendations(ordered))\"]\n\na--scoring-->b--complex re-scoring-->c--ranking,selection-->d\n```\n# High-level description on priorities/ ML approach at each stage above\n# First Pass ^candidate_generation\nTo get from __Corpus__ to __Candidates__\n\nquick-ish models, fast collaborative filtering,etc.\n\nKNN w/ random projection or local hashing, etc.\n[[science.math.Functional Analysis.High Dimensional Neighborhood Search]]\n[[science.math.Functional Analysis.High Dimensional Neighborhood Search.Random Projections]]\n\n# Second Pass\n\nBigger models, use everything possible, user activity etc.\n[possible recsys architectures](https://d2l.ai/chapter_recommender-systems/index.html).\n\nAll tricks about cold start, session models, etc also come here.\n\n\n# Third pass re-Ranking\n\nAdd constraints (already seen this item, has clicked 'not interested' on similar, etc).\nAdd freshness, fairness, diversity.\nMaybe use some linear programming or other stuff to optimize something close to business objective.\n\n# Data\n\n## User features:\n\nlogin date, demographics\n\n## Item features\n\nItem content features- description, publisher, category, images, video snapshots. Tags, publisher tags,\ntags from image/video object detection algos, etc.\n\n\n# Item-user Interaction \n* Rating\n* Purchase\n* Other stuff\n\n\n# Feature Engineering\n* Normalization of ratings\n\n\n\n## Implicit and Explicit Signals, combining them ^implicit-explicit signal\n\nSummary:\nimplicit feedback based models seem better for ranking predictions, much richer, but if\nbasing only on implicit feedback, might have popularity bias.\n![[science.stats.Regression.Recommender Systems#^popularity-bias-implicit]]\n\n\n Metrics\n* \n![[science.stats.Regression.Loss Functions#^ranking-start]]\n![[science.stats.Regression.Loss Functions#^ranking-start:#^ranking-end]]\n\n# Item-item or user-user based similarity (content-based filtering) ^content-filtering\n## Data:\nMovie profile:\n* Genre\n* Producer\n* Tags\n* Description (word2vec,doc2vec)\n* Images and video snapshots (maybe tagging based on that, maybe color pallet)\n* Thumbnails\n<!-- * User search/interest history -->\n\nMaybe latent space of 'interests' that's common to not only this recsys, but\nthe search as well...\n\n\n\n\n# Item-user based similarity (collaborative filtering) ^collaborative-filtering\n\n# Models ^models\n## Item-Item Similarity ^item-item-similarity\n\n* Item KNN\n* Item Attr\n* BPRMF\n* ItemKNN\n* Item Attribute KNN\n* UserKNN\n* User Attribute KNN\n* Group-based (Clustering-based algorithm)\n* Paco Recommender (Co-Clustering-based algorithm)\n\n\n\n\n\n# Algorithms ^algorithms\n\nFor content filtering approaches:\n\nClustering type things, manifold dimensionality reduction, etc. General unsupervised learning techniques.\n[[science.stats.Unsupervised Learning]] \n[[science.stats.Unsupervised Learning.KNN]] \n\n\n## Collaborative Filtering ^collaborative-filtering\n\n## Item-User Embedding (Collaborative Filtering)) ^collaborative-filtering-models\n* Matrix Factorization (with and without baseline)\n* Non-negative Matrix Factorization\n* SVD\n* SVD++\n* ItemKNN\n\n## Optimization Techniques ^optimization-techniques\n### Stochastic Gradient Descent ^sgd\n\n\n[[science.math.Optimization.Stochastic Gradient Descent]]\n\n### Alternating Least Squares ^als\n\nNote in ![[science.stats.Regression.Recommender Systems#^svd-loss2]] \nwe're optimizing wrt $p,q,b$. \nThe loss is not convex, BUT if we fix $p,b$ we can optimize wrt $q$ with least squares.\nSame for fixing $q,b$ -$p$ and $q,p$, which means we can have a sequence of solving quadratic (and I think in this case, convext) problems.\n\n Advantages:\n massive parallelization, as if we have only the $p,q$ case, the objective function decomposes across variables!!!\n But depends on the objective itself.\n\n\n# Cold Start Problem\nNew (or unknown) users or  items.\n\n\n## New Item\n No historical interaction data.\n Typically use item data or baselines.\n\n* Use item-item model, based on content (item-similarity for current item) [[^item-item-similarity]]\n\n## New User\n\nUnseen or anonusers - no profile or historical interactions. \n\n### User-user model, based on demographic characteristics\n\n###  Anonimous Users\n \n If no profile, start showing items (Akinator-style)[https://en.akinator.com/] somehow and try to represent the user a s linear combination of the items seen.\n\n## No collaborative filtering\n\nItem-similarity\nContextual models for short-term history.\n\n### Intra-session models\nFrom [this video](https://youtu.be/y_TzOOCJqxI?t=1066), we get a session-based recommendation\nusing such architecture:\n```mermaid\ngraph LR;\n\na[\"Input 1-hot encoding\"];\nb[\"Embedding Layer\"];\nc[\"GRU Layer\"];\nd[\"GRU Layer\"];\ne[\"GRU Layer\"];\nf[\"Feedforward layers\"];\ng[\"Output: scores on items\"];\n\na-->b-->c-->d-->e-->f-->g\nb-->d;\nb-->e;\nb-->f;\n```\n\nuses [[science.math.Optimization.Optimizers In in Neural Networks.Negative Sampling]],#minibatch.\n\n[[science.stats.Regression.Metrics:^ranking-start:^ranking-end]]: BPR, TOP1.\n\n\n### But in fact neighborhood based Methods are not much worse if done properly\n[Debunk on the 20-30% of the last paragraph](https://web-ainf.aau.at/pub/jannach/files/Conference_RecSys_2017.pdf)\n\n\n\n## Representing user as linear combination of items\n\n# Discrepency between 'business goal metric' and 'within-optimizer loss'\n\nCan have variety of final allocators.\n\n# Fairness ^fairness\n[[Philosophy and Rationality.Algorithmic Fairness]]\n## Error is same across groups\n\n![[Philosophy and Rationality.Algorithmic Fairness#^independence-formula]]\n\nCan either model directly or just train algo and then test if erros same (ANOVA, t-test variations etc).\n\n# Keeping Track and serving of multiple models, model versions, A/B/C/D... testing,rollbacks\n## Data Structure for multiple models\n\n## A/B/C/D testing \n\n## Model Rollback\n\n\n\n## Train-test set splitting\n\nProbably similar to how we split data for testing in [[science.stats.Deep Neural Networks.Graph Neural Networks]]\n\n![[science.stats.Train Test Splitting#^recsys-start]]\n[[science.stats.Train Test Splitting]]\n\n\n\n# Moderation\n\nRemove, reduce, inform approach.\n\n## Remove\n\nAs users upload stuff, it's put in a [[engineering.technologies.Message Queues]] and pool of workers\nis processing it for violation of Community standards, forbidden content, abuse, etc.\nIf confidence is high >99.5%, say, can directly remove.\n\n## Reduce\n\nCan send stuff above certain threshold for manual moderation. Can have buttons to report, etc,\ngain more feedback about it.\n Threats, etc.\n\n## Inform\n\n\nCan match clickbait titles, if we detect topic or semantics of a title/article, can check agains \n3rd party fact-checkers.\n\n\n# Quick Filtering Tricks  ^filters\n\nSome fast algorithms for deleting items for consideration for a certain query.\n\n### Bloom Filters for deleting forbidden Items\n[[science.CS.algos.Data Structures.Bloom Filters#use-in-recommendation-systems]]\nUsage- mostly first-pass.\n### Exclusion of 'too similar' items from same newsfeed\nThis looks vaguely like [[science.math.modelling.Operations Research.Facility Location]], or\n[[science.stats.Unsupervised Learning.Clustering]] problem. Can, though, solve approximately by a greedy approach where we pick an item and remove from consideration items too similar to it, until correlation/cosine similarity is low enough, pick next item, etc. Always pick the next thing that's dissimilar enough from the previous ones.\n\nSee also (Greedy 2-approximation for k-center)[https://ugtcs.berkeley.edu/src/approx-sp19/scribe-notes-2.pdf].\n\nUsage-mostly first pass.\n\n#  Privacy and GDPR\n![[Philosophy and Rationality.Algorithmic Privacy, Right to be Forgotten#^gdpr:#^gdpr-end]]\n\n\n# Model Serving \nTricky, thus the multi-step process.\n\n\n# Future Directions\n\n# Improved RNN's : cold starts and session models\n\n# curther research on contextual models, as well as content and metadata.\n\n# Combining sequence and historical data (long and short term behavior)\n","n":0.034}}},{"i":476,"$":{"0":{"v":"Local Search Ranking","n":0.577},"1":{"v":"\nProbably [[science.CS.algos.Data Structures.Quad Tree]]+ Recommender Systems+\nUI for selecting location, range etc.\n\nGaussian kernel around location, e.g. 100 meters vs 1km is much larger difference than 40 km vs 41km.\n","n":0.189}}},{"i":477,"$":{"0":{"v":"Ads Within Newsfeed Pasc","n":0.5},"1":{"v":"\n\n#TODO \n\n 1. Talk more about motivated reasoning - pre-selection/ranking steps.\n 2. a/b testing - why do it\n 3. offline preselection/ranking - most of this is precomputed.\n Can do it at 3am. \n online things- in emergency.\n \n Missed internationalization.\n \n how do you featurize text/images from different countries. Is this a problem/not a problem.\n \n Text has biggest problems in internationalization.\n \n memorize a few formulas to use.\n Ranking/recommendation.\n \n NDCG\n \n Given a typical loss, be able to write the gradient.\n \n -----\n \n Sometimes they ask for gradient of that...\n \n -----\n","n":0.103}}},{"i":478,"$":{"0":{"v":"Ads Evaluation Framework","n":0.577},"1":{"v":"\n\n\nDesign evaluation framework for ads ranking\n\nSource ads: given query; queries are grouped for scalability.\n\n- Sourcing ads is like 'search' a list of ads.\n- Then you have several steps of rankings.\n- They all go trough same code. \n- $E[CTR]$ , other metrics -> bidding  formula.\n- Positioning on page hapens in the end.\n\nCause you have many steps and need to return ad very fast, every step needs to be fast.\n\nRevenue\nOPS - what they make from the sale using the ad.\n\nRoAS = OPS/Revenue\n\n------------\n\nLTV - lifetime value\n\nUse short-term surrogates. Number of top purchases is correlated with LTV (Accuracy@1).\n\n3 stakeholders:\nAdvertiser\nAd provider\nShopper.\n\nFor each model you have treatment, do statistical testing on the business metrics.\n\nWhen you're online you know the metrics.\n\n**You need offline metrics (counterfactuals) that it correlates a lot with the online evaluation.\n**\n\n\n\n# offline vs online ads testing\nOnline - AB testing, etc.\n\nOffline - counterfactuals with proxies.\n\nNeed very high value of the 'offline evaluation data'.\n\nHumans can create this 'ground truth' data.\n\nExample of automatically create ground truth data is 'clicked and purchased' data..\n\n**Is the offline ground truth data representative of the online use case\n**\n\nRank models against each other- offline proxies.\n\nOffline data is not representative of the online use case.\n\n\n\n\n\n Offline proxi metric should 'correlate' with online 'proper counterfactuals', which are impossible to estimate. \n\n The correlation should be in the sense of 'ranks between models are monotonous'.\n\n\n## AB Testing Comment when switching models\n\n  When switching models, leave the baselines as some pct to be able to compare stuff later.\n\n e.g. tiny percentage of population w/o spam filter.\n \n\n\n\n# Questions\n\n## \n\n ## Reading list/Topics to read\n\n * EducativeIO Grokking ML list\n * Attribtuion Modelling for Google and Facebook Ads\n * https://www.amazon.com/Attribution-Modelling-Google-Ads-Facebook/dp/1792911394\n\n ## Classification/ranking based approaches\n ## Optimization/Game Theory/ Bidding\n ## Technologies\n He has background in graphs, e-commerce, multi-agent distributed planning, trust,\n etc\n\n\n\n\n ## Technology Stack\n\n ## What are you looking for in terms of skill set?\n\n How is the team matching done?\n\n\n # Onboarding\n # Team Integration\n\n # Pct of People Working Off-Site\n  How many ppl work \n\n\nCommerce Area.\n\n##","n":0.055}}},{"i":479,"$":{"0":{"v":"Logs","n":1},"1":{"v":"\n#todo add log page from onenotes\n\nappend-only data structure thats used to restore stuff.\n\n","n":0.277}}},{"i":480,"$":{"0":{"v":"InfluxDB","n":1},"1":{"v":"\n\n An open source Time Series DB.","n":0.378}}},{"i":481,"$":{"0":{"v":"Game Achievement System","n":0.577}}},{"i":482,"$":{"0":{"v":"ElasticSearch","n":1},"1":{"v":"\n* Built on Apache Lucene (search engine library)\n[Hadoop Note](https://www.evernote.com/shard/s101/nl/11122041/6e2b3519-6f6e-4b62-9f68-44da2e077952?title=Hadoop%20interview)\n\n#elasticsearch\n\n\n[[engineering.system_design.Case Studies.Twitter Search]]\n\n\n\n","n":0.302}}},{"i":483,"$":{"0":{"v":"Designing Data Intensive Applications","n":0.5},"1":{"v":"\nThese are nots from the Designing Data Intensive Applications book.\n\n# Storage and Retrieval\n\nBig difference between storage engines, optimized for analytics, and ones optimized for transactional workloads.\n\n\none can use auxilary [[science.CS.algos.Data Structures.Bloom Filters]] in cases where not finding key would take long time.\n## Hash indices\nKeep the offset\n* only append to file\n* tombstone is a special value, indicating that the key is deleted\n* to optimize: \n use fixed- size segments, periodically compact (removing duplicates) and merge them \n\n\nLimitations: no range queries.\n\n## Apend, split into segments\nkeep segments sorted, compactify segments.\n\n# SSTables and LSM trees\nRequire that the sequence of key value records is sorted by key always.\nIn-memory memtable, implemented as self-balancing tree.\nWhen grows, write it to disk as a segment.\n\nFind record: \n1. try the memtable.\n2. if not found, try the disk segments in order of recency.\n\nHandle crash by writing simultaneously to disk as well as the memtable.\n\n### Merge and compact\n\nOn schedule, compact and merge the disk segments.\n\nThis is how lucene works, roughly.\n\n**Range queries ** are supported ,as keys are kept sorted.\n\n# B-tree indices\n\n\n\nB-trees are much more wildly used than lsm trees, but latter are promising.\n\nVery similar to other balanced trees\n\n# Summary\n LSM trees might be faster to write, as it's just sequential writes...\n Look at pages 82-83 of the book.\n\n # Secondary keys\n they are not unique, but crucial for performance of joins and such.\n can append row id to the row to make it unique and use either b-tree or lsm tree. Another way is to make the values lists of matching row identifiers.\n\n\n # Multi-dimensional indices\n ## Latitude and longitude\n in a geographical ocntext, we would like to see all locations within a lat-lon grid...\n\n One option is to translate a two-dimensional location into a single number using a **space-filling curve**, and then to use a regular B-tree index [28]. More commonly, spe‐\ncialized spatial indexes such as R-trees are used. For example, PostGIS implements\ngeospatial indexes as R-trees using PostgreSQL’s Generalized Search Tree indexing\nfacility [29]. We don’t have space to describe R-trees in detail here, but there is plenty\nof literature on them.\n\n# In-memory databases\nRedis, Memcached\n[[engineering.system_design.Caching.Redis and Memcached]]\nwhen restarted, Memcached would reload state from disk or over network. Disk is used only for an appen0donly log, which we use in case of crash/resta\n\n\n \n\n","n":0.052}}},{"i":484,"$":{"0":{"v":"Data Warehouse","n":0.707},"1":{"v":"\n# DWH\n\n\n\n[[engineering.system_design.nosql.Amazon Athena]]\n","n":0.577}}},{"i":485,"$":{"0":{"v":"Consistent Hashing","n":0.707},"1":{"v":"\n\n ## Motivation:\n We have a stream of BLOB objects, and want to assign them to $n$ servers in a 'uniform' way. We also want to ensure that\n if a server is added or removed, the 'movement' of objects is not too much. In particular, if we add or remove a server we want only\n about $1/n$) of the objects to move around.\n\n Idea:\n Use a hash function that assigns both objects and servers to points in the unit circle. So $f:A->[0,2\\pi]$, for both servers and objects.\n Then assign each object $o$ to the closest server *counterclockwise* of $f(o)$. \n If a server is added or removed, it's obvious then what to do. \n 1. If added- only move objects __from__ the first one counterclockwise to it (and only those needed)- those are $\\approx O(1/n)$. \n 2. If removed -  move all objects __to__ the first one counterclockwise-all of them. Those are also about $O(1/n)$ \n\n","n":0.08}}},{"i":486,"$":{"0":{"v":"Case Studies","n":0.707},"1":{"v":"\n# Case Studies\n[Folder](https://drive.google.com/drive/folders/1P06pZj7OGW-ZNLgE2LuCCWPR0Ih3YmoL?usp=sharing)\n","n":0.577}}},{"i":487,"$":{"0":{"v":"youtube","n":1},"1":{"v":"\n[Youtube](https://docs.google.com/drawings/d/1EM7Ttn0Elk5Q_qjEcBhj9YOU1_DWwmQni7S_Dah4d-o/edit)\n\nDesign a video sharing service like youtube/ netflix.\n\n","n":0.354}}},{"i":488,"$":{"0":{"v":"Yelp Or Proximity Server","n":0.5},"1":{"v":"\n[Yelp](https://docs.google.com/drawings/d/1HZRf2XmpJVC9DXF5T-c7pL2KNtRO1Ol-IW4GNPfkgjw/edit).\n\n\nCan put all the locations in a [[science.CS.algos.Data Structures.Quad Tree]] -this will support search in expanding geographical area.\n","n":0.236}}},{"i":489,"$":{"0":{"v":"Web Crawler","n":0.707},"1":{"v":"\n[Web Crawler](https://docs.google.com/drawings/d/16zKbXuHaL3Zl2W0fQ1PbAYvBTIDIRJ_2M6j3XDAkq0s/edit)\n\n\n## basics\n\nStore html, maybe copy of page.\n* mention client-side rendered stuff (especially links)\n\n## Crawl = search\nBFS more natural than DFS (as we would rather go 'wide' than 'deep'). \n\n\nSend to pool of processors.\n\n\n\n[Web Crawler](https://app.excalidraw.com/s/1o3Skjxn05c/7pOeqla4JKf)\n\n![](/assets/images/2022-01-25-19-40-28.png)\n\n\n \n","n":0.167}}},{"i":490,"$":{"0":{"v":"Typeahead Suggestion","n":0.707},"1":{"v":"[Typeahead suggestion](https://docs.google.com/drawings/d/1X2E-llNZg0q9qga7JssUwsoVwiAJwWcBo-F-zWcHFg4/edit).\n\n\nIdea:\nUse Distributed [[science.CS.algos.Data Structures.Trie (Prefix Tree)]] and augment each node with  pointers to the the top K most frequent __words__  among the descendants.\n\nHave some batch job that periodically updates these top K words","n":0.171}}},{"i":491,"$":{"0":{"v":"Twitter","n":1},"1":{"v":"\n[Twitter](https://docs.google.com/drawings/d/1gLOKM2dSE4Zc77NbfyeX4R1e0mzZ0NeQlT1vqpU2FyM/edit)\n\n\n# System Scale ^scale\n\n200M users, 100M tweets/day, 1M followers/day, 1M following/day\n\n\n","n":0.302}}},{"i":492,"$":{"0":{"v":"Twitter Search","n":0.707},"1":{"v":"\n.\n\n[Twitter Search](https://docs.google.com/drawings/d/1qOdTbwsBYQ65XtxucVac01HI8a5yHMNB3i-mKD570XE/edit).\n\nMostly taken from [This conference talk](https://www.youtube.com/watch?v=KUmFJc3fFuM&ab_channel=Lucidworks).\n\n\n* Tweets- per-seconds: 150k\n* more than 2*10^9 search queries per day\n* Latency between tweeting and them beeing searchable <10 seconds\n\n## search ARchitecture\n\n\n\n# Basics Of Lucene and Inverted Indiex\n\nCreating an inverted index.\nSorted index - tree map in java?\n\n## TreeMap ^treemap\nCan be implemented as a  balanced Binary tree (like red-black tree)\n\n\n\nSr. No.\tAlgorithm\tTime Complexity\n1.\tSearch\tO(log n)\n2.\tInsert\tO(log n)\n3.\tDelete\tO(log n)\n\nOperation | Time |\n---------|----------|\n Search | O(logn) | \n Insert |(O(logn))  |\n Delete | O(logn)   |\n\nCan do range queries...\n\n## Another index\n\n[Lucene Internals Talk](https://www.youtube.com/watch?v=T5RmMNDR5XI&ab_channel=LuceneSolrRevolution)\n\ntermNo | Terms | docids \n---------|----------|---------\n 0 | data | 0,1\n 1 | index | 0,1\n 2 | lucene | 1\n\n\nBut difficult to update...\nSo same data as in a tree\n\n# \nCheck out also [General Search](https://app.excalidraw.com/s/1o3Skjxn05c/4C5rccysS5A)\n\n\nand\n[Twitters search in a bit more detail](https://app.excalidraw.com/s/1o3Skjxn05c/66MrgTm9HMM)","n":0.091}}},{"i":493,"$":{"0":{"v":"Pastebin","n":1},"1":{"v":"\n\n[Pastebin](https://docs.google.com/drawings/d/1azSNCipd9gVvZm4d5RbBMXUaT-ZA5xGiP552iz7AZrw/edit)","n":1}}},{"i":494,"$":{"0":{"v":"Netflix","n":1},"1":{"v":"\n[Netflix](https://docs.google.com/drawings/d/1vbQ4raPaJzwQsC8Z75r8wcMyVt08JygZChGcgf1hpkE/edit)\n","n":1}}},{"i":495,"$":{"0":{"v":"Mastering Sytem Design Notes","n":0.5},"1":{"v":"\n\n![](/assets/images/2022-01-11-14-57-10.png)","n":1}}},{"i":496,"$":{"0":{"v":"Instagram","n":1},"1":{"v":"\n[Instagram](https://docs.google.com/drawings/d/1I2mfNsUeJ53ciwtdq_jOjQJqRmzwrK9PniT7dUW5A5o/edit)","n":1}}},{"i":497,"$":{"0":{"v":"Facebook Newsfeed","n":0.707},"1":{"v":"\n[Facebook’s newsfeed](https://docs.google.com/drawings/d/1-KCd7J3r9k2uy50IKM6AiiCEUbz7Ku83d1r9_LXLfBU/edit).","n":0.707}}},{"i":498,"$":{"0":{"v":"Facebook Messenger","n":0.707},"1":{"v":"\n[Facebook Messenger](https://docs.google.com/drawings/d/1irhiSxKfTH3T3aLZrpK628Vq1ETF0PEdStVHEML7yFM/edit).\n","n":0.707}}},{"i":499,"$":{"0":{"v":"Dropbox","n":1},"1":{"v":"[Dropbox](https://docs.google.com/drawings/d/1E18zpiZHSP6wdnMT7k7EPzyVmmkOTLqTLytzEfsMado/edit).\n","n":1}}},{"i":500,"$":{"0":{"v":"Designing Uber Backend","n":0.577},"1":{"v":"\n[Uber Backend](https://docs.google.com/drawings/d/1-kZWlP49_xPPXh3CmE_7g8WLbHwE2p6at4iVpGxwJj0/edit).\n\n\n\n![[science.CS.algos.Data Structures.Quad Tree]]\n\nWe can use this to store the \"long-term locations\" of all drivers. \nUpdating it might be a bit costly, as they constantly move around, BUT we can do as follows:\n\nWhen a user requests a ride, we can check top drivers in their area and see their location in the quad-tree. Say the quad-tree is updated every minute or 15 seconds. \n\nIn addition, every driver sends their current location back every 3 seconds, but this is not reflected\nin the quad-tree as often, as it's a bit expensive to update.\n\nEvery driver represents a topic in a [[engineering.technologies.Message Queues]], to which topic all\ncustomers, interested in them, are subscribed (via the mobile client).\n\nThus a rider can request more general info on all drivers from the quad-tree (every 15 seconds), but \ncan track the locations of drivers they are subscribed to much more efficiently (every 3 seconds).\n\nThese subscriptions will be normally terminated when a ride is confirmed.\n","n":0.08}}},{"i":501,"$":{"0":{"v":"Design Ticketmaster","n":0.707},"1":{"v":"[Ticketmaster](https://docs.google.com/drawings/d/11bQH2kiRma-5naEyYxk8CbVnE0Pmdz1O3a5CQKRxhHg/edit).\n","n":1}}},{"i":502,"$":{"0":{"v":"API Rate Limiter","n":0.577},"1":{"v":"\n[API Rate Limiter](https://docs.google.com/drawings/d/10qrTOUTPn5mVVJgFJtpJFY9fNgsV3L77mX4buc7is90/edit)\n\n\nThis is quite simple:\nimagine we have such a picture:\n\n\n\n\nThen we simply want to discuss about a rolling window algorithm and how to implement it in a distributed way. It's not a big deal...\n![](/assets/images/2022-01-25-20-00-52.png)\n\nNote- maybe Mitko's solution w/ the 300 second buffer and writing things mod 300 will work here.\n\nAlso -for this talk about atomicity and stuff.","n":0.131}}},{"i":503,"$":{"0":{"v":"Caching","n":1},"1":{"v":"\n\n\nAppropriate for applications with more reads than writes.\n\nCache expiration policy...\n\n","n":0.316}}},{"i":504,"$":{"0":{"v":"Redis and Memcached","n":0.577},"1":{"v":"\n# Redis\n\n\n","n":0.707}}},{"i":505,"$":{"0":{"v":"CAP and PACELC Theorems","n":0.5},"1":{"v":"\n\n# CAP theorem\n\n## Availability\neveryone can read and write at the same time\n## Consistency\nif you and I both read some data, it will be the same.\n## Partition tolerance\nthe system works well across physical network partitions.\n\n\nExamples with a physical notebook- we all write some data for family finances in a  notebook. \nI have a notebook now and I put it on the camina. Now, a database system would be:\nWho's allowed to write in nb . What are the allowed to write?\nWhat constraints, like you can't write that I have 100000 usd;\nWhat happens if 2 peoiple try to write simultaneously?\n\n\nCap theorem- pick 2\n\n\n# PACELC Theorems\n In case of Partitionin one has to choose between availability and consistency,\n else (normal operations) between latency and consistency (in the sense of data consistency).","n":0.089}}},{"i":506,"$":{"0":{"v":"system_design,,Ml System Design","n":0.577}}},{"i":507,"$":{"0":{"v":"Doordash Talk","n":0.707},"1":{"v":"\nfrom ![](https://www.youtube.com/watch?v=sEZsIUBIhNk&list=PLmGsNPZGeM5D8fgr2scwe8wZih4SYB7Vt&ab_channel=InfoQ)\n\nReal world ML systems:\n```mermaid\ngraph LR;\nA(Data Pipeline)-->B(Model Deployment/Management)-->C(Model Monitoring/Evaluation)\n```\nReal world ML systems:\n10% algorithms\n90% ml systems\n\nHow to return the focus to the algorithms:\n# ML Systems\nRobust tools + templatzize best practices\n\n## DoorDash overview\n* Last mile on-demand logistics\n* 3 sided marketplace (users, restaurants, delivery service)\n* 1600 cities by end of 2018\n\nTechnology company\n\nConnecting the 3-sided marketplace.\n\nMostly restaurant delivery.\n\n100000+ resraurants.\n300000 delivery drivers.\n10^10^6 deliveries.\n### Goals of users: ^usergoals\n\n[[seed.Product Management.Personas]]\n### Restaurants:\nreach and revenie\n\n### Delivery Service:\nFlexibility and earnings\n\n### Users:\nConvenience and seleciton\n\nBetween the above sides, there are multiple ml algorithms:\n\n## Users-Restaurants:\nRecyss- recommendation/personalization, search ranking, demand prediction.\n\n## Merchants - Drivers:\n\nCore dispatch algorithm\nHotspots\nBatching of orders/etc\n\nSeems like the usual VRP stuff...\n\n\n# Merchants:\n\nfood prep time\nparking prediction\nselection intelligence (e.g. what things are ppl going to order, how to structure the menu maybe, etc..)\ncombine demand spikes etc\n\n\n# Users\nlifetime value\npromotions\naquisition\n\n# Delivery Service\n\nSupply calculation \nPay calculation (effort-based)\nIncentives\n\n\n# Offline (batch) to online (on-demand) axis\n\nreccomendation might be offline (in this case) so offline\ntime prediction -online\ndemand forecasting in the middle (multiple horizons).\n\n\n# Training Pipeline\n\n\n```mermaid\ngraph LR;\nF[Common Features Store]-->B\nA[(Data)]-->B(\"Features Extractor\")-->C(\"Model Training Jobs\")-->D[(Model Repo)]\n\n```\n\n[[Feature Stores]] are great/super important.\n\nThey serve as a single source of truth, store embeddings etc.\n\n\n# ML Performance goals\n\n* Accuracy SLAs\n* System SLAs  (latency)\n* Debuggability*\n* Time to Ship \n\n# Debuggability goals\n \n If some model is giving weird results, what do you do? What tooling do you need so you can quickly decide if it's a data issue, model going stale issue, or something else? What\n\n\n # Stefan's own musings\n\nLet's have some such structure:\n\n```mermaid\ngraph LR;\n\nD[Model Repository]--model-->I\nA[Request]-->B[Load Balancer]--\"json_data{user_id:1,restaurant_id:2,type:parking,...,timestamp}\"-->C[Predict]\nD[(Model Repository)]--Shadow Model-->I\n\nI[Model Service]-.-C\n\nF[(Feature Store)]--\"fetch data for entities, last entry<=Timestamp\"-->C\nE[(Model Log)]\nG[(\"Model Metrics and Monitoring\")]\nE-.->G\nC--\"features, predictions\"-->E\n\nA1[Model Metadata]-.->D\nH[S3]--->D\n\n\n```\n\nThe model log holds all request, feature values, predictions, and outcomes\n\n## Shadowing models\n\nRun models in parallel, as well as on the different groups. Use the parallel models for counterfactual stuff.\n\n## Use the model log to replay stuff\n\n\n## Use log for monitoring\n[[science.stats.Distribution Drift]]\n\n## Use log to train new models\nThus making the training and prediction processes closer (modulo effect on customer behavior).\n\n\n\n# Monitor\n* Feature Distributions\n* Predictions\n* Response times\n\ntrack summary stats, plot distributions, alert.\n\n# Launching new models\n\nMuch faser now, as now the process is as follows:\n```mermaid\ngraph TD;\na[Model Ready]--\"Model Registry Knows how to serve model\"-->B[Register Model Metadata]\nB--\"Can test as shadow as a stage before AB test\"-->C\nC[\"Enable Shadow/experiment\"]-->D[Monitor Metrics]\n\n\n\n```\n\n\n# Data Preparation\n\nWhile doing data prep, it would be ideal to integrate with the feature store.\n\n\n","n":0.052}}},{"i":508,"$":{"0":{"v":"HTTP Requests","n":0.707},"1":{"v":"\n#  POST, GET, PUT, DELETE\n\nPost - create\nGET- read\nPUT- update\nDelete - delete\n\n\nEverything but a get has a body\n\n\n","n":0.243}}},{"i":509,"$":{"0":{"v":"Instrumentation","n":1},"1":{"v":"\nOne re-writes \n\n\nhttps://docs.microsoft.com/en-us/dotnet/framework/debug-trace-profile/tracing-and-instrumenting-applications\n\n\nFrom [StackOverflow](https://stackoverflow.com/questions/2434516/what-is-instrumentation)\n\n\n* DLL rewriting. This is what tools like Purify and Quantify do. A previous reply to this question said that they instrument post-compile/link. That is not correct. Purify and Quantify instrument the DLL the first time it is executed after a compile/link cycle, then cache the result so that it can be used more quickly next time around. For large applications, profiling the DLLs can be very time consuming. It is also problematic - at a company I worked at between 1998-2000 we had a large 2 million line app that would take 4 hours to instrument, and 2 of the DLLs would randomly crash during instrumentation and if either failed you would have do delete both of them, then start over.\n\n* In place instrumentation. This is similar to DLL rewriting, except that the DLL is not modified and the image on the disk remains untouched. The DLL functions are hooked appropriately to the task required when the DLL is first loaded (either during startup or after a call to LoadLibrary(Ex). You can see techniques similar to this in the Microsoft Detours library.\n\n* On-the-fly instrumentation. Similar to in-place but only actually instruments a method the first time the method is executed. This is more complex than in-place and delays the instrumentation penalty until the first time the method is encountered. Depending on what you are doing, that could be a good thing or a bad thing.\n\nIntermediate language instrumentation. This is what is often done with Java and .Net languages (C~, VB.Net, F#, etc). The language is compiled to an intermediate language which is then executed by a virtual machine. The virtual machine provides an interface (JVMTI for Java, ICorProfiler(2) for .Net) which allows you to monitor what the virtual machine is doing. Some of these options allow you to modify the intermediate language just before it gets compiled to executable instructions.\n\nIntermediate language instrumentation via reflection. Java and .Net both provide reflection APIs that allow the discovery of metadata about methods. Using this data you can create new methods on the fly and instrument existing methods just as with the previously mentioned Intermediate language instrumentation.\n\nCompile time instrumentation. This technique is used at compile time to insert appropriate instructions into the application during compilation. Not often used, a profiling feature of Visual Studio provides this feature. Requires a full rebuild and link.\n\nSource code instrumentation. This technique is used to modify source code to insert appropriate code (usually conditionally compiled so you can turn it off).\n\nLink time instrumentation. This technique is only really useful for replacing the default memory allocators with tracing allocators. An early example of this was the Sentinel memory leak detector on Solaris/HP in the early 1990s.\n\nThe various in-place and on-the-fly instrumentation methods are fraught with danger as it is very hard to stop all threads safely and modify the code without running the risk of requiring an API call that may want to access a lock which is held by a thread you've just paused - you don't want to do that, you'll get a deadlock. You also have to check if any of the other threads are executing that method, because if they are you can't modify it.\n\nThe virtual machine based instrumentation methods are much easier to use as the virtual machine guarantees that you can safely modify the code at that point.\n\n(EDIT - this item added later) IAT hooking instrumentation. This involved modifying the import addess table for functions linked against in other DLLs/Shared Libraries. This type of instrumentation is probably the simplest method to get working, you do not need to know how to disassemble and modify existing binaries, or do the same with virtual machine opcodes. You just patch the import table with your own function address and call the real function from your hook. Used in many commercial and open source tools.\n\n\n","n":0.039}}},{"i":510,"$":{"0":{"v":"Human Computer Interface","n":0.577},"1":{"v":"\n# AutoEDA\n[[engineering.technologies.AutoEDA]]\n\n\n\n#\n","n":0.707}}},{"i":511,"$":{"0":{"v":"Google Analytics","n":0.707}}},{"i":512,"$":{"0":{"v":"Cloud","n":1},"1":{"v":"\n# [[engineering.Cloud.Google Cloud]]\n# [[engineering.Cloud.AWS]]\n\n# [[engineering.Cloud.Azure]]\n\n","n":0.447}}},{"i":513,"$":{"0":{"v":"Lambda","n":1},"1":{"v":"\n# Amazon Lambda\n\n# Google Cloud Functions\n","n":0.408}}},{"i":514,"$":{"0":{"v":"Google Cloud","n":0.707}}},{"i":515,"$":{"0":{"v":"CLI","n":1}}},{"i":516,"$":{"0":{"v":"Azure","n":1}}},{"i":517,"$":{"0":{"v":"AWS","n":1},"1":{"v":"\n\n# [[engineering.system_design.nosql.Amazon Kinesis]]\n\n# [[engineering.Cloud.AWS.Forecasting]]\n\n\n# [[engineering.Cloud.AWS.Simple Storage Service (S3)]]\n","n":0.354}}},{"i":518,"$":{"0":{"v":"Simple Storage Service (S3)","n":0.5}}},{"i":519,"$":{"0":{"v":"Forecasting","n":1},"1":{"v":"\n[[science.stats.Time Series]]\nSummary of [tutorial notebook](https://github.com/aws-samples/amazon-forecast-samples/blob/master/notebooks/advanced/Getting_started_with_AutoML/Getting_started_with_AutoML.ipynb)\n\n1. Install [[engineering.Cloud.AWS.CLI]] \n(Install from)[https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html)\n\n\n\n\n\n\n","n":0.333}}},{"i":520,"$":{"0":{"v":"CLI","n":1},"1":{"v":"\nSeel Also [[engineering.Cloud.Google Cloud.CLI]]\n\n\n","n":0.5}}},{"i":521,"$":{"0":{"v":"Firmware","n":1},"1":{"v":"\nFirmware is software that's embedded in a piece of hardware. Think **software for hardware**.\n\n\nFrom (wikipedia)[https://en.wikipedia.org/wiki/Firmware].\n\nExamples:\n \n BIOS of a computer: defines basic functions of a device, providing hardware abstraction services to higher level software such as OS.\n\n\n # Hardware abstraction\n \nFrom Wikipedia again:\n\nHardware abstractions are sets of routines in software that provide programs with access to hardware resources through programming interfaces. The programming interface allows all devices in a particular class C of hardware devices to be accessed through identical interfaces even though C may contain different subclasses of devices that each provide a different hardware interface.\n\n\n\n\n","n":0.102}}},{"i":522,"$":{"0":{"v":"Daily","n":1},"1":{"v":"\n\nTOP of mind:\n\n-- Make a mock service in python, connect it to a mock web internal tool.\n-- [Pytorch/BM/pyro] - make a logistic regression, as well as a mixed linear model in BM...\n-- try to write a process in pyro/bm\n-- [Communicate the status of the OR experiment to Sergei/etc]\n-- Check with bento ppl when CC is available in hack/JS...\n-- [learn what is a scaled lift experiment] \n-- Write down a simulation about what is 'scaled lyft' --\n-- write down a OR program about how the 'bqrt' universes look like...\n-- [Write down findings about the triggered exposures...]\n\n-----\n\n\nN, \\sigma, p:\n\n....\n\n------\n\n\nQ: what is scaled lift?\nA: is there a table of \n\n\n---\n\nQ: Exposing internal hack ndpoinp to python.\nuse trift ox xinterngwraphcontroller..\n\n----\n\nQ: how to measure 'work hours saved'?\n---- Maybe needed for BE things, would like to understand...\nI suppose you can try to identify the \nmeasure you're trying to move, and then move it.\nMaybe identify the sub-space you're likely to target.\n\n-- end to end workflow duration=\nusers spend less working hours =\nimproved sentiment around efficeincy.\n\n----\nQ: code ownership is still a bit of a foggy  conscetd, but filer are normally owned by an oncall...\n\nA\n----\nMore layoffs...\n---\nMore layoffs confirmed\n\n---\nJulia at meta is available...\n\n----","n":0.072}}},{"i":523,"$":{"0":{"v":"Journal","n":1}}},{"i":524,"$":{"0":{"v":"2022","n":1}}},{"i":525,"$":{"0":{"v":"07","n":1}}},{"i":526,"$":{"0":{"v":"2022-07-04","n":1}}},{"i":527,"$":{"0":{"v":"03","n":1}}},{"i":528,"$":{"0":{"v":"02","n":1}}},{"i":529,"$":{"0":{"v":"2022-02-04","n":1}}},{"i":530,"$":{"0":{"v":"Child Development","n":0.707},"1":{"v":"[[child development.screen time]]\n","n":0.577}}},{"i":531,"$":{"0":{"v":"Screen Time","n":0.707},"1":{"v":"# Cribsheet\nThe conclusion from the book is that limited screen time is not likely to be a problem. \nThis is true if TV is replacing low-value activities. When the parent/caregiver is tired or needs to do something  they can use the TV.\nChildren below the age of 3 years are not likely to learn anything from TV. Older children (3-5) can get value from educational material, such as Sesame Street. Interaction w/ real humans is still a  higher value learning activity.\n\nIt's likely that educational screen time (i.e. various games on the iPad) have similar properties, e.g. for very small children useless, but after 18-24 months, maybe useful.\n\nWatch out for reduced physical activity, as obesity is a risk w/ TV.\n\n\n# Oster Article ^Oster\n[emily oster about screentime](https://fivethirtyeight.com/features/screen-time-for-kids-is-probably-fine/) \n\nSummary:\nAAP recommendation from Emily Oster's childhood, as well as today:\n\nMain arguments:\n\n* Children and teens should have no more than __one to two hours__ of screen time per day, \nwith children under __2 having no screen time at all__. Those orders remain the same today.\n\n* But, iPad, Kindle, and others have opened the world of __educational__ screen time.\n\n* Mainly focusing on TV (passive) vs doing stuff on computer, or educational games.\n\n* Many studies, looking at executive function, but many confounders (TV time not randomly assigned - parents with less money, education give more passive screen time).\n\n* When you control for this results are mixedtest scores not so much.\n* Some evidence that reducing screen time can combat __obesity__\n* Eye strain not an issue- __kindle is fine__.\n\n* Some researchers used differen time TV was introduced in different parts of USA to produce counterfactuals for analysis:\n\nDirect Quote:\n\"The impacts of TV on IQ and test scores have not been subjected to large \nrandomized trial evaluation. Perhaps the best causal evidence on this question \ncomes from a 2008 paper by two media economists.1 The researchers take advantage \nof the fact that television was introduced to different areas of the United States at \ndifferent times. This variation meant that, when television was first introduced in the \n1940s and 1950s, some kids had access to TV when they were children and \nsome did not. The researchers could then see how having TV access as a \nyoung child — what the AAP is most worried about — related to test scores \nwhen kids were in school at slightly older ages.\"\n\n* maybe small impact on obesity, but difficult to study\n* What do you do instead of TV/ gaming. if whining and doing nothing, not so good. If interacting around, better.\n\n\n# Obesity Argument\n\nDirect quote:\n\"With this insight, it’s easy to see why less television is likely to decrease obesity. The process of weight gain and loss is pretty simple: if you burn more calories than you take in, you’ll lose weight. Watching television is mostly done sitting. And most other activities involve at least some moving around. So pretty much no matter what else they do, watching less TV is likely to be associated with kids burning more calories and losing weight.\"\n\n\n\n\n\n\n\n\n[[child development]]\n\n","n":0.045}}},{"i":532,"$":{"0":{"v":"Sleep Training","n":0.707}}},{"i":533,"$":{"0":{"v":"Mouth Breathing","n":0.707},"1":{"v":"It's bad, as it can lead to flat jaw, as well as dry mouth and teeth/gum problems, and it can also lead to sleep apnea.\n\n","n":0.2}}},{"i":534,"$":{"0":{"v":"Montessori","n":1},"1":{"v":"\n\n\nMontessory book notes.\n\n\nProbably connected to [[learning.Inquiry Based]]\n\n","n":0.378}}},{"i":535,"$":{"0":{"v":"Games","n":1},"1":{"v":"# How do Giants and Dwarves walk?\n\n# Dancing with some pieces of cloth\n\nSee if he/she can imitate your movements\n\n\n# Dancing with ribbons \nAs Above...\n\n# Bead Maze\n\nA bead maze is something like this:\n![](/assets/images/2023-01-22-17-15-08.png)\n\n# More dancing (moving to the rythm of the music)\n\n# Singing...","n":0.154}}},{"i":536,"$":{"0":{"v":"Baby Shopping List","n":0.577},"1":{"v":"\nWatch some baby first aid videos/take a course. Get first aid and [grooming kit for newborn](https://www.amazon.de/-/en/Thermometer-Aspirator-Scissors-Equipment-Newborns/dp/B07W7YWC67/ref=sr_1_6?keywords=baby+pflegeset&qid=1643489359&sprefix=baby+grooming%2Caps%2C92&sr=8-6). Also get some special [ baby laundry detergent](https://www.thebump.com/a/best-baby-detergent) and wash new everything new before wearing. Idk if needed, but my partner did it.\n\n0. Baby stroller- not much opinion, you can buy used, just test it, look so it has big wheels as it's easier to handle. Also if you're driving, be careful if buying so it's easy to put a base on the car. I think there are different standards and so on. For us we put it without the base.\n\n\n1. Bed - We used [Snoo Smart Sleeper](https://www.happiestbaby.com/products/snoo-smart-bassinet) . By far the best item on the list if you can get it, highly recommended. Will send some sleeping data separately.\n[You can also look at this article](https://www.littlebabygear.com/cheaper-snoo-alternative/).\nAlso consider buying some [baby swaddles](https://www.amazon.de/gp/product/B08DG66XWC/ref=ppx_yo_dt_b_asin_title_o06_s02?ie=UTF8&psc=1). We bought some, but practically used only the ones w/ the snoo. \n\n2. Books - we read very little, but I do recommend [Emily Oster's books](https://www.amazon.co.jp/s?k=emily+oster&crid=6IVPRSTBTOZC&sprefix=emily+oster%2Caps%2C259&ref=nb_sb_noss_1).\nWe are using a lot of the advice there. It appeals to me cause it's short and it has a lot of meta-analyses of papers and help you ease your anxiety specifically about breastfeeding and so. She now has a [blog, which is pretty nice too](https://emilyoster.substack.com/).\nI went trough first 5 chapters of [Baby 411](https://www.amazon.de/-/en/Ari-Brown/dp/1889392618/ref=sr_1_1?crid=7LR0P02PBXVG&keywords=baby+411&qid=1643489049&sprefix=baby+411%2Caps%2C100&sr=8-1), it's great, then used rest for reference\n\n\n3. [Dedicated white noise machine](https://www.amazon.co.jp/-/en/SoundSpa-Shower-Sleeping-Adjustable-Stroller/dp/B07317NQKW/ref=sr_1_11?crid=E17IESH6MEN3&keywords=baby+white+noise+machine&qid=1643488800&sprefix=baby+white+noise+machin%2Caps%2C246&sr=8-11) is a great one.0ww\n\n\n4. In-ear or contactless thermomether. Bonus: for boys for me it was super helpful to use the in-ear thermometer cap as a proxy for the bellow item the penis during diaper change.\n5. For [boys](https://www.amazon.co.jp/-/en/PT3080/dp/B004UGM6TS/ref=sr_1_1?crid=1JJ88DXPJIJNV&keywords=teepee+peepee&qid=1643487378&sprefix=teepee+peepe%2Caps%2C231&sr=8-1) only. Helps with diaper change stress (you don't ha).\n6. [Anti-smell diaper bin](https://www.amazon.de/gp/product/B004ME5O6K/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&psc=1). Helps a lot with the smell and have to change the inside bag only 1-2 times a week.\n\n7. Diaper changing mat. Diapers, 99% water baby wipes, diaper changing non-reusable pads. Put those to subscription.\n8. Pacifiers- buys several types to try\n9. Breast pump- not sure, we used mostly a manual one, as it's easier to control power, but had a electrical one as well.\n10. Baby bottle sanitizer (we had Phillips).\n11. [Baby bottle warmer](https://www.amazon.co.jp/-/en/Multi-functional-Pacifier-Disinfecting-Instruction-Guaranteed/dp/B085QJCZ4M/ref=sr_1_39?keywords=%E8%B5%A4%E3%81%A1%E3%82%83%E3%82%93%E3%83%9C%E3%83%88%E3%83%AB%E6%AE%BA%E8%8F%8C%E5%99%A8&qid=1643487615&sprefix=baby+bottle+%2Caps%2C231&sr=8-39), just picked a random one. \n12. [Nasal Aspirator](https://www.amazon.co.jp/-/en/dp/B09LLVMDCJ/ref=sr_1_2?keywords=%E8%B5%A4%E3%81%A1%E3%82%83%E3%82%93%E9%BC%BB%E5%90%B8%E5%BC%95%E5%99%A8&qid=1643487760&sprefix=baby+nasal+as%2Caps%2C229&sr=8-2)- I think this kind is quite good. You have some in the grooming kit as well, but for us we needed another kind...\n\n14. Baby carrier and maybe [winter/rain protector for it](https://www.amazon.de/gp/product/B07YBCKLB5/ref=ppx_yo_dt_b_asin_title_o09_s02?ie=UTF8&psc=1).  We're not using the carrier too much, but that's cause I'm lazy and it was super cold. Probably go for ergobaby or so.\n\n15. Maybe a [baby bathtub](https://www.amazon.de/gp/product/B07JMWCXZB/ref=ppx_yo_dt_b_asin_title_o00_s02?ie=UTF8&psc=1). We used it, but maybe you can just do it in the sink\n\n16. If supplementing, consider looking for [low flow bottles](https://www.amazon.de/gp/product/B000OE2XFC/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&psc=1) so it's harder to reject breast.\n\n17. Consider some contraption like [this](https://www.amazon.de/gp/product/B00JZF8LHK/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&psc=1) in case baby is fussy on breast. We tried it but was a bit annoying to use. But if you're commited it probably helps...\n\n18. [Baby doses of saline solution](https://www.amazon.de/gp/product/B007PZJOQ4/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&psc=1). Honestly haven't used, but meh.\n\n19. Liquid Vitamin D and some [topical baby oil](https://www.amazon.de/gp/product/B000ORYEF6/ref=ppx_yo_dt_b_asin_title_o09_s00?ie=UTF8&psc=1).\n\n20. Consider putting [some matress topper on your bed](https://www.amazon.de/gp/product/B00J70WFFM/ref=ppx_yo_dt_b_asin_title_o04_s02?ie=UTF8&psc=1), cause you know.\n\n21. Buy some clothes as needed.\n\n\n## From 6th week\n21.Maybe some [black and white, 'chewable' books like so](https://www.amazon.de/gp/product/B07SZK7HYC/ref=ppx_yo_dt_b_asin_title_o04_s00?ie=UTF8&psc=1). Baby didn't care for them the first 6 weeks, after started to like them and play w/ them a bit. \n22. Re:toys, i got recommended lovevery. Checki it out. Else I recommend to pay attention to buy some toys that both make noise and are thin enought for baby to grab. For couple of weeks he was grabbing stuff, but we didn't have anything both small enough to grab, not hard, and noise-making.\n\n## From 10th week\n23. [Some stuff to chew on if needed](https://www.amazon.de/gp/product/B001ABZGU2/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&psc=1)\n\n\n## Consider nannies/ au pair/etc.\n\n\n","n":0.041}}},{"i":537,"$":{"0":{"v":"Light Strollers","n":0.707},"1":{"v":"\n# [Article 1](https://www.babylist.com/hello-baby/best-lightweight-strollers)\n\n[Baby jogger city 2]https://www.amazon.de/-/en/Baby-Jogger-City-Tour-Jet/dp/B07NDVKQL8/ref=sr_1_3?keywords=baby+jogger+city+tour+2&qid=1647462147&sprefix=baby+jogger%2Caps%2C124&sr=8-3]\n\n\"Seat can be adjusted almost to the horizontal position and adjustable calf support for added comfort.\n\"\none-hand foldable\n\n199eu\n\n[Mountain Buggy Nano](https://www.amazon.de/-/en/Mountain-Buggy-Pushchair-Black-Travel/dp/B085RZJ4QK/ref=sr_1_2?crid=247XXAD0TY3E0&keywords=mountain+buggy+nano&qid=1647462317&sprefix=mountain+buggy+nano%2Caps%2C88&sr=8-2)\n\n[Chicco Buggy :light Weight](https://www.amazon.de/-/en/Foldable-Lightweight-Pushchair-Sleeping-Position/dp/B0927YHK4Z/ref=sr_1_3?keywords=chicco+buggy&qid=1647462344&sprefix=chicco+buggy%2Caps%2C91&sr=8-3)\n\n[This one is okay, but ](https://www.amazon.de/-/en/gp/product/B08J4WVYL8/ref=ox_sc_saved_image_1?smid=A3JWKAKR8XB7XF&psc=1)\nisn't this on ebetter?\nhttps://www.amazon.de/-/en/Reclining-Pneumatic-Height-Adjustable-Compactly-Collapsible/dp/B074ZCR33L/ref=zg_bs_3968955031_5/258-9899009-0338127?pd_rd_i=B09KLL12BF&psc=1\n","n":0.169}}},{"i":538,"$":{"0":{"v":"9 11 Month Development","n":0.5},"1":{"v":"\n\n# Starting to walk\n\n\nBaby started moving, so there's some exponential exploration going on.\n\n# [[Health And Personal Development.Language Learning]]","n":0.236}}},{"i":539,"$":{"0":{"v":"Misc","n":1}}},{"i":540,"$":{"0":{"v":"CofoundersBuyout","n":1},"1":{"v":"\n[Cofounders Buyout and Money raising](https://www.quora.com/As-a-co-founder-of-a-startup-who-is-no-longer-with-the-company-and-holding-17-equity-is-it-reasonable-to-put-up-a-fight-when-they-are-forcing-me-to-sell-my-shares-for-below-market-value-Im-told-they-will-dissolve-the-company-if-I-dont-sell)\n\n[Price to buy out co-founder](https://www.quora.com/Determining-a-price-for-buying-out-your-co-founder).\n\n\n","n":0.333}}},{"i":541,"$":{"0":{"v":"Test block references","n":0.577},"1":{"v":"Lorem ipsum dolor amet ^1234\n\n\n* Item 1\n* Item 2 ^second-item\n  * Item 2a\n  * Item 2b\n* Item 3 ^third-item\n* Item 4\n\n^whole-list\n\n| Sapiente | accusamus |\n|----------|-----------|\n| Laborum  | libero    |\n| Ullam    | optio     | ^whole-table\n","n":0.171}}},{"i":542,"$":{"0":{"v":"Supply Chain","n":0.707},"1":{"v":"\n\n# Supply Chain\nthe vaccine supply chain is crazy.\n#TODO - maybe someday research vaccine supply chains\n\n","n":0.258}}},{"i":543,"$":{"0":{"v":"Statsd","n":1},"1":{"v":"\nA network daemon that runs on the Node.js platform and listens for statistics, like counters and timers, sent over UDP or TCP and sends aggregates to one or more pluggable backend services (e.g., Graphite).\n\n\n","n":0.171}}},{"i":544,"$":{"0":{"v":"Reading List","n":0.707},"1":{"v":"\n- [ ] [GRL book ](https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf)\n- [ ] [Pytorch Tutorials](https://pytorch.org/tutorials/)\n   -  \n   - \n- [ ]  \n- [ ]  \n\n\n\n\n\n","n":0.224}}},{"i":545,"$":{"0":{"v":"Top Priority","n":0.707}}},{"i":546,"$":{"0":{"v":"Low Priority","n":0.707},"1":{"v":"\n\n* https://doc.rero.ch/record/333567/files/2021INFO014.pdf \n [[science.stats.Deep Neural Networks.Graph Neural Networks]]\n","n":0.354}}},{"i":547,"$":{"0":{"v":"Product Management","n":0.707}}},{"i":548,"$":{"0":{"v":"Philosophy and Rationality","n":0.577},"1":{"v":"\n\n## Difference Between Physics and Metaphysics\nCarl Sagan wrote directly about this:\n\nIn the 1920s, there was a dinner at which the physicist Robert W. Wood was asked to respond to a toast ... \n*'To physics and metaphysics.'* Now by *metaphysics was meant something like philosophy—truths that you could get to just by thinking about them*. Wood took a second, glanced about him, and answered along these lines: \n\nThe physicist has an idea, he said. The more he thinks it through, the more sense it makes to him. He goes to the scientific literature, and the more he reads, the more promising the idea seems. Thus prepared, he devises an experiment to test the idea. The experiment is painstaking. \nMany possibilities are eliminated or taken into account; the accuracy of the measurement is refined. At the end of all this work, the experiment is completed, and ... the idea is shown to be worthless. \n\nThe physicist then discards the idea, __frees his mind__ (as I was saying a moment ago) from the __clutter of error__, and moves on to something else. The difference between physics and metaphysics, Wood concluded, is that the __metaphysicist has no laboratory__.\n\nThe same is true of philosophy.\n\nHuman beings are *really good storytellers*. Philosophy can be thought of as a discipline that’s all about *telling stories*, often incomprehensible, and then congratulating yourself for the cleverness of your story*.\n\nBut stories aren’t truth. Finding *scientific truth means always, always looking outward at the physical world, not inward at your own navel*. No matter how clever an idea, no matter how elegant it is, and no matter how impressed you are by it, if it doesn’t match reality it must be discarded.\n\n#[Less Wrong](https://www.lesswrong.com/)\n\n#TODO add Kindle Notes From Book\n\n","n":0.059}}},{"i":549,"$":{"0":{"v":"Ugh Fields","n":0.707},"1":{"v":"And Ugh fields are areas of personal problems that make us flinch from thinking about, or doing, certain things. They are the areas where we have a conditioned emotional response of \"Ugh!\" conditioned to certain stimuli.\nIn That way they are 'pavlovian'.\n\n","n":0.156}}},{"i":550,"$":{"0":{"v":"The Modesty Epistemology","n":0.577},"1":{"v":"\n\n[Inadequate Equilibria:Where and  How Civilizations Get Stuck](https://equilibriabook.com/)\n","n":0.378}}},{"i":551,"$":{"0":{"v":"Scientific Method","n":0.707},"1":{"v":"\n# Reading List\n\n[Art of Grieving Well](https://www.lesswrong.com/posts/PHnMDhfiadQt6Gj23/the-art-of-grieving-well)\nIt's one perspective, a bit underestimating the initial parts and not discussing utility of \navoidance, adressed in the comments. But it's very good overall.\n\nKey part is it's framing loss in several ways that all seem kind of true and helpful.\n\nEg. :\nworld has changed, you have to move to a new world without the valued thing, but \nthe process of noticing and recognizing it feels like it's doing the 'moving itself'.\n\n\n\n\n[deliberate Grieving](https://www.lesswrong.com/posts/gs3vp3ukPbpaEie5L/deliberate-grieving-1)\nPractical advices...\n\n\n\nDon't ask for more effort. Grieving persons see things clearly. Don't burden them with your incompetence of dealing with the situation.\n\n\n\n# The Five Invitations\n[Sam harris podcast with hospise care guy](https://fiveinvitations.com/sam-harris-podcast-the-lessons-of-death/)\n\n\n# The Art of Grieving well\n[[Philosophy and Rationality.Ugh Fields]]\n\n\n\n\n# Deliberate Griefing\n\n\n## Orientation\n\n\n## Catharsis\n\n\n## Filling the Shape\n\n## Avoidance behaviors\n\nAnger, Denial, Bargaining...\n\n## Little bits of pain vs One big pain\n\n## Loss of the thing vs Loss of the future with the thing\n\n## Practicing the Grieving Process with Smaller Losses\n\n## How this relates with [[Philosophy and Rationality.Length of Emotional Response]]\n\n# 5 Stages and Beyond\n\n## 5 stages of grief\n### Denial\n\n### Anger\n\n### Bargaining\n\n### Depression\n\n### Acceptance\n\n\n## More Accurate Models\n\n\n\n## Ways to be okay\n\nEmotional regulation (if you're having a  bodily seresponse,but the thing can't be solved fi you're rushing around in the next minutes,  you're havinga reality distortion episode.).\n\nBut this cn be also said about any time you're not fully present inthe moment (mindfullness).\n#todo Mindfulness Practice\n#todo Check how mindfulness relates to overall practice.\n#todo Just return to the present moment...\n\n\n\n\n\n\n","n":0.065}}},{"i":552,"$":{"0":{"v":"Reasoning by Analogy","n":0.577}}},{"i":553,"$":{"0":{"v":"Propaganda","n":1}}},{"i":554,"$":{"0":{"v":"Podcast Summaries","n":0.707},"1":{"v":"\n\n#[Lex Fridman](https://www.lexfridman.com/) ^lexFridman\n## Lex Fridman and Tim Urban \n\n### Neuralink\n\n* Solve Paralysis\n* More bandwidth when communicating (telepathy)\n* Direct Communication Interface (e.g. run Spotify song on audio processing part of the brain)\n* Procrastination and Having a System, .g. work for a 3 hour blocks in the morning\n* Anxiety and \"clean fun\", rather than guilty fun. ![](https://store.waitbutwhy.com/collections/posters/products/dark-playground-poster-18x24)\n* [Procrastination Blog Post](https://waitbutwhy.com/2013/10/why-procrastinators-procrastinate.html).\n* How our brain processes film and music\n Language is low-bandwidth. For example,I say 'this film made me sad and  angry'. You're not going to necessarily understand what 'angry' means in this context. In reality, a film or book evokes a multitude of thoughts, which are complicated and hard to convey in low-bandwidth media, such as language. If I have a Neuralink connection with you, I can directly give you the bucket of thoughts and feelings that I'm feeling.\n __Stefan's commentary__ - it's debatable if this makes sense, as you still have the summarization problem. \n That is, why would the bucket then be more concise of just the person watching the movie?\n\n\n * Elon Musk and thinking from [[Philosophy and Rationality.First Principles Thinking]]\n Have to find a balance between thinking from first principles and [[Philosophy and Rationality.Reasoning by Analogy]], as the latter is faster.\n\n* Echo Chambers and Idea Labs\n[[Philosophy and Rationality.Echo Chambers]]\nAn Echo Chamber has a religious component. 'My peer group has decided to take this position on the topic so this is my position as well'.\n\nAn Idea Lab follows the [[Philosophy and Rationality.Scientific Method]] to evaluate ideas by designing and running experiments and analyzing their results.\n\n","n":0.063}}},{"i":555,"$":{"0":{"v":"Length of Emotional Response","n":0.5},"1":{"v":"Half- life in terms of physiology of negative emotions is incredibly short and if you want to stir it up more, you have to actively re-open the topic.\n[Longer Video](https://www.youtube.com/watch?v=ru9Od__qDaA&ab_channel=BillionaireAdvice)","n":0.186}}},{"i":556,"$":{"0":{"v":"Knowledge Should be Public","n":0.5},"1":{"v":"\n\nConrado from Verta emphasised on this point.\n","n":0.378}}},{"i":557,"$":{"0":{"v":"Incentives for Research and Engineering Advances","n":0.408},"1":{"v":"\n# Large, Standartized, and Open datasets open the floodgates for ML advancement\n\n[Point](https://youtu.be/y_TzOOCJqxI?t=553)\n\n# ImageNet\n# Netflix Prize ^netflix-prize\n","n":0.25}}},{"i":558,"$":{"0":{"v":"Futurism","n":1},"1":{"v":"# The Class of Unemployable Person\n## Universal Basic Income\n[Andrew Yang on Sam Harris' podcast](https://www.samharris.org/podcasts/making-sense-episodes/202-may-11-2020)\n\n## Opioid Crysis\n## Externalities by Big Tech\n[Movie ](https://en.wikipedia.org/wiki/The_Social_Dilemma)\n[Podcast](https://www.humanetech.com/podcast)\n\n#TristanHarris\n","n":0.218}}},{"i":559,"$":{"0":{"v":"First Principles Thinking","n":0.577}}},{"i":560,"$":{"0":{"v":"Echo Chambers","n":0.707},"1":{"v":"\n\n[[science.stats.Regression.Recommender Systems]]\n[[seed.Product Management.AdTech]]\n[[Philosophy and Rationality.Propaganda]]\n","n":0.447}}},{"i":561,"$":{"0":{"v":"Algorithmic Privacy, Right to be Forgotten","n":0.408},"1":{"v":"\n\n# Differential Privacy\n\n#  Privacy and GDPR ^gdpr\n E.g. in the context of [[science.stats.Regression.Recommender Systems]], we could delete the user data and then use the cold start models\n\n^gdpr-end\n","n":0.192}}},{"i":562,"$":{"0":{"v":"Algorithmic Fairness","n":0.707},"1":{"v":"\n\n## Error is same across groups\nCan just train algo and then test if errors same (ANOVA, t-test variations, [[science.stats.Bayesian Framework]] bayesian models, etc).\n\n[Independence,etc](https://en.wikipedia.org/wiki/Fairness_(machine_learning)#Fairness_criteria_in_classification_problems)\n\n# Independence\nWe say the random variables ${\\textstyle (R,A)}$ satisfy independence if the sensitive characteristics $A$ are statistically independent to the prediction $R$, and we write $R\\bot A$.\n\nWe can also express this notion with the following formula:\n\n${P(R=r|A=a)=P(R=r|A=b)\\quad \\forall r\\in R\\quad \\forall a,b\\in A}$ for $R$-result, $A$ -sensitive characteristic. ^independence-formula\n\nThis means that the probability of being classified by the algorithm in each of the groups is equal for two individuals with different sensitive characteristics.\n I think this is roughly equivalent of the 'same error for all groups'.","n":0.097}}},{"i":563,"$":{"0":{"v":"ML system design","n":0.577}}},{"i":564,"$":{"0":{"v":"Youtube Case Study","n":0.577},"1":{"v":"\n# Problem Statements\n\nBuild a video recsys for Youtube end users. Maximize engagement+ serendipity.\n\n\n# Metrics\n\n## Offline Evaluation Metrics\n![[science.stats.Regression.Loss Functions#^ranking-start]]\nDepends on how the problem is posed. If posed as a classification problem (probability to interact), can use precision, recall, etc.\n\nDuring training we use whatever's the model. During model evaluation \n\n","n":0.144}}},{"i":565,"$":{"0":{"v":"Loss Functions","n":0.707}}},{"i":566,"$":{"0":{"v":"Health And Personal Development","n":0.5},"1":{"v":"[[science.Health]]\n\n\n\n\n\n\n\n.\n","n":1}}},{"i":567,"$":{"0":{"v":"Work Habits","n":0.707}}},{"i":568,"$":{"0":{"v":"New Future of Work","n":0.5},"1":{"v":"\n\n# New Future of Work Talk (Sam Harris) \n\n[Conversation With Matt Mullenweg](https://www.samharris.org/podcasts/making-sense-episodes/194-new-future-work)\n\n\n![](/assets/images/2022-07-04-11-24-58.png)\n**Main outtakes:**\n\n**1. Levels of usage of remote work\n**  \n1.1. No action\n1.2 Recreate office- synchronous communcation, interruptions, etc.\n1.3 Adapting to the medium\n4. Asynch communication, seamless collaboration, public knowledge\n5. Nirvana (?) \n* Replicate office in online settings\n* New processes\n\n2. Live 'meeting notes' document, where everyone can comment etc.\n3. Make *knowledge public*, then best ideas float up\n4. *Hack against 'lizard brain'* and dick-waving \nPrevent \n**\n\n\n# Effective Meetings\n\n#TODO Check [this article](https://www.scienceofpeople.com/run-a-meeting/) out\n\n![](/assets/images/2022-07-04-12-01-07.png)\nhttps://www.scienceofpeople.com/run-a-meeting/\n\n\n# Effective Remote meetings\n\n\"around 50% of meeting time is used effectively\".\n\nWhat is 'effective meeting'\n\nhttps://sloanreview.mit.edu/article/the-surprising-science-behind-successful-remote-meetings/\n\n\n1. Stewardship mindset\nProtector and server of other's time\n2. Set up for success\n\n ** Lean towards shorter meetings**\n\n **Sharpen the agenda**\n Make the agenda a set of answers to be answered, rather than set of topics to be discussed.\n\n **Use Video** \n\n !![[Psychology.Social Loafing]]\n\n Video + inviting as few people as possible reduces that.\n\n\n * Start and End on Time (pay attention to smooth technical setup)\n * Norms \n  With your attendees, periodically create **mutual expectations** about what makes for a good remote meeting. Surface expectations, like **“let’s keep all contributions to no more than 60 seconds so everyone has a chance to speak,”** and **give colleagues a chance to reply**. To combat meeting fatigue in longer meetings, it’s helpful to **set norms about when folks can take breaks**, stand up, and stretch.\n* Actively Facilitate\n \"** Ivana, please share your thoughts**\"\n\n * Use Tools\n  Don't use side conversation, use available in-chat technology. Speak up if missed something.\n  Polls (Klaxoon, Pool Everywhere)\n  Determine if consensous has been reached.\n\n# End Meetings, Gathering Feedback\n\n* **End Meetings Well** Clarify takeaways.\nIdentify **who does what next**. \n**Don't let anyone leave your meeting wondering what was accomplished or what the next steps are.**\n\n* Ask for feedback\n Quick surveys- what's going well/not so well, provide ideas for improvement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","n":0.058}}},{"i":569,"$":{"0":{"v":"Collaboration","n":1},"1":{"v":"\n\n\n\n\n[Article from MIT Sloan about collaboration](https://sloanreview.mit.edu/article/collaboration-is-a-key-skill-so-why-arent-we-teaching-it/)\n\n\nStructured learning for collaboration.\n\n * Meetings\n * Act together in project teams\n * Manage Up, Down\n\n[Running successful remote meetings](https://sloanreview.mit.edu/article/the-surprising-science-behind-successful-remote-meetings/)\n \n","n":0.2}}},{"i":570,"$":{"0":{"v":"Progressive Overload","n":0.707},"1":{"v":"\n\nUseful in the gym...\n\nGet out of your comfort zone by a bit...\n\nUseful in learning- try to get the appropriate level of difficulty.\n\n\n[[Health And Personal Development.Growth Mindset]]","n":0.196}}},{"i":571,"$":{"0":{"v":"Procrastination","n":1},"1":{"v":"\n# Wait but Why? (Tim Urban)\n* Future you\n* Impulsive Monkey\n\n# Rapid Anti-Procrastination Techniques\n1. Make a List, broken down by smaller tasks\n -- have to know the topic first!!!\n2. Set your environment - distractions, etc\n3. get started early \n4. Group up find yourself a buddy to keep accoutables\n5. Aim for a PB (againhave to have a goal) - meet yourself where you are, not where you should be\n6. Something is better than nothing (done is better than perfect)\n7. Try things outs\n\n\n\n# BEDS-M system\n## B-Burn Bridges\nHold yourself accountable by making real punishments\n## E- Environment\nSet up your environment to make it easier to do the right thing and hard to do the wrong thing\n\n## D- Distraction Cheat Sheet\nWhenever you get distracted, write down what you were doing and what distracted you. Then, when you get back to work, you can see what you were doing and what distracted you. This will help you to see patterns and make changes.\n\n## S- Schedule\nWe'll go over this at some point. I'm terrible at it.\n\n\n## M- Minimum Viable Task\n\nIf I want to study for 2 hours, but this seems daunting, then force myself to study 1 hour, before that force myself to just set up the environment.\n\nMove the bottleneck from motivation to environment. This requires setting up the enviromnnt, but the motivation for that can be lower cause it's easier to automate and doesn't require cognitive power, and thus doesn't require much willpower.\n\n\n\n","n":0.065}}},{"i":572,"$":{"0":{"v":"Language Learning","n":0.707},"1":{"v":"\n\n# Early childhood language learning\n\n# Understanable Input Language Learning\n\n","n":0.333}}},{"i":573,"$":{"0":{"v":"Keyboards","n":1}}},{"i":574,"$":{"0":{"v":"QMK Notes","n":0.707},"1":{"v":"\nNotes, following the [official QMK documentation](https://docs.qmk.fm/).\n\n\n\n# Tools\n\n# QMK Firmware\n[[Engineering.Firmware]]\n\n\nFrom [QMK docs](https://docs.qmk.fm/#/newbs)\nYour computer **keyboard has a processor** inside of it, similar to the one inside your computer. This processor **runs software** that is responsible for **detecting button pr\nsesses** and informing the computer when keys are pressed. **QMK Firmware** fills the role of **that software**, detecting button presses and passing that information on to the host computer. When you build your **custom keymap**, you are creating an **executable program for your keyboard**.\njkll\n\n\n\n\nSteps:\n1. First, fork the ergohaven's fork of the qMk repo. they have the code there.\n2. Make sure the compiler works, using some of the example keyboards in the qmk repo.\n3. install the qmk. it was tricky to do on linux, as there was something with the nmPy first, and then after that arm stack etc...\n4. From the EH repo, copy to the vial repo, the EH files. Edit as needed. I basically removed the fancy rgb sruff, and added rhe tap daace stuff. \n5. Build the files. I found the build hex files in rhe .build folder in the repo.\n6. Use the qmk toolbox to flash. The best way to flash is to check in **Vial** where is the **Reset** button. This will put the kb in the flash mode, then relAtively quickly press the ** flash** button in the qmk toolbox interface. \n7. Of course, there is an equivalent command line way to do that, but haven't used it.\n8. Voila, you gotthe tap dace option now!!!\n\n\n\n\n# QMK Configurator\n\n\n# QMK Toolbox \n\n# qmk.fm\n\n\n\n\n# Software-only alternatives\n\nOn windows there is autohotkey, which has a bunch of advanced functionalities.\nOn unix and mac (as well as Win), there is  kmonad, which can I suppose emulate qmk pretty well...\n\nWill try to check it out, p;erhaps especially with autoshift for the kinesis and so on...\n\nMaybe also on the lapop i would be nice.\n\n","n":0.057}}},{"i":575,"$":{"0":{"v":"Kinesis Advantage","n":0.707}}},{"i":576,"$":{"0":{"v":"Ergodox","n":1}}},{"i":577,"$":{"0":{"v":"Dactyl","n":1}}},{"i":578,"$":{"0":{"v":"Habits","n":1},"1":{"v":"# Habit Tier List\n\nFrom [This youtube video](https://www.youtube.com/watch?v=GriR73kSvPY&ab_channel=ImprovementPill)\n\n\n## Life Changing Habits\n\n### **Exercise**\n\n### Bullet Journaling\n\n### **Reading**\n\n### **Meditation** \n  \n### Keeping a diary\n\n### Listening to podcasts\n\n\n### Practicing a skill\n\n\n\n\n\n\n## Great habits\n\n### Cooking\n\n\n\n\n### Practicing Music\n\n### Doing your chores\n\n\n### Dancing\n\n\n\n### Studying (in a traditional sense, for exams) \n\n\n\n\n### Grooming\n\n\n\n### Cold Showers\n\n\n\n## Nice to Have\n\n### Getting sunlight\n\n\n### Positive affirmations\n\n### Drinking Water Every Morning\nGood cause slightly dehydrated\n\n### Resting your eyes\n20/20/20 rule- every 20 minutes, for 20 seconds, look at something 20 feet away.\n\n### Making your bed\n\n### Being mindful of your posture\nA weird habit in a sense, since it's acombination of other hings.\n\n### Watching self-improvement videos\nWorse than reading/podcasts/blogging, as videos  and games prioritize making you feel better about yourself to information density.\n\n## Not Really a Habit\n\n### Waking up Early\n\n### Being mindful of your words\n","n":0.089}}},{"i":579,"$":{"0":{"v":"Growth Mindset","n":0.707},"1":{"v":"\n\n\n\nRelated to embracing failure, and not being afraid of it.\n\n(should be a concentric circles)\n```mermaid\n\ngraph LR;\nA[Comfort Zone]-->B[Fear Zone]-->C[Growth Zone];\n```\n\nBy definition anything that's not in the 'fear zone' is in the 'comfort zone'","n":0.18}}},{"i":580,"$":{"0":{"v":"Currying","n":1},"1":{"v":"Convert $f:AxB->C$ into $f:A->(B->C)$, i.e. $f_a(b) = f(a,b)$ but $f_a$ is now a function. \n\n\nmoo mooo lmoo.","n":0.243}}},{"i":581,"$":{"0":{"v":"Cache Invalidation","n":0.707}}}]}
