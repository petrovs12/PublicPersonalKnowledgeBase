<h1 id="nlp">NLP<a aria-hidden="true" class="anchor-heading icon-link" href="#nlp"></a></h1>
<p>From <a href="https://towardsdatascience.com/a-no-frills-guide-to-most-natural-language-processing-models-part-1-the-pre-lstm-ice-age-86055dd5d67c">this medium article</a>
Pre- LSTM Dark Age</p>
<div class="mermaid">
  graph LR;
a[NNLM-2003] --> b[word2Vec 2013]--> c[GloVe 2014]-->d["fastText(2016)"]
</div>
<h1 id="seq2seq">Seq2Seq<a aria-hidden="true" class="anchor-heading icon-link" href="#seq2seq"></a></h1>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/PublicPersonalKnowledgeBase/notes/e19xez30674v61vgdmj2wyp">Sequence To Sequence Modelling</a></li>
</ol>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/PublicPersonalKnowledgeBase/notes/kLxsht52xetEs7EkFskgS">Kaggle Competition Notes</a></li>
<li><a href="/PublicPersonalKnowledgeBase/notes/i9SU8nymuONYrefbbOfKX">API's</a></li>
</ul>