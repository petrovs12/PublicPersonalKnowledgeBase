<h1 id="classification">Classification<a aria-hidden="true" class="anchor-heading icon-link" href="#classification"></a></h1>
<h1 id="multiple-label-classification">Multiple Label Classification<a aria-hidden="true" class="anchor-heading icon-link" href="#multiple-label-classification"></a></h1>
<p></p><p></p><div class="portal-container">
<div class="portal-head">
<div class="portal-backlink">
<div class="portal-title">From <span class="portal-text-title">Multiple Labels</span></div>
<a href="/PublicPersonalKnowledgeBase/notes/ir5u91f6di3yclnfq9xnxxl" class="portal-arrow">Go to text <span class="right-arrow">â†’</span></a>
</div>
</div>
<div id="portal-parent-anchor" class="portal-parent" markdown="1">
<div class="portal-parent-fader-top"></div>
<div class="portal-parent-fader-bottom"></div><h1 id="multilabel-classification-"><a aria-hidden="true" class="block-anchor anchor-heading icon-link" id="^multilabel" href="#^multilabel"></a>MultiLabel Classification <a aria-hidden="true" class="anchor-heading icon-link" href="#multilabel-classification-"></a></h1>
<p><a href="https://machinelearningmastery.com/multi-label-classification-with-deep-learning/">https://machinelearningmastery.com/multi-label-classification-with-deep-learning/</a>
<a href="https://github.com/keras-team/keras/issues/741">https://github.com/keras-team/keras/issues/741</a></p>
<p>One way is to use sigmoid output, but not normalize w/ softmax/multilabel likelyhood, and have the loss function be point-wise binary crossentropy
loss for each element, and sum them up (it works).</p>
<pre><code>
Q:
I need train a multi-label softmax classifier, but there is a lot of one-hot code labels in examples, so how to change code to do it?

A:elanmart commented on Sep 28, 2015
Don't use softmax. Use sigmoid units in the output layer and then use "binary_crossentrpy" loss.
</code></pre>
<p><strong>Actually it's equivalent to train a single binary classifier to everything, but the learned hierarchical representation before the last label
is shared.</strong></p>
<h2 id="keras-example">Keras Example<a aria-hidden="true" class="anchor-heading icon-link" href="#keras-example"></a></h2>
<pre class="language-{python}"><code class="language-{python}">
# Build a classifier optimized for maximizing f1_score (uses class_weights)

clf = Sequential()

clf.add(Dropout(0.3))
clf.add(Dense(xt.shape[1], 1600, activation='relu'))
clf.add(Dropout(0.6))
clf.add(Dense(1600, 1200, activation='relu'))
clf.add(Dropout(0.6))
clf.add(Dense(1200, 800, activation='relu'))
clf.add(Dropout(0.6))
clf.add(Dense(800, yt.shape[1], activation='sigmoid'))

clf.compile(optimizer=Adam(), loss='binary_crossentropy')

clf.fit(xt, yt, batch_size=64, nb_epoch=300, validation_data=(xs, ys), class_weight=W, verbose=0)

preds = clf.predict(xs)

preds[preds>=0.5] = 1
preds[preds&#x3C;0.5] = 0

print f1_score(ys, preds, average='macro')

</code></pre></div></div><p></p><p></p>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/PublicPersonalKnowledgeBase/notes/ohig3kFWFg58aXDpgB3Aq">Class Imbalance</a></li>
<li><a href="/PublicPersonalKnowledgeBase/notes/C0xQGR2tHaA6spLh3IAiw">Metrics</a></li>
<li><a href="/PublicPersonalKnowledgeBase/notes/ir5u91f6di3yclnfq9xnxxl">Multiple Labels</a></li>
</ol>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/PublicPersonalKnowledgeBase/notes/hiuvax4qcz63e0zseg5c8ai">Industry Applications</a></li>
<li><a href="/PublicPersonalKnowledgeBase/notes/ohig3kFWFg58aXDpgB3Aq">Class Imbalance</a></li>
</ul>